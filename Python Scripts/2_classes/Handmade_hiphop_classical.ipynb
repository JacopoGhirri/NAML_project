{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_hiphop_classical.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for 2 genres classification - Hip Hop vs Classical\n",
        "\n",
        "We aim at training a Neural Network to distinguish between two genres: Hip Hop and classical."
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33c2743-4d4e-4668-9c62-689308f13f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e6b8ea-f0f2-41f7-a86b-71256e30d850"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "IoV9bIbPfg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "#genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "genres = {'hiphop': 0, 'classical': 1}\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=2)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0176d1c8-f160-4474-ba43-0bf8a7d07a85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hiphop done\n",
            "classical done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "0sgOQfv-gZ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(2):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 173, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 173, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 173, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, 2))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, 2))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, 2))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "O6AvTMw2hgxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.25, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_units = 2\n",
        "input_shape = (128,173,1)\n",
        "\n",
        "model = build_model(input_shape, n_units)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9221aad-6128-49b6-fbea-31a71c06552d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 173, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 173, 4)       40        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 173, 8)       136       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 86, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 86, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 43, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 43, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 21, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 21, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 21, 64)        16448     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 10, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 10, 128)        32896     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 5, 286)         146718    \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 241,056\n",
            "Trainable params: 241,056\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 20,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9d2f34-7fa1-45f9-ac16-beaa528fbd26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "7/7 [==============================] - 12s 92ms/step - loss: 0.7197 - accuracy: 0.5286 - val_loss: 0.6527 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.7101 - accuracy: 0.4786 - val_loss: 0.6696 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6458 - accuracy: 0.6929 - val_loss: 0.5295 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.4794 - accuracy: 0.8143 - val_loss: 0.2487 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.2975 - accuracy: 0.8643 - val_loss: 0.2298 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.2876 - accuracy: 0.8714 - val_loss: 0.2254 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.2543 - accuracy: 0.9143 - val_loss: 0.3337 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.2493 - accuracy: 0.9214 - val_loss: 0.2128 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.1808 - accuracy: 0.9429 - val_loss: 0.4292 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.1832 - accuracy: 0.9286 - val_loss: 0.2622 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1579 - accuracy: 0.9643 - val_loss: 0.2699 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1539 - accuracy: 0.9429 - val_loss: 0.3272 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.1150 - accuracy: 0.9714 - val_loss: 0.2118 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.2581 - accuracy: 0.9214 - val_loss: 0.6723 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1401 - accuracy: 0.9500 - val_loss: 0.2139 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1357 - accuracy: 0.9786 - val_loss: 0.3008 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1359 - accuracy: 0.9714 - val_loss: 0.3226 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.0997 - accuracy: 0.9714 - val_loss: 0.3239 - val_accuracy: 0.9250 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.0819 - accuracy: 0.9786 - val_loss: 0.2985 - val_accuracy: 0.9250 - lr: 5.0000e-04\n",
            "Epoch 20/500\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.0936 - accuracy: 0.9714 - val_loss: 0.2978 - val_accuracy: 0.9250 - lr: 5.0000e-04\n",
            "Epoch 21/500\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.0908 - accuracy: 0.9857 - val_loss: 0.3182 - val_accuracy: 0.9250 - lr: 5.0000e-04\n",
            "Epoch 22/500\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0517 - accuracy: 0.9857 - val_loss: 0.3224 - val_accuracy: 0.9500 - lr: 5.0000e-04\n",
            "Epoch 23/500\n",
            "7/7 [==============================] - 0s 51ms/step - loss: 0.0660 - accuracy: 0.9786 - val_loss: 0.3254 - val_accuracy: 0.9500 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0564 - accuracy: 0.9857 - val_loss: 0.3237 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 25/500\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.0659 - accuracy: 0.9857 - val_loss: 0.3069 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 26/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0557 - accuracy: 0.9857 - val_loss: 0.3001 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 27/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0789 - accuracy: 0.9786 - val_loss: 0.3313 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 28/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0495 - accuracy: 0.9857 - val_loss: 0.3258 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 29/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0411 - accuracy: 0.9857 - val_loss: 0.3145 - val_accuracy: 0.9500 - lr: 1.2500e-04\n",
            "Epoch 30/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0497 - accuracy: 0.9857 - val_loss: 0.2970 - val_accuracy: 0.9500 - lr: 1.2500e-04\n",
            "Epoch 31/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0607 - accuracy: 0.9857 - val_loss: 0.2901 - val_accuracy: 0.9500 - lr: 1.2500e-04\n",
            "Epoch 32/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.0526 - accuracy: 0.9857 - val_loss: 0.2871 - val_accuracy: 0.9500 - lr: 1.2500e-04\n",
            "Epoch 33/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.0604 - accuracy: 0.9714 - val_loss: 0.2966 - val_accuracy: 0.9500 - lr: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "09486e2b-65e5-4eb8-bb41-718afc485973"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/hiphopvclassical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "55fa4c81-888e-496b-95fc-fa78b7ab2475"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/hiphopvclassical/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/hiphopvclassical/assets\n"
          ]
        }
      ]
    }
  ]
}