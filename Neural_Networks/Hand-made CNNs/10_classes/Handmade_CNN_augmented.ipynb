{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Handmade_CNN_augmented.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Black Box Approach for all 10 genres classification\n",
    "\n",
    "We aim at training a Neural Network to distinguish between all the different genres.\n",
    "In this model we try and augment the dataset"
   ],
   "metadata": {
    "id": "gKB_Sss8Ql-3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SwPJ54sBQlFO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "98f5755d-096d-4ba5-b70f-906561cd8fdb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "#importing google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#setting the working directory\n",
    "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
   ],
   "metadata": {
    "id": "iYHj7NhnQs_-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f6754e91-e67c-4cc4-e4c8-80593f082f73"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "seed = 42"
   ],
   "metadata": {
    "id": "INc4ttEUQuxN"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
   ],
   "metadata": {
    "id": "WS4HjCWqkkUY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = []\n",
    "genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, \n",
    "        'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
    "n_genres = 10\n",
    "\n",
    "for genre, genre_number in genres.items():\n",
    "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
    "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
    "        for i in range(3):\n",
    "          y, sr = librosa.load(songname, mono=True, duration=9.9, offset = i*9.9)\n",
    "          ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
    "          ps = librosa.power_to_db(ps**2)\n",
    "          dataset.append( (ps, genre_number) )\n",
    "    print(str(genre+' done'))"
   ],
   "metadata": {
    "id": "oiT5mkVqQ_lt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "46ce1b74-fd58-4947-b402-c5cfc7a22f31"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "blues done\n",
      "classical done\n",
      "country done\n",
      "disco done\n",
      "hiphop done\n",
      "jazz done\n",
      "metal done\n",
      "pop done\n",
      "reggae done\n",
      "rock done\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We split the dataset according to the following composition:\n",
    "\n",
    "\n",
    "*   70% training set\n",
    "*   20% validation set\n",
    "*   10% test set\n",
    "\n",
    "Maintaining equal proportions amongst classes\n",
    "\n"
   ],
   "metadata": {
    "id": "FD5R_1cekn7f"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "order = np.arange(start = 0, stop = 100, step = 1)\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "training = []\n",
    "validation = []\n",
    "test = []\n",
    "\n",
    "for i in range(n_genres):\n",
    "  shuffle = np.random.permutation(order)\n",
    "  for k in range(70):\n",
    "    for kk in range(3):\n",
    "      training.append(dataset[i*100 + shuffle[k]*3 + kk])\n",
    "  for l in range(20):\n",
    "    for ll in range(3):\n",
    "      validation.append(dataset[i*100 + shuffle[l+70]*3 + ll])\n",
    "  for m in range(10):\n",
    "    for mm in range(3):\n",
    "      test.append(dataset[i*100 + shuffle[m+90]*3 + mm])"
   ],
   "metadata": {
    "id": "OSUK8JPgRFVF"
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, Y_train = zip(*training)\n",
    "X_valid, Y_valid = zip(*validation)\n",
    "X_test, Y_test = zip(*test)\n",
    "\n",
    "X_train = np.array([x.reshape( (128, 853, 1) ) for x in X_train])\n",
    "X_valid = np.array([x.reshape( (128, 853, 1) ) for x in X_valid])\n",
    "X_test = np.array([x.reshape( (128, 853, 1) ) for x in X_test])\n",
    "\n",
    "\n",
    "Y_train = np.array(tfk.utils.to_categorical(Y_train, n_genres))\n",
    "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, n_genres))\n",
    "Y_test = np.array(tfk.utils.to_categorical(Y_test, n_genres))"
   ],
   "metadata": {
    "id": "WA29NV-URMuG"
   },
   "execution_count": 52,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
    "\n",
    "Optimization is performed as a Batch version of Adam optimizer algorithm"
   ],
   "metadata": {
    "id": "oaOErj4uktYn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def build_model(input_shape, n_units):\n",
    "# Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        name = 'conv_1',\n",
    "        filters=4,\n",
    "        kernel_size=(5, 5),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(input_layer)\n",
    "    conv1_2 = tfkl.Conv2D(\n",
    "        name = 'conv_1_2',\n",
    "        filters=8,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(conv1)\n",
    "    pool1 = tfkl.MaxPooling2D(\n",
    "        name = 'pool_1',\n",
    "        pool_size = (2, 2)\n",
    "    )(conv1_2)\n",
    "\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        name = 'conv_2',\n",
    "        filters=16,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool1)\n",
    "    conv2_2 = tfkl.Conv2D(\n",
    "        name = 'conv_2_2',\n",
    "        filters=16,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(conv2)\n",
    "    pool2 = tfkl.MaxPooling2D(\n",
    "        name = 'pool_2',\n",
    "        pool_size = (2, 2)\n",
    "    )(conv2_2)\n",
    "\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        name = 'conv_3',\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool2)\n",
    "    pool3 = tfkl.MaxPooling2D(\n",
    "        name = 'pool_3',\n",
    "        pool_size = (2, 2)\n",
    "    )(conv3)\n",
    "\n",
    "    conv4 = tfkl.Conv2D(\n",
    "        name = 'conv_4',\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool3)\n",
    "    pool4 = tfkl.MaxPooling2D(\n",
    "        name = 'pool_4',\n",
    "        pool_size = (2, 2)\n",
    "    )(conv4)\n",
    "\n",
    "    conv5 = tfkl.Conv2D(\n",
    "        name = 'conv_5',\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool4)\n",
    "    pool5 = tfkl.MaxPooling2D(\n",
    "        name = 'pool_5',\n",
    "        pool_size = (2, 2)\n",
    "    )(conv5)\n",
    "\n",
    "    conv6 = tfkl.Conv2D(\n",
    "        name = 'conv_6',\n",
    "        filters=286,\n",
    "        kernel_size=(1, 1),\n",
    "        strides = (1, 1),\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
    "    )(pool5)\n",
    "    \n",
    "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
    "    global_average = tfkl.Dropout(0.3, seed=seed, name = 'Dropout_GAP')(global_average)\n",
    "    \n",
    "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
    "    \n",
    "    classifier_layer = tfkl.Dropout(0.3, seed=seed, name = 'Dropout_Classifier')(classifier_layer)\n",
    "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
    "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed, name = 'Dropout_Classifier_2')(classifier_layer_2)\n",
    "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "id": "lR2QkBoSQ8lW"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_shape = (128, 853, 1)\n",
    "\n",
    "model = build_model(input_shape, n_genres)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "id": "zIitkAlGQ-mM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "96d44031-b9aa-4835-c5f8-b8838c0c80f4"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input (InputLayer)          [(None, 128, 853, 1)]     0         \n",
      "                                                                 \n",
      " conv_1 (Conv2D)             (None, 128, 853, 4)       104       \n",
      "                                                                 \n",
      " conv_1_2 (Conv2D)           (None, 128, 853, 8)       296       \n",
      "                                                                 \n",
      " pool_1 (MaxPooling2D)       (None, 64, 426, 8)        0         \n",
      "                                                                 \n",
      " conv_2 (Conv2D)             (None, 64, 426, 16)       1168      \n",
      "                                                                 \n",
      " conv_2_2 (Conv2D)           (None, 64, 426, 16)       2320      \n",
      "                                                                 \n",
      " pool_2 (MaxPooling2D)       (None, 32, 213, 16)       0         \n",
      "                                                                 \n",
      " conv_3 (Conv2D)             (None, 32, 213, 32)       4640      \n",
      "                                                                 \n",
      " pool_3 (MaxPooling2D)       (None, 16, 106, 32)       0         \n",
      "                                                                 \n",
      " conv_4 (Conv2D)             (None, 16, 106, 64)       18496     \n",
      "                                                                 \n",
      " pool_4 (MaxPooling2D)       (None, 8, 53, 64)         0         \n",
      "                                                                 \n",
      " conv_5 (Conv2D)             (None, 8, 53, 128)        73856     \n",
      "                                                                 \n",
      " pool_5 (MaxPooling2D)       (None, 4, 26, 128)        0         \n",
      "                                                                 \n",
      " conv_6 (Conv2D)             (None, 4, 26, 286)        36894     \n",
      "                                                                 \n",
      " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Dropout_GAP (Dropout)       (None, 286)               0         \n",
      "                                                                 \n",
      " Classifier (Dense)          (None, 64)                18368     \n",
      "                                                                 \n",
      " Dropout_Classifier (Dropout  (None, 64)               0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Classifier_2 (Dense)        (None, 32)                2080      \n",
      "                                                                 \n",
      " Dropout_Classifier_2 (Dropo  (None, 32)               0         \n",
      " ut)                                                             \n",
      "                                                                 \n",
      " Output (Dense)              (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 158,552\n",
      "Trainable params: 158,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
    "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
    "\n",
    "standard_history = model.fit(\n",
    "    x = X_train,\n",
    "    y = Y_train,\n",
    "    epochs = 500,\n",
    "    batch_size = 100,\n",
    "    validation_data= (X_valid, Y_valid),\n",
    "    callbacks = [early_stopping, adaptive_LR]\n",
    "    )"
   ],
   "metadata": {
    "id": "yFUsDY6BRWi1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "39a6f880-c3bc-4a14-c5ad-5cb308067757"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/500\n",
      "21/21 [==============================] - 20s 328ms/step - loss: 2.1290 - accuracy: 0.1943 - val_loss: 1.7001 - val_accuracy: 0.4450 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 6s 299ms/step - loss: 1.6313 - accuracy: 0.3767 - val_loss: 1.1207 - val_accuracy: 0.5150 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 6s 297ms/step - loss: 1.2825 - accuracy: 0.4876 - val_loss: 1.0419 - val_accuracy: 0.5883 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 6s 302ms/step - loss: 1.2047 - accuracy: 0.4814 - val_loss: 0.9445 - val_accuracy: 0.5567 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 6s 297ms/step - loss: 1.0998 - accuracy: 0.5214 - val_loss: 0.9572 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 6s 308ms/step - loss: 0.9856 - accuracy: 0.5576 - val_loss: 0.8144 - val_accuracy: 0.6250 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 6s 307ms/step - loss: 0.9171 - accuracy: 0.6090 - val_loss: 0.7109 - val_accuracy: 0.7200 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 6s 308ms/step - loss: 0.8499 - accuracy: 0.6500 - val_loss: 0.6402 - val_accuracy: 0.7750 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.7711 - accuracy: 0.6881 - val_loss: 0.6945 - val_accuracy: 0.7333 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 6s 305ms/step - loss: 0.7304 - accuracy: 0.7048 - val_loss: 0.5504 - val_accuracy: 0.8250 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 6s 310ms/step - loss: 0.6529 - accuracy: 0.7457 - val_loss: 0.5046 - val_accuracy: 0.8133 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.6336 - accuracy: 0.7490 - val_loss: 0.4707 - val_accuracy: 0.8117 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 7s 316ms/step - loss: 0.5676 - accuracy: 0.7800 - val_loss: 0.4371 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 7s 312ms/step - loss: 0.5382 - accuracy: 0.7952 - val_loss: 0.4241 - val_accuracy: 0.8417 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.4717 - accuracy: 0.8252 - val_loss: 0.3578 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.4534 - accuracy: 0.8419 - val_loss: 0.3493 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 7s 321ms/step - loss: 0.4011 - accuracy: 0.8605 - val_loss: 0.3489 - val_accuracy: 0.8683 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 7s 323ms/step - loss: 0.3663 - accuracy: 0.8671 - val_loss: 0.2746 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 7s 330ms/step - loss: 0.3270 - accuracy: 0.8938 - val_loss: 0.3866 - val_accuracy: 0.8483 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 7s 329ms/step - loss: 0.3170 - accuracy: 0.8981 - val_loss: 0.2468 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 7s 316ms/step - loss: 0.2253 - accuracy: 0.9286 - val_loss: 0.2156 - val_accuracy: 0.9367 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.2056 - accuracy: 0.9414 - val_loss: 0.2345 - val_accuracy: 0.9050 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 7s 313ms/step - loss: 0.2230 - accuracy: 0.9395 - val_loss: 0.2039 - val_accuracy: 0.9367 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 7s 317ms/step - loss: 0.2250 - accuracy: 0.9295 - val_loss: 0.2531 - val_accuracy: 0.9167 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 7s 317ms/step - loss: 0.2222 - accuracy: 0.9352 - val_loss: 0.2434 - val_accuracy: 0.9133 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 7s 316ms/step - loss: 0.2387 - accuracy: 0.9305 - val_loss: 0.2339 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 7s 322ms/step - loss: 0.1690 - accuracy: 0.9500 - val_loss: 0.1787 - val_accuracy: 0.9467 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 7s 323ms/step - loss: 0.2292 - accuracy: 0.9329 - val_loss: 0.1672 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 7s 323ms/step - loss: 0.1300 - accuracy: 0.9700 - val_loss: 0.1303 - val_accuracy: 0.9633 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 7s 323ms/step - loss: 0.1086 - accuracy: 0.9729 - val_loss: 0.1106 - val_accuracy: 0.9717 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 7s 325ms/step - loss: 0.1112 - accuracy: 0.9690 - val_loss: 0.1998 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 7s 316ms/step - loss: 0.0971 - accuracy: 0.9695 - val_loss: 0.1496 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 7s 320ms/step - loss: 0.0707 - accuracy: 0.9819 - val_loss: 0.1196 - val_accuracy: 0.9717 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 7s 320ms/step - loss: 0.0566 - accuracy: 0.9867 - val_loss: 0.0800 - val_accuracy: 0.9767 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 7s 317ms/step - loss: 0.0535 - accuracy: 0.9876 - val_loss: 0.0840 - val_accuracy: 0.9717 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 7s 321ms/step - loss: 0.0469 - accuracy: 0.9876 - val_loss: 0.0803 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 7s 321ms/step - loss: 0.0589 - accuracy: 0.9852 - val_loss: 0.2759 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 7s 330ms/step - loss: 0.0823 - accuracy: 0.9724 - val_loss: 0.0742 - val_accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 7s 332ms/step - loss: 0.0436 - accuracy: 0.9867 - val_loss: 0.1438 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 7s 318ms/step - loss: 0.0474 - accuracy: 0.9862 - val_loss: 0.2775 - val_accuracy: 0.9267 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 7s 321ms/step - loss: 0.1315 - accuracy: 0.9600 - val_loss: 0.1867 - val_accuracy: 0.9433 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 7s 320ms/step - loss: 0.0572 - accuracy: 0.9829 - val_loss: 0.0663 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 7s 318ms/step - loss: 0.0329 - accuracy: 0.9910 - val_loss: 0.0632 - val_accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0187 - accuracy: 0.9952 - val_loss: 0.0745 - val_accuracy: 0.9767 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.0940 - val_accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.0442 - accuracy: 0.9919 - val_loss: 0.1346 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.0521 - accuracy: 0.9876 - val_loss: 0.0875 - val_accuracy: 0.9783 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0302 - accuracy: 0.9938 - val_loss: 0.0624 - val_accuracy: 0.9867 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 7s 314ms/step - loss: 0.0213 - accuracy: 0.9952 - val_loss: 0.0760 - val_accuracy: 0.9867 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 7s 314ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 0.1432 - val_accuracy: 0.9733 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0401 - accuracy: 0.9914 - val_loss: 0.0995 - val_accuracy: 0.9800 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0461 - accuracy: 0.9919 - val_loss: 0.0661 - val_accuracy: 0.9867 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 7s 320ms/step - loss: 0.0500 - accuracy: 0.9848 - val_loss: 0.1082 - val_accuracy: 0.9633 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 7s 316ms/step - loss: 0.0266 - accuracy: 0.9924 - val_loss: 0.0540 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0096 - accuracy: 0.9981 - val_loss: 0.0640 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 7s 317ms/step - loss: 0.0074 - accuracy: 0.9990 - val_loss: 0.0756 - val_accuracy: 0.9867 - lr: 5.0000e-04\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 7s 313ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.1033 - val_accuracy: 0.9817 - lr: 5.0000e-04\n",
      "Epoch 58/500\n",
      "21/21 [==============================] - 7s 318ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0967 - val_accuracy: 0.9850 - lr: 5.0000e-04\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0972 - val_accuracy: 0.9817 - lr: 5.0000e-04\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0952 - val_accuracy: 0.9817 - lr: 2.5000e-04\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.1071 - val_accuracy: 0.9817 - lr: 2.5000e-04\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0929 - val_accuracy: 0.9817 - lr: 2.5000e-04\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0979 - val_accuracy: 0.9817 - lr: 2.5000e-04\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 7s 320ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0985 - val_accuracy: 0.9817 - lr: 2.5000e-04\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 7s 318ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0967 - val_accuracy: 0.9817 - lr: 1.2500e-04\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 7s 318ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0996 - val_accuracy: 0.9817 - lr: 1.2500e-04\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 7s 314ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9817 - lr: 1.2500e-04\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9817 - lr: 1.2500e-04\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 7s 319ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 0.9817 - lr: 1.2500e-04\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 7s 314ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0997 - val_accuracy: 0.9817 - lr: 1.0000e-04\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 7s 318ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1004 - val_accuracy: 0.9817 - lr: 1.0000e-04\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 7s 314ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1018 - val_accuracy: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 7s 315ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.1051 - val_accuracy: 0.9867 - lr: 1.0000e-04\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 7s 316ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9817 - lr: 1.0000e-04\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
    "\n",
    "# Compute the classification metrics\n",
    "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
    "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "print('Accuracy:',accuracy.round(4))\n",
    "print('Precision:',precision.round(4))\n",
    "print('Recall:',recall.round(4))\n",
    "print('F1:',f1.round(4))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "Opnhk9yA_Vt8",
    "outputId": "847ef3be-a416-48d2-d120-9199a7b82acc"
   },
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.99\n",
      "Precision: 0.9883\n",
      "Recall: 0.9881\n",
      "F1: 0.988\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/augmented/complete')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SO-HKBQc9I7r",
    "outputId": "4ac3aa99-cbc0-4ec4-c5eb-7b65a6ebf8d5"
   },
   "execution_count": 55,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/augmented/complete/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/augmented/complete/assets\n"
     ]
    }
   ]
  }
 ]
}