{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_CNN_complete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for all 10 genres classification\n",
        "\n",
        "We aim at training a Neural Network to distinguish between all the different genres"
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965db4f6-6738-45bf-b357-d7ed57fec460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16df26a-f851-43a2-8786-00008661db16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "WS4HjCWqkkUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, \n",
        "        'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=2)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5c795b3-a394-4ff8-dea2-482b6a99426a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blues done\n",
            "classical done\n",
            "country done\n",
            "disco done\n",
            "hiphop done\n",
            "jazz done\n",
            "metal done\n",
            "pop done\n",
            "reggae done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "FD5R_1cekn7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(10):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 173, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 173, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 173, 1) ) for x in X_test])\n",
        "\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, 10))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, 10))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, 10))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "oaOErj4uktYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    conv3_2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv3)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3_2)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(pool5)\n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.2, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.2, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_units = 10\n",
        "input_shape = (128,173,1)\n",
        "\n",
        "model = build_model(input_shape, n_units)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7431a0fc-011b-49b5-d6d2-98369ae8cba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 173, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_465 (Conv2D)         (None, 128, 173, 4)       40        \n",
            "                                                                 \n",
            " conv2d_466 (Conv2D)         (None, 128, 173, 8)       136       \n",
            "                                                                 \n",
            " max_pooling2d_273 (MaxPooli  (None, 64, 86, 8)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_467 (Conv2D)         (None, 64, 86, 16)        1168      \n",
            "                                                                 \n",
            " conv2d_468 (Conv2D)         (None, 64, 86, 16)        1040      \n",
            "                                                                 \n",
            " max_pooling2d_274 (MaxPooli  (None, 32, 43, 16)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_469 (Conv2D)         (None, 32, 43, 32)        2080      \n",
            "                                                                 \n",
            " conv2d_470 (Conv2D)         (None, 32, 43, 32)        4128      \n",
            "                                                                 \n",
            " max_pooling2d_275 (MaxPooli  (None, 16, 21, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_471 (Conv2D)         (None, 16, 21, 64)        8256      \n",
            "                                                                 \n",
            " conv2d_472 (Conv2D)         (None, 16, 21, 64)        16448     \n",
            "                                                                 \n",
            " max_pooling2d_276 (MaxPooli  (None, 8, 10, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_473 (Conv2D)         (None, 8, 10, 128)        32896     \n",
            "                                                                 \n",
            " max_pooling2d_277 (MaxPooli  (None, 4, 5, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 128)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76,858\n",
            "Trainable params: 76,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 100,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bd0a51-51bb-4dbd-a659-edbc20bb61ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 3s 335ms/step - loss: 2.3052 - accuracy: 0.0914 - val_loss: 2.2949 - val_accuracy: 0.1100 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 2.2951 - accuracy: 0.1157 - val_loss: 2.2859 - val_accuracy: 0.1250 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 2.2883 - accuracy: 0.1086 - val_loss: 2.2705 - val_accuracy: 0.1450 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 2.2685 - accuracy: 0.1371 - val_loss: 2.2373 - val_accuracy: 0.1650 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 2.2437 - accuracy: 0.1343 - val_loss: 2.1957 - val_accuracy: 0.1750 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 2.2267 - accuracy: 0.1586 - val_loss: 2.1949 - val_accuracy: 0.1950 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 2.2085 - accuracy: 0.1600 - val_loss: 2.1493 - val_accuracy: 0.2100 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 2.1861 - accuracy: 0.1614 - val_loss: 2.1075 - val_accuracy: 0.2150 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 2.1391 - accuracy: 0.1843 - val_loss: 2.0634 - val_accuracy: 0.2350 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 2.1336 - accuracy: 0.1900 - val_loss: 2.0300 - val_accuracy: 0.2300 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 2.0835 - accuracy: 0.2014 - val_loss: 2.0306 - val_accuracy: 0.2400 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 2.0703 - accuracy: 0.2300 - val_loss: 1.9826 - val_accuracy: 0.2450 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 2.0380 - accuracy: 0.2514 - val_loss: 1.9417 - val_accuracy: 0.2550 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.9792 - accuracy: 0.2557 - val_loss: 1.9040 - val_accuracy: 0.2600 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.9982 - accuracy: 0.2400 - val_loss: 1.9408 - val_accuracy: 0.2450 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.9657 - accuracy: 0.2514 - val_loss: 1.9219 - val_accuracy: 0.2700 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.9890 - accuracy: 0.2514 - val_loss: 1.9280 - val_accuracy: 0.2600 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.9749 - accuracy: 0.2543 - val_loss: 1.9660 - val_accuracy: 0.2900 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 1.9954 - accuracy: 0.2529 - val_loss: 1.9159 - val_accuracy: 0.2650 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.9351 - accuracy: 0.2714 - val_loss: 1.8430 - val_accuracy: 0.3050 - lr: 5.0000e-04\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 1.8918 - accuracy: 0.2986 - val_loss: 1.8218 - val_accuracy: 0.2650 - lr: 5.0000e-04\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.8532 - accuracy: 0.2943 - val_loss: 1.7983 - val_accuracy: 0.2950 - lr: 5.0000e-04\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.8303 - accuracy: 0.3143 - val_loss: 1.8274 - val_accuracy: 0.2650 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 1.8608 - accuracy: 0.3000 - val_loss: 1.8099 - val_accuracy: 0.2850 - lr: 5.0000e-04\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.8597 - accuracy: 0.2914 - val_loss: 1.7927 - val_accuracy: 0.2700 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 1.8291 - accuracy: 0.2971 - val_loss: 1.7815 - val_accuracy: 0.3300 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.8183 - accuracy: 0.3129 - val_loss: 1.7939 - val_accuracy: 0.2650 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 1.8072 - accuracy: 0.3229 - val_loss: 1.7499 - val_accuracy: 0.3250 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 1.7917 - accuracy: 0.3257 - val_loss: 1.7594 - val_accuracy: 0.2750 - lr: 5.0000e-04\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.7909 - accuracy: 0.3286 - val_loss: 1.7325 - val_accuracy: 0.3050 - lr: 5.0000e-04\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.7799 - accuracy: 0.3243 - val_loss: 1.7664 - val_accuracy: 0.3250 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.7796 - accuracy: 0.3314 - val_loss: 1.7380 - val_accuracy: 0.3150 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 1.7582 - accuracy: 0.3357 - val_loss: 1.7503 - val_accuracy: 0.3050 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.7579 - accuracy: 0.3086 - val_loss: 1.7306 - val_accuracy: 0.3150 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 1.7576 - accuracy: 0.3443 - val_loss: 1.7317 - val_accuracy: 0.3150 - lr: 5.0000e-04\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.7489 - accuracy: 0.3243 - val_loss: 1.7167 - val_accuracy: 0.3950 - lr: 5.0000e-04\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 1s 226ms/step - loss: 1.7572 - accuracy: 0.3400 - val_loss: 1.7481 - val_accuracy: 0.2750 - lr: 5.0000e-04\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.7423 - accuracy: 0.3543 - val_loss: 1.7173 - val_accuracy: 0.3900 - lr: 5.0000e-04\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.7153 - accuracy: 0.3814 - val_loss: 1.7206 - val_accuracy: 0.3250 - lr: 5.0000e-04\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.7280 - accuracy: 0.3529 - val_loss: 1.6901 - val_accuracy: 0.4050 - lr: 5.0000e-04\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.7138 - accuracy: 0.3671 - val_loss: 1.6960 - val_accuracy: 0.3600 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.7111 - accuracy: 0.3500 - val_loss: 1.6643 - val_accuracy: 0.3850 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 1s 224ms/step - loss: 1.7012 - accuracy: 0.4014 - val_loss: 1.6682 - val_accuracy: 0.3500 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 1.6938 - accuracy: 0.3886 - val_loss: 1.6691 - val_accuracy: 0.3300 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.6593 - accuracy: 0.3600 - val_loss: 1.6607 - val_accuracy: 0.4100 - lr: 5.0000e-04\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 1s 228ms/step - loss: 1.6760 - accuracy: 0.3729 - val_loss: 1.6516 - val_accuracy: 0.3850 - lr: 5.0000e-04\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.6523 - accuracy: 0.3900 - val_loss: 1.6714 - val_accuracy: 0.3500 - lr: 5.0000e-04\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.7027 - accuracy: 0.3929 - val_loss: 1.6415 - val_accuracy: 0.3900 - lr: 5.0000e-04\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 1.6633 - accuracy: 0.3714 - val_loss: 1.6539 - val_accuracy: 0.3950 - lr: 5.0000e-04\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 1.6995 - accuracy: 0.3857 - val_loss: 1.6735 - val_accuracy: 0.4000 - lr: 5.0000e-04\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.6852 - accuracy: 0.3800 - val_loss: 1.6540 - val_accuracy: 0.4250 - lr: 5.0000e-04\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.6679 - accuracy: 0.3643 - val_loss: 1.6137 - val_accuracy: 0.4250 - lr: 5.0000e-04\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 1.6629 - accuracy: 0.3929 - val_loss: 1.6209 - val_accuracy: 0.4000 - lr: 5.0000e-04\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 1s 227ms/step - loss: 1.6242 - accuracy: 0.4271 - val_loss: 1.6108 - val_accuracy: 0.4250 - lr: 5.0000e-04\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 1.6254 - accuracy: 0.4100 - val_loss: 1.6362 - val_accuracy: 0.3750 - lr: 5.0000e-04\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 1.6111 - accuracy: 0.3986 - val_loss: 1.5927 - val_accuracy: 0.4350 - lr: 5.0000e-04\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.6082 - accuracy: 0.4171 - val_loss: 1.5851 - val_accuracy: 0.4350 - lr: 5.0000e-04\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.5984 - accuracy: 0.4171 - val_loss: 1.6794 - val_accuracy: 0.4250 - lr: 5.0000e-04\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 1.6530 - accuracy: 0.4129 - val_loss: 1.6391 - val_accuracy: 0.4500 - lr: 5.0000e-04\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.6131 - accuracy: 0.4129 - val_loss: 1.6078 - val_accuracy: 0.4250 - lr: 5.0000e-04\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.6078 - accuracy: 0.4071 - val_loss: 1.6798 - val_accuracy: 0.3900 - lr: 5.0000e-04\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.6295 - accuracy: 0.4114 - val_loss: 1.6632 - val_accuracy: 0.4350 - lr: 5.0000e-04\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.6478 - accuracy: 0.4071 - val_loss: 1.5999 - val_accuracy: 0.4450 - lr: 2.5000e-04\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.5807 - accuracy: 0.4200 - val_loss: 1.5901 - val_accuracy: 0.4300 - lr: 2.5000e-04\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 1s 212ms/step - loss: 1.5477 - accuracy: 0.4557 - val_loss: 1.5932 - val_accuracy: 0.4450 - lr: 2.5000e-04\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.5705 - accuracy: 0.4286 - val_loss: 1.5719 - val_accuracy: 0.4250 - lr: 2.5000e-04\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.5348 - accuracy: 0.4486 - val_loss: 1.5442 - val_accuracy: 0.4400 - lr: 2.5000e-04\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.5067 - accuracy: 0.4486 - val_loss: 1.5522 - val_accuracy: 0.4300 - lr: 2.5000e-04\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 1.5302 - accuracy: 0.4457 - val_loss: 1.5494 - val_accuracy: 0.4500 - lr: 2.5000e-04\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.5270 - accuracy: 0.4543 - val_loss: 1.5379 - val_accuracy: 0.4400 - lr: 2.5000e-04\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.4714 - accuracy: 0.4757 - val_loss: 1.5218 - val_accuracy: 0.4450 - lr: 2.5000e-04\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.4857 - accuracy: 0.4786 - val_loss: 1.5160 - val_accuracy: 0.4600 - lr: 2.5000e-04\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.4743 - accuracy: 0.4757 - val_loss: 1.5245 - val_accuracy: 0.4500 - lr: 2.5000e-04\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.4810 - accuracy: 0.4400 - val_loss: 1.5374 - val_accuracy: 0.4650 - lr: 2.5000e-04\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 1s 223ms/step - loss: 1.5326 - accuracy: 0.4386 - val_loss: 1.5226 - val_accuracy: 0.4550 - lr: 2.5000e-04\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.4874 - accuracy: 0.4500 - val_loss: 1.5225 - val_accuracy: 0.4350 - lr: 2.5000e-04\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 1.4855 - accuracy: 0.4643 - val_loss: 1.5107 - val_accuracy: 0.4650 - lr: 2.5000e-04\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.4547 - accuracy: 0.5157 - val_loss: 1.5204 - val_accuracy: 0.4400 - lr: 2.5000e-04\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.4935 - accuracy: 0.4729 - val_loss: 1.5272 - val_accuracy: 0.4750 - lr: 2.5000e-04\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.5088 - accuracy: 0.4586 - val_loss: 1.5148 - val_accuracy: 0.4600 - lr: 2.5000e-04\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.4755 - accuracy: 0.4486 - val_loss: 1.5230 - val_accuracy: 0.4450 - lr: 2.5000e-04\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.4745 - accuracy: 0.4757 - val_loss: 1.5068 - val_accuracy: 0.4650 - lr: 2.5000e-04\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.5186 - accuracy: 0.4600 - val_loss: 1.5157 - val_accuracy: 0.4550 - lr: 2.5000e-04\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.4431 - accuracy: 0.4800 - val_loss: 1.4938 - val_accuracy: 0.4750 - lr: 2.5000e-04\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 1.4607 - accuracy: 0.4871 - val_loss: 1.5106 - val_accuracy: 0.4500 - lr: 2.5000e-04\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 1s 199ms/step - loss: 1.4786 - accuracy: 0.4386 - val_loss: 1.4986 - val_accuracy: 0.4900 - lr: 2.5000e-04\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.4788 - accuracy: 0.4643 - val_loss: 1.5216 - val_accuracy: 0.4300 - lr: 2.5000e-04\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.4281 - accuracy: 0.4686 - val_loss: 1.5007 - val_accuracy: 0.5050 - lr: 2.5000e-04\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.4139 - accuracy: 0.5043 - val_loss: 1.5015 - val_accuracy: 0.4700 - lr: 2.5000e-04\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.4360 - accuracy: 0.4829 - val_loss: 1.5019 - val_accuracy: 0.4550 - lr: 1.2500e-04\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.4142 - accuracy: 0.4886 - val_loss: 1.4883 - val_accuracy: 0.4950 - lr: 1.2500e-04\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 1s 215ms/step - loss: 1.4277 - accuracy: 0.4900 - val_loss: 1.4862 - val_accuracy: 0.4850 - lr: 1.2500e-04\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 1s 240ms/step - loss: 1.4421 - accuracy: 0.4757 - val_loss: 1.4789 - val_accuracy: 0.4750 - lr: 1.2500e-04\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 1s 208ms/step - loss: 1.4032 - accuracy: 0.4957 - val_loss: 1.4755 - val_accuracy: 0.4800 - lr: 1.2500e-04\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 1s 225ms/step - loss: 1.3597 - accuracy: 0.5214 - val_loss: 1.4636 - val_accuracy: 0.4800 - lr: 1.2500e-04\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.3907 - accuracy: 0.4843 - val_loss: 1.4629 - val_accuracy: 0.4750 - lr: 1.2500e-04\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3763 - accuracy: 0.5214 - val_loss: 1.4640 - val_accuracy: 0.4700 - lr: 1.2500e-04\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 1s 234ms/step - loss: 1.4349 - accuracy: 0.5071 - val_loss: 1.4576 - val_accuracy: 0.4900 - lr: 1.2500e-04\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 1.3702 - accuracy: 0.5171 - val_loss: 1.4690 - val_accuracy: 0.4600 - lr: 1.2500e-04\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 1s 248ms/step - loss: 1.4097 - accuracy: 0.4871 - val_loss: 1.4618 - val_accuracy: 0.4700 - lr: 1.2500e-04\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.3769 - accuracy: 0.5229 - val_loss: 1.4615 - val_accuracy: 0.4800 - lr: 1.2500e-04\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.3970 - accuracy: 0.4957 - val_loss: 1.4715 - val_accuracy: 0.4650 - lr: 1.2500e-04\n",
            "Epoch 103/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.3860 - accuracy: 0.5157 - val_loss: 1.4524 - val_accuracy: 0.5000 - lr: 1.2500e-04\n",
            "Epoch 104/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.3650 - accuracy: 0.5214 - val_loss: 1.4555 - val_accuracy: 0.5100 - lr: 1.2500e-04\n",
            "Epoch 105/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3865 - accuracy: 0.5186 - val_loss: 1.4714 - val_accuracy: 0.4700 - lr: 1.2500e-04\n",
            "Epoch 106/500\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 1.3634 - accuracy: 0.5114 - val_loss: 1.4566 - val_accuracy: 0.4950 - lr: 1.2500e-04\n",
            "Epoch 107/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.3687 - accuracy: 0.5186 - val_loss: 1.4508 - val_accuracy: 0.4950 - lr: 1.2500e-04\n",
            "Epoch 108/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.3544 - accuracy: 0.5229 - val_loss: 1.4588 - val_accuracy: 0.4800 - lr: 1.2500e-04\n",
            "Epoch 109/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.3331 - accuracy: 0.5229 - val_loss: 1.4511 - val_accuracy: 0.4950 - lr: 1.2500e-04\n",
            "Epoch 110/500\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 1.3370 - accuracy: 0.5157 - val_loss: 1.4510 - val_accuracy: 0.4950 - lr: 1.2500e-04\n",
            "Epoch 111/500\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 1.3522 - accuracy: 0.5300 - val_loss: 1.4590 - val_accuracy: 0.4900 - lr: 1.2500e-04\n",
            "Epoch 112/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.3711 - accuracy: 0.5057 - val_loss: 1.4539 - val_accuracy: 0.5050 - lr: 1.2500e-04\n",
            "Epoch 113/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.3669 - accuracy: 0.5100 - val_loss: 1.4476 - val_accuracy: 0.5050 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "4/4 [==============================] - 1s 197ms/step - loss: 1.3628 - accuracy: 0.5143 - val_loss: 1.4500 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3419 - accuracy: 0.5357 - val_loss: 1.4465 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.2986 - accuracy: 0.5371 - val_loss: 1.4447 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3307 - accuracy: 0.5086 - val_loss: 1.4452 - val_accuracy: 0.5050 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "4/4 [==============================] - 1s 198ms/step - loss: 1.3137 - accuracy: 0.5171 - val_loss: 1.4479 - val_accuracy: 0.4950 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.3562 - accuracy: 0.5186 - val_loss: 1.4493 - val_accuracy: 0.4900 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.3099 - accuracy: 0.5414 - val_loss: 1.4395 - val_accuracy: 0.5150 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 1.3264 - accuracy: 0.5257 - val_loss: 1.4329 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "4/4 [==============================] - 1s 206ms/step - loss: 1.3119 - accuracy: 0.5586 - val_loss: 1.4376 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.3376 - accuracy: 0.5357 - val_loss: 1.4410 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.3005 - accuracy: 0.5257 - val_loss: 1.4372 - val_accuracy: 0.4900 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3172 - accuracy: 0.5300 - val_loss: 1.4478 - val_accuracy: 0.5050 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.3074 - accuracy: 0.5429 - val_loss: 1.4482 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.3156 - accuracy: 0.5257 - val_loss: 1.4604 - val_accuracy: 0.4950 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3304 - accuracy: 0.5300 - val_loss: 1.4467 - val_accuracy: 0.4850 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.3098 - accuracy: 0.5400 - val_loss: 1.4402 - val_accuracy: 0.5050 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3032 - accuracy: 0.5557 - val_loss: 1.4447 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3266 - accuracy: 0.5343 - val_loss: 1.4441 - val_accuracy: 0.4850 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "4/4 [==============================] - 1s 196ms/step - loss: 1.3126 - accuracy: 0.5343 - val_loss: 1.4429 - val_accuracy: 0.4850 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "4/4 [==============================] - 1s 201ms/step - loss: 1.3130 - accuracy: 0.5314 - val_loss: 1.4491 - val_accuracy: 0.4700 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.3030 - accuracy: 0.5529 - val_loss: 1.4418 - val_accuracy: 0.4900 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "4/4 [==============================] - 1s 202ms/step - loss: 1.3024 - accuracy: 0.5386 - val_loss: 1.4427 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "4/4 [==============================] - 1s 204ms/step - loss: 1.2875 - accuracy: 0.5400 - val_loss: 1.4499 - val_accuracy: 0.4950 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.2868 - accuracy: 0.5400 - val_loss: 1.4395 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.2762 - accuracy: 0.5657 - val_loss: 1.4506 - val_accuracy: 0.4750 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "4/4 [==============================] - 1s 203ms/step - loss: 1.2934 - accuracy: 0.5471 - val_loss: 1.4376 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "4/4 [==============================] - 1s 200ms/step - loss: 1.2932 - accuracy: 0.5443 - val_loss: 1.4412 - val_accuracy: 0.5050 - lr: 1.0000e-04\n",
            "Epoch 141/500\n",
            "4/4 [==============================] - 1s 205ms/step - loss: 1.2574 - accuracy: 0.5543 - val_loss: 1.4477 - val_accuracy: 0.4950 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "3dde738f-116c-48f4-f214-c492eab3f316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6\n",
            "Precision: 0.5962\n",
            "Recall: 0.6\n",
            "F1: 0.5877\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/complete/first3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "122384ac-b546-4db0-fff9-6300a7bf3982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/complete/first3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/complete/first3/assets\n"
          ]
        }
      ]
    }
  ]
}