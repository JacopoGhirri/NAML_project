{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_rock_metal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for 2 genres classification - Rock vs Metal\n",
        "\n",
        "We aim at training a Neural Network to distinguish between two genres: rock and metal."
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a82379-4f57-4d05-8a04-55a2e0bd979c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c26aa72-dd92-489a-9b55-a1998d6f580f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "IoV9bIbPfg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "#genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "genres = {'metal': 0, 'rock': 1}\n",
        "n_genres = 2\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16608b0-ef06-4280-ec93-d15cb8219134"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metal done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "0sgOQfv-gZ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(seed)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(n_genres):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, n_genres))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, n_genres))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, n_genres))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "O6AvTMw2hgxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        name = 'conv_1',\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        name = 'conv_1_2',\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        name = 'pool_1',\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        name = 'conv_2',\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        name = 'pool_2',\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        name = 'conv_3',\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        name = 'pool_3',\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        name = 'conv_4',\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        name = 'pool_4',\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        name = 'conv_5',\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        name = 'pool_5',\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        name = 'conv_6',\n",
        "        filters=256,\n",
        "        kernel_size=(1, 1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed, name = 'Dropout_GAP')(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed, name = 'Dropout_Classifier')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.25, seed=seed, name = 'Dropout_Classifier_2')(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, n_genres)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52085599-e22a-4c4f-a8b7-39154393ba18"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv_1 (Conv2D)             (None, 128, 2559, 4)      104       \n",
            "                                                                 \n",
            " conv_1_2 (Conv2D)           (None, 128, 2559, 8)      296       \n",
            "                                                                 \n",
            " pool_1 (MaxPooling2D)       (None, 64, 1279, 8)       0         \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, 64, 1279, 16)      1168      \n",
            "                                                                 \n",
            " pool_2 (MaxPooling2D)       (None, 32, 639, 16)       0         \n",
            "                                                                 \n",
            " conv_3 (Conv2D)             (None, 32, 639, 32)       4640      \n",
            "                                                                 \n",
            " pool_3 (MaxPooling2D)       (None, 16, 319, 32)       0         \n",
            "                                                                 \n",
            " conv_4 (Conv2D)             (None, 16, 319, 64)       18496     \n",
            "                                                                 \n",
            " pool_4 (MaxPooling2D)       (None, 8, 159, 64)        0         \n",
            "                                                                 \n",
            " conv_5 (Conv2D)             (None, 8, 159, 128)       73856     \n",
            "                                                                 \n",
            " pool_5 (MaxPooling2D)       (None, 4, 79, 128)        0         \n",
            "                                                                 \n",
            " conv_6 (Conv2D)             (None, 4, 79, 256)        33024     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 256)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Dropout_GAP (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                16448     \n",
            "                                                                 \n",
            " Dropout_Classifier (Dropout  (None, 64)               0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " Dropout_Classifier_2 (Dropo  (None, 32)               0         \n",
            " ut)                                                             \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 150,178\n",
            "Trainable params: 150,178\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 20,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de924e8b-f1e7-416b-c667-991e46c91854"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "7/7 [==============================] - 3s 310ms/step - loss: 0.8291 - accuracy: 0.4500 - val_loss: 0.6934 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.7291 - accuracy: 0.5143 - val_loss: 0.6913 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.6996 - accuracy: 0.4643 - val_loss: 0.6931 - val_accuracy: 0.4750 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.6945 - accuracy: 0.4857 - val_loss: 0.6940 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "7/7 [==============================] - 2s 233ms/step - loss: 0.6935 - accuracy: 0.5214 - val_loss: 0.6938 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.6926 - accuracy: 0.4714 - val_loss: 0.6924 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "7/7 [==============================] - 2s 236ms/step - loss: 0.6908 - accuracy: 0.4714 - val_loss: 0.6905 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "7/7 [==============================] - 2s 257ms/step - loss: 0.6921 - accuracy: 0.4929 - val_loss: 0.6864 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.6871 - accuracy: 0.5643 - val_loss: 0.6765 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.6799 - accuracy: 0.5714 - val_loss: 0.6771 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "7/7 [==============================] - 2s 233ms/step - loss: 0.6847 - accuracy: 0.5786 - val_loss: 0.6825 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.6709 - accuracy: 0.5929 - val_loss: 0.6739 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.6395 - accuracy: 0.6214 - val_loss: 0.6715 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "7/7 [==============================] - 2s 232ms/step - loss: 0.6466 - accuracy: 0.6643 - val_loss: 0.7210 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.6150 - accuracy: 0.7143 - val_loss: 0.6736 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "7/7 [==============================] - 2s 259ms/step - loss: 0.5869 - accuracy: 0.6643 - val_loss: 0.6281 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.4689 - accuracy: 0.8071 - val_loss: 0.6068 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "7/7 [==============================] - 2s 233ms/step - loss: 0.4303 - accuracy: 0.8143 - val_loss: 0.7154 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.3140 - accuracy: 0.8714 - val_loss: 0.3989 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "7/7 [==============================] - 2s 231ms/step - loss: 0.4711 - accuracy: 0.7929 - val_loss: 0.6617 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "7/7 [==============================] - 2s 233ms/step - loss: 0.3968 - accuracy: 0.8214 - val_loss: 0.4008 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "7/7 [==============================] - 2s 249ms/step - loss: 0.3205 - accuracy: 0.8929 - val_loss: 0.4193 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "7/7 [==============================] - 2s 239ms/step - loss: 0.2890 - accuracy: 0.8857 - val_loss: 0.4282 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "7/7 [==============================] - 2s 233ms/step - loss: 0.2453 - accuracy: 0.9214 - val_loss: 0.4446 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.2128 - accuracy: 0.9143 - val_loss: 0.4340 - val_accuracy: 0.8250 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.2070 - accuracy: 0.9071 - val_loss: 0.4677 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.2541 - accuracy: 0.8857 - val_loss: 0.6009 - val_accuracy: 0.7750 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "7/7 [==============================] - 2s 232ms/step - loss: 0.3096 - accuracy: 0.9071 - val_loss: 0.4320 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "7/7 [==============================] - 2s 236ms/step - loss: 0.2327 - accuracy: 0.9000 - val_loss: 0.3959 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 30/500\n",
            "7/7 [==============================] - 2s 232ms/step - loss: 0.2104 - accuracy: 0.9071 - val_loss: 0.6407 - val_accuracy: 0.8250 - lr: 5.0000e-04\n",
            "Epoch 31/500\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.2261 - accuracy: 0.9071 - val_loss: 0.4029 - val_accuracy: 0.8250 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.1532 - accuracy: 0.9643 - val_loss: 0.5394 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.1771 - accuracy: 0.9143 - val_loss: 0.5083 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "7/7 [==============================] - 2s 259ms/step - loss: 0.1727 - accuracy: 0.9286 - val_loss: 0.6191 - val_accuracy: 0.7750 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "7/7 [==============================] - 2s 236ms/step - loss: 0.2018 - accuracy: 0.9429 - val_loss: 0.4864 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 36/500\n",
            "7/7 [==============================] - 2s 258ms/step - loss: 0.1855 - accuracy: 0.9143 - val_loss: 0.5870 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 37/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.1718 - accuracy: 0.9214 - val_loss: 0.5017 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 38/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.1700 - accuracy: 0.9214 - val_loss: 0.5820 - val_accuracy: 0.8250 - lr: 2.5000e-04\n",
            "Epoch 39/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.1236 - accuracy: 0.9571 - val_loss: 0.4822 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 40/500\n",
            "7/7 [==============================] - 2s 231ms/step - loss: 0.1171 - accuracy: 0.9571 - val_loss: 0.5370 - val_accuracy: 0.8250 - lr: 1.2500e-04\n",
            "Epoch 41/500\n",
            "7/7 [==============================] - 2s 256ms/step - loss: 0.1199 - accuracy: 0.9429 - val_loss: 0.5437 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 42/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.1077 - accuracy: 0.9429 - val_loss: 0.5292 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 43/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.1355 - accuracy: 0.9500 - val_loss: 0.5655 - val_accuracy: 0.8250 - lr: 1.2500e-04\n",
            "Epoch 44/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.1361 - accuracy: 0.9357 - val_loss: 0.5306 - val_accuracy: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 45/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.1236 - accuracy: 0.9571 - val_loss: 0.5308 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 46/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.1166 - accuracy: 0.9500 - val_loss: 0.6193 - val_accuracy: 0.8250 - lr: 1.0000e-04\n",
            "Epoch 47/500\n",
            "7/7 [==============================] - 2s 234ms/step - loss: 0.1027 - accuracy: 0.9643 - val_loss: 0.5337 - val_accuracy: 0.8250 - lr: 1.0000e-04\n",
            "Epoch 48/500\n",
            "7/7 [==============================] - 2s 233ms/step - loss: 0.1715 - accuracy: 0.9286 - val_loss: 0.5723 - val_accuracy: 0.8250 - lr: 1.0000e-04\n",
            "Epoch 49/500\n",
            "7/7 [==============================] - 2s 235ms/step - loss: 0.1362 - accuracy: 0.9286 - val_loss: 0.6138 - val_accuracy: 0.8250 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "fa211402-7706-42ec-e998-aa0e383c7264"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Precision: 0.9167\n",
            "Recall: 0.9\n",
            "F1: 0.899\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/rockvmetal/rockvmetal')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "996d8645-979c-4af8-bb0b-e04d6a1d8a8b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/rockvmetal/rockvmetal/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/rockvmetal/rockvmetal/assets\n"
          ]
        }
      ]
    }
  ]
}