{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_country_blues.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for 2 genres classification - Country vs Blues\n",
        "\n",
        "We aim at training a Neural Network to distinguish between two genres: country and blues."
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1977be38-b57c-433d-eff3-18f9f8b75feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed1ade7-ba8c-4043-cbff-a3e54ae6d3ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "IoV9bIbPfg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "#genres = {'country': 0, 'blues': 1}\n",
        "\n",
        "y_r, sr_r = librosa.load('dataset_old/genres/blues/blues.00000.wav', mono=True, duration=29.7)\n",
        "ps_r = librosa.feature.melspectrogram(y=y_r, sr=sr_r, hop_length = 256, n_fft = 512)\n",
        "ps_r = librosa.power_to_db(ps_r**2)\n",
        "     \n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "        if ps.shape != ps_r.shape:\n",
        "          print(songname)\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pu8r54LJMSj",
        "outputId": "55154a11-6745-42fc-8153-973155b441f0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blues done\n",
            "classical done\n",
            "country done\n",
            "disco done\n",
            "hiphop done\n",
            "jazz done\n",
            "metal done\n",
            "pop done\n",
            "reggae done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "#genres = {'country': 0, 'blues': 1}\n",
        "\n",
        "y_r, sr_r = librosa.load('dataset_old/genres/blues/blues.00000.wav', mono=True, duration=30)\n",
        "ps_r = librosa.feature.melspectrogram(y=y_r, sr=sr_r, hop_length = 256, n_fft = 512)\n",
        "ps_r = librosa.power_to_db(ps_r**2)\n",
        "        \n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=30)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "        if len(y) != len(y_r) or sr_r != sr:\n",
        "          print(songname)\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed37e78a-c807-4be3-b9c7-7e8c22c19b50"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blues done\n",
            "dataset_old/genres/classical/classical.00051.wav\n",
            "dataset_old/genres/classical/classical.00049.wav\n",
            "classical done\n",
            "dataset_old/genres/country/country.00004.wav\n",
            "dataset_old/genres/country/country.00007.wav\n",
            "dataset_old/genres/country/country.00003.wav\n",
            "country done\n",
            "dataset_old/genres/disco/disco.00014.wav\n",
            "disco done\n",
            "dataset_old/genres/hiphop/hiphop.00032.wav\n",
            "dataset_old/genres/hiphop/hiphop.00031.wav\n",
            "hiphop done\n",
            "jazz done\n",
            "metal done\n",
            "pop done\n",
            "reggae done\n",
            "dataset_old/genres/rock/rock.00038.wav\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "0sgOQfv-gZ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(10):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNsfoewZARn8",
        "outputId": "df6894f7-87a3-4ae9-b84a-4cea5267e405"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 2559)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, 10))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, 10))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, 10))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "O6AvTMw2hgxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_units = 2\n",
        "input_shape = (128,2498,1)\n",
        "\n",
        "model = build_model(input_shape, n_units)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c928b5c-7b31-4da5-820b-41713e53e438"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2498, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 128, 2498, 4)      104       \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 128, 2498, 8)      296       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 64, 1249, 8)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 64, 1249, 16)      1168      \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 64, 1249, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 32, 624, 16)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 32, 624, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 16, 312, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 16, 312, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 16, 312, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 8, 156, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 8, 156, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 4, 78, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 4, 78, 286)        36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,216\n",
            "Trainable params: 195,216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 20,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b83b056-0a05-4813-a6cc-ad11e449a75c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "7/7 [==============================] - 4s 362ms/step - loss: 0.7369 - accuracy: 0.4643 - val_loss: 0.6930 - val_accuracy: 0.4750 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "7/7 [==============================] - 2s 334ms/step - loss: 0.6844 - accuracy: 0.5643 - val_loss: 0.6928 - val_accuracy: 0.5250 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.7030 - accuracy: 0.5071 - val_loss: 0.6914 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "7/7 [==============================] - 2s 317ms/step - loss: 0.6947 - accuracy: 0.4857 - val_loss: 0.6914 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.6976 - accuracy: 0.4571 - val_loss: 0.6925 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "7/7 [==============================] - 2s 330ms/step - loss: 0.6919 - accuracy: 0.5214 - val_loss: 0.6915 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.6950 - accuracy: 0.5357 - val_loss: 0.6876 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.6932 - accuracy: 0.4857 - val_loss: 0.6899 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.6969 - accuracy: 0.4929 - val_loss: 0.6912 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "7/7 [==============================] - 2s 329ms/step - loss: 0.6938 - accuracy: 0.5143 - val_loss: 0.6914 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.6942 - accuracy: 0.4857 - val_loss: 0.6914 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.6920 - accuracy: 0.5286 - val_loss: 0.6902 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.6947 - accuracy: 0.5000 - val_loss: 0.6897 - val_accuracy: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 14/500\n",
            "7/7 [==============================] - 2s 317ms/step - loss: 0.6936 - accuracy: 0.5357 - val_loss: 0.6888 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 15/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.6941 - accuracy: 0.4857 - val_loss: 0.6902 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 16/500\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.6917 - accuracy: 0.5500 - val_loss: 0.6897 - val_accuracy: 0.7750 - lr: 5.0000e-04\n",
            "Epoch 17/500\n",
            "7/7 [==============================] - 2s 329ms/step - loss: 0.6887 - accuracy: 0.5929 - val_loss: 0.6857 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 18/500\n",
            "7/7 [==============================] - 2s 331ms/step - loss: 0.6877 - accuracy: 0.5429 - val_loss: 0.6830 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 19/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.6956 - accuracy: 0.4786 - val_loss: 0.6874 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 20/500\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.6888 - accuracy: 0.5857 - val_loss: 0.6911 - val_accuracy: 0.5250 - lr: 5.0000e-04\n",
            "Epoch 21/500\n",
            "7/7 [==============================] - 2s 329ms/step - loss: 0.6879 - accuracy: 0.6143 - val_loss: 0.6798 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 22/500\n",
            "7/7 [==============================] - 2s 333ms/step - loss: 0.6871 - accuracy: 0.6000 - val_loss: 0.6776 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 23/500\n",
            "7/7 [==============================] - 2s 330ms/step - loss: 0.6766 - accuracy: 0.5857 - val_loss: 0.6631 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.6745 - accuracy: 0.5571 - val_loss: 0.6857 - val_accuracy: 0.5500 - lr: 5.0000e-04\n",
            "Epoch 25/500\n",
            "7/7 [==============================] - 2s 327ms/step - loss: 0.6935 - accuracy: 0.5071 - val_loss: 0.6930 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "7/7 [==============================] - 2s 326ms/step - loss: 0.6905 - accuracy: 0.5714 - val_loss: 0.6814 - val_accuracy: 0.7250 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "7/7 [==============================] - 2s 325ms/step - loss: 0.6759 - accuracy: 0.6000 - val_loss: 0.6680 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "7/7 [==============================] - 2s 328ms/step - loss: 0.6805 - accuracy: 0.5214 - val_loss: 0.6639 - val_accuracy: 0.5000 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.6692 - accuracy: 0.5714 - val_loss: 0.6642 - val_accuracy: 0.5500 - lr: 2.5000e-04\n",
            "Epoch 30/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.6701 - accuracy: 0.5571 - val_loss: 0.6612 - val_accuracy: 0.7000 - lr: 2.5000e-04\n",
            "Epoch 31/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.6496 - accuracy: 0.6357 - val_loss: 0.6492 - val_accuracy: 0.5500 - lr: 2.5000e-04\n",
            "Epoch 32/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.6620 - accuracy: 0.5929 - val_loss: 0.6459 - val_accuracy: 0.7250 - lr: 2.5000e-04\n",
            "Epoch 33/500\n",
            "7/7 [==============================] - 2s 311ms/step - loss: 0.6468 - accuracy: 0.7143 - val_loss: 0.6340 - val_accuracy: 0.7750 - lr: 2.5000e-04\n",
            "Epoch 34/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.6197 - accuracy: 0.7214 - val_loss: 0.6224 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 35/500\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.6137 - accuracy: 0.7357 - val_loss: 0.6029 - val_accuracy: 0.7500 - lr: 2.5000e-04\n",
            "Epoch 36/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.5857 - accuracy: 0.7429 - val_loss: 0.6181 - val_accuracy: 0.7000 - lr: 2.5000e-04\n",
            "Epoch 37/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.6111 - accuracy: 0.7000 - val_loss: 0.6362 - val_accuracy: 0.6750 - lr: 2.5000e-04\n",
            "Epoch 38/500\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.5609 - accuracy: 0.7429 - val_loss: 0.5379 - val_accuracy: 0.8250 - lr: 2.5000e-04\n",
            "Epoch 39/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.5424 - accuracy: 0.7357 - val_loss: 0.5140 - val_accuracy: 0.8250 - lr: 2.5000e-04\n",
            "Epoch 40/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.5037 - accuracy: 0.8071 - val_loss: 0.4821 - val_accuracy: 0.8250 - lr: 2.5000e-04\n",
            "Epoch 41/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.4719 - accuracy: 0.7857 - val_loss: 0.4704 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 42/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.5009 - accuracy: 0.8071 - val_loss: 0.8544 - val_accuracy: 0.5750 - lr: 2.5000e-04\n",
            "Epoch 43/500\n",
            "7/7 [==============================] - 2s 328ms/step - loss: 0.5333 - accuracy: 0.7286 - val_loss: 0.5299 - val_accuracy: 0.7500 - lr: 2.5000e-04\n",
            "Epoch 44/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.5157 - accuracy: 0.7357 - val_loss: 0.4781 - val_accuracy: 0.8250 - lr: 2.5000e-04\n",
            "Epoch 45/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.4838 - accuracy: 0.7929 - val_loss: 0.4652 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 46/500\n",
            "7/7 [==============================] - 2s 333ms/step - loss: 0.4450 - accuracy: 0.7929 - val_loss: 0.4378 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 47/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.4097 - accuracy: 0.8143 - val_loss: 0.4189 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 48/500\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.4209 - accuracy: 0.8143 - val_loss: 0.4643 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 49/500\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.4325 - accuracy: 0.8143 - val_loss: 0.3464 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 50/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.3369 - accuracy: 0.8429 - val_loss: 0.3569 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 51/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.4024 - accuracy: 0.8143 - val_loss: 0.4034 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 52/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.3352 - accuracy: 0.8643 - val_loss: 0.4410 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 53/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.3364 - accuracy: 0.8500 - val_loss: 0.3961 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 54/500\n",
            "7/7 [==============================] - 2s 331ms/step - loss: 0.3267 - accuracy: 0.8571 - val_loss: 0.2870 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 55/500\n",
            "7/7 [==============================] - 2s 328ms/step - loss: 0.3553 - accuracy: 0.8643 - val_loss: 0.3904 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 56/500\n",
            "7/7 [==============================] - 2s 329ms/step - loss: 0.2835 - accuracy: 0.8857 - val_loss: 0.4066 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 57/500\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.2591 - accuracy: 0.9071 - val_loss: 0.2634 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 58/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.3864 - accuracy: 0.8071 - val_loss: 0.2906 - val_accuracy: 0.8250 - lr: 2.5000e-04\n",
            "Epoch 59/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.3914 - accuracy: 0.8357 - val_loss: 0.3531 - val_accuracy: 0.7750 - lr: 2.5000e-04\n",
            "Epoch 60/500\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.3591 - accuracy: 0.8571 - val_loss: 0.5272 - val_accuracy: 0.8250 - lr: 2.5000e-04\n",
            "Epoch 61/500\n",
            "7/7 [==============================] - 2s 331ms/step - loss: 0.3276 - accuracy: 0.8714 - val_loss: 0.2590 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 62/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.2469 - accuracy: 0.8929 - val_loss: 0.3361 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 63/500\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.2504 - accuracy: 0.8857 - val_loss: 0.3044 - val_accuracy: 0.8250 - lr: 2.5000e-04\n",
            "Epoch 64/500\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.3503 - accuracy: 0.8429 - val_loss: 0.3741 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 65/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.2635 - accuracy: 0.8714 - val_loss: 0.4441 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 66/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.2756 - accuracy: 0.9000 - val_loss: 0.3061 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 67/500\n",
            "7/7 [==============================] - 2s 328ms/step - loss: 0.2492 - accuracy: 0.8643 - val_loss: 0.5069 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 68/500\n",
            "7/7 [==============================] - 2s 330ms/step - loss: 0.2170 - accuracy: 0.9000 - val_loss: 0.2663 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 69/500\n",
            "7/7 [==============================] - 2s 317ms/step - loss: 0.2246 - accuracy: 0.9214 - val_loss: 0.4107 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 70/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.2484 - accuracy: 0.9143 - val_loss: 0.2548 - val_accuracy: 0.9250 - lr: 1.2500e-04\n",
            "Epoch 71/500\n",
            "7/7 [==============================] - 2s 311ms/step - loss: 0.1857 - accuracy: 0.9286 - val_loss: 0.3521 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 72/500\n",
            "7/7 [==============================] - 2s 332ms/step - loss: 0.2538 - accuracy: 0.9071 - val_loss: 0.3050 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 73/500\n",
            "7/7 [==============================] - 2s 331ms/step - loss: 0.3289 - accuracy: 0.8500 - val_loss: 0.2531 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 74/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.2013 - accuracy: 0.9357 - val_loss: 0.4825 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 75/500\n",
            "7/7 [==============================] - 2s 328ms/step - loss: 0.1723 - accuracy: 0.9500 - val_loss: 0.2534 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 76/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.1745 - accuracy: 0.9286 - val_loss: 0.3666 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 77/500\n",
            "7/7 [==============================] - 2s 315ms/step - loss: 0.2331 - accuracy: 0.9214 - val_loss: 0.2815 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 78/500\n",
            "7/7 [==============================] - 2s 328ms/step - loss: 0.1849 - accuracy: 0.9357 - val_loss: 0.3539 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 79/500\n",
            "7/7 [==============================] - 2s 329ms/step - loss: 0.1418 - accuracy: 0.9714 - val_loss: 0.3663 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "7/7 [==============================] - 2s 327ms/step - loss: 0.1481 - accuracy: 0.9429 - val_loss: 0.3554 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "7/7 [==============================] - 2s 328ms/step - loss: 0.1175 - accuracy: 0.9571 - val_loss: 0.3706 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "7/7 [==============================] - 2s 331ms/step - loss: 0.1348 - accuracy: 0.9429 - val_loss: 0.4116 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.1248 - accuracy: 0.9714 - val_loss: 0.3998 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "7/7 [==============================] - 2s 331ms/step - loss: 0.1335 - accuracy: 0.9429 - val_loss: 0.4387 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.1480 - accuracy: 0.9500 - val_loss: 0.3556 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.1277 - accuracy: 0.9643 - val_loss: 0.4207 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.1062 - accuracy: 0.9714 - val_loss: 0.2847 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "7/7 [==============================] - 2s 331ms/step - loss: 0.1249 - accuracy: 0.9571 - val_loss: 0.3607 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "7/7 [==============================] - 2s 313ms/step - loss: 0.1093 - accuracy: 0.9714 - val_loss: 0.3577 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "7/7 [==============================] - 2s 312ms/step - loss: 0.1051 - accuracy: 0.9643 - val_loss: 0.3505 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "7/7 [==============================] - 2s 314ms/step - loss: 0.1133 - accuracy: 0.9429 - val_loss: 0.4508 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "7/7 [==============================] - 2s 317ms/step - loss: 0.0971 - accuracy: 0.9786 - val_loss: 0.3747 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "7/7 [==============================] - 2s 316ms/step - loss: 0.0810 - accuracy: 0.9714 - val_loss: 0.3805 - val_accuracy: 0.8750 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "075c67a7-5094-4ca5-e947-d50abf6da89a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Precision: 0.9167\n",
            "Recall: 0.9\n",
            "F1: 0.899\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/countryvblues/countryvblues_1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "c232f941-d153-4c79-8403-75b81a59a7fb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/countryvblues/countryvblues_1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/countryvblues/countryvblues_1/assets\n"
          ]
        }
      ]
    }
  ]
}