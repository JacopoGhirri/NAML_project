{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_reggae_jazz.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for 2 genres classification - Reggae vs Jazz\n",
        "\n",
        "We aim at training a Neural Network to distinguish between two genres: reggae and jazz."
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb55bf5-68aa-43c5-b2ea-c296d1be86e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383c459d-da45-4606-b6f6-37a1a9c34d2b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "IoV9bIbPfg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "#genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "genres = {'reggae': 0, 'jazz': 1}\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=2)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc43145b-3f56-4389-c797-a7b542c69014"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reggae done\n",
            "jazz done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "0sgOQfv-gZ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(2):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 173, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 173, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 173, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, 2))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, 2))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, 2))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "O6AvTMw2hgxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1, 1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.25, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_units = 2\n",
        "input_shape = (128,173,1)\n",
        "\n",
        "model = build_model(input_shape, n_units)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23cc15c-8671-487b-d1c3-b2474e47439f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 173, 1)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 173, 4)       40        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 173, 8)       136       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 86, 8)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 86, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 43, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 43, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 21, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 21, 64)        8256      \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 21, 64)        16448     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 10, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 8, 10, 128)        32896     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 5, 286)         36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 120,992\n",
            "Trainable params: 120,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 20,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b28f89-b2dc-42e4-8712-547c753c4b33"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "7/7 [==============================] - 11s 52ms/step - loss: 0.7216 - accuracy: 0.4714 - val_loss: 0.6865 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6904 - accuracy: 0.5000 - val_loss: 0.6834 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6819 - accuracy: 0.5143 - val_loss: 0.6835 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6895 - accuracy: 0.5143 - val_loss: 0.6791 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6762 - accuracy: 0.4929 - val_loss: 0.6732 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6689 - accuracy: 0.5357 - val_loss: 0.6621 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6641 - accuracy: 0.5286 - val_loss: 0.6623 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6477 - accuracy: 0.5929 - val_loss: 0.6309 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6309 - accuracy: 0.6071 - val_loss: 0.5940 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5776 - accuracy: 0.7214 - val_loss: 0.5995 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5055 - accuracy: 0.7571 - val_loss: 0.4630 - val_accuracy: 0.8250 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4585 - accuracy: 0.8071 - val_loss: 0.6237 - val_accuracy: 0.7250 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5400 - accuracy: 0.7857 - val_loss: 0.4342 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4961 - accuracy: 0.7500 - val_loss: 0.4285 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.8571 - val_loss: 0.3974 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4518 - accuracy: 0.8500 - val_loss: 0.5675 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4538 - accuracy: 0.7714 - val_loss: 0.4198 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3765 - accuracy: 0.8643 - val_loss: 0.4116 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3687 - accuracy: 0.8571 - val_loss: 0.3691 - val_accuracy: 0.8250 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2813 - accuracy: 0.9071 - val_loss: 0.3834 - val_accuracy: 0.8250 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2964 - accuracy: 0.8786 - val_loss: 0.3814 - val_accuracy: 0.7750 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2170 - accuracy: 0.9500 - val_loss: 0.4363 - val_accuracy: 0.8250 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2914 - accuracy: 0.9071 - val_loss: 0.4160 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2327 - accuracy: 0.9143 - val_loss: 0.3442 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.2123 - accuracy: 0.9286 - val_loss: 0.4283 - val_accuracy: 0.8250 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1822 - accuracy: 0.9429 - val_loss: 0.3340 - val_accuracy: 0.8250 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1508 - accuracy: 0.9571 - val_loss: 0.4786 - val_accuracy: 0.8250 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1415 - accuracy: 0.9357 - val_loss: 0.4040 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1046 - accuracy: 0.9786 - val_loss: 0.5479 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0973 - accuracy: 0.9643 - val_loss: 0.4049 - val_accuracy: 0.8500 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1062 - accuracy: 0.9786 - val_loss: 0.3939 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1116 - accuracy: 0.9643 - val_loss: 0.4594 - val_accuracy: 0.8750 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0809 - accuracy: 0.9786 - val_loss: 0.4074 - val_accuracy: 0.8750 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0710 - accuracy: 0.9786 - val_loss: 0.4593 - val_accuracy: 0.8750 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0535 - accuracy: 0.9857 - val_loss: 0.4782 - val_accuracy: 0.8750 - lr: 5.0000e-04\n",
            "Epoch 36/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 0.4590 - val_accuracy: 0.8750 - lr: 5.0000e-04\n",
            "Epoch 37/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0370 - accuracy: 0.9857 - val_loss: 0.4597 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 38/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0340 - accuracy: 0.9929 - val_loss: 0.4537 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 39/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0319 - accuracy: 0.9929 - val_loss: 0.4737 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 40/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0320 - accuracy: 0.9929 - val_loss: 0.4815 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 41/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0248 - accuracy: 0.9929 - val_loss: 0.4931 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 42/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.0147 - accuracy: 0.9929 - val_loss: 0.4988 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 43/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0203 - accuracy: 0.9929 - val_loss: 0.5114 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 44/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0257 - accuracy: 0.9929 - val_loss: 0.5219 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 45/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 0.5610 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 46/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.9000 - lr: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "2aaf18c9-2f2d-44a7-9ac7-b7079162e911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9b0f4535f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9b0f4535f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Precision: 0.9\n",
            "Recall: 0.9\n",
            "F1: 0.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/reggaevjazz/reggaevjazz_1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "00a56e33-b62a-414b-faf2-86f6e561e5e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/reggaevjazz/reggaevjazz_1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/reggaevjazz/reggaevjazz_1/assets\n"
          ]
        }
      ]
    }
  ]
}