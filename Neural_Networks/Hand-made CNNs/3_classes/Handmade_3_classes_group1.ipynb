{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_3_classes_group1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##3 classes: classical, jazz, rock\n",
        "\n",
        "###Network: \n",
        "5 conv+max pooling, 2 dense \n",
        "\n"
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eaa6b89-0481-4ba6-822e-55b699e02f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/Colab Notebooks/NAML/Project"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347c02eb-2a98-4e46-8c24-eb2b382c4dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks/NAML/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "# genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "\n",
        "genres = { 'classical': 0, 'jazz': 1, 'rock': 2}\n",
        "\n",
        "n_genres = 3\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299db99a-a22f-4972-f9dd-7388ff7db015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classical done\n",
            "jazz done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(3):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, n_genres))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, n_genres))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, n_genres))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 conv e double conv + max pool + GAP final, square filters"
      ],
      "metadata": {
        "id": "ic00Oo914L7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, n_genres)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe89e71-b6f9-49f0-dbae-68cb90431dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 2559, 4)      104       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 2559, 8)      296       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 1279, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 1279, 16)      1168      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 1279, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 639, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 319, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 8, 159, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 79, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 79, 286)        36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,249\n",
            "Trainable params: 195,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41be81b9-5f37-43ec-9ec1-ab4172bd3a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 25s 2s/step - loss: 1.1568 - accuracy: 0.3000 - val_loss: 1.0979 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 3s 793ms/step - loss: 1.1032 - accuracy: 0.3095 - val_loss: 1.0979 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 3s 787ms/step - loss: 1.1018 - accuracy: 0.3333 - val_loss: 1.0976 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 3s 792ms/step - loss: 1.0998 - accuracy: 0.3238 - val_loss: 1.0968 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 3s 787ms/step - loss: 1.0976 - accuracy: 0.3571 - val_loss: 1.0969 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 3s 788ms/step - loss: 1.0970 - accuracy: 0.3333 - val_loss: 1.0963 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 3s 792ms/step - loss: 1.0978 - accuracy: 0.3095 - val_loss: 1.0939 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 3s 788ms/step - loss: 1.0915 - accuracy: 0.3762 - val_loss: 1.0869 - val_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 3s 786ms/step - loss: 1.0824 - accuracy: 0.3571 - val_loss: 1.0706 - val_accuracy: 0.3167 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 1.0761 - accuracy: 0.3905 - val_loss: 1.0649 - val_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 3s 785ms/step - loss: 1.0269 - accuracy: 0.4381 - val_loss: 1.1623 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 1.0627 - accuracy: 0.3810 - val_loss: 1.0788 - val_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 3s 786ms/step - loss: 1.0148 - accuracy: 0.4476 - val_loss: 0.9660 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.9439 - accuracy: 0.4524 - val_loss: 0.9102 - val_accuracy: 0.4833 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.8723 - accuracy: 0.4905 - val_loss: 1.0126 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 3s 786ms/step - loss: 0.8575 - accuracy: 0.6190 - val_loss: 0.9066 - val_accuracy: 0.5333 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.7887 - accuracy: 0.6238 - val_loss: 0.9896 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.7572 - accuracy: 0.6571 - val_loss: 0.8628 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 3s 815ms/step - loss: 0.7289 - accuracy: 0.6238 - val_loss: 0.9646 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.7503 - accuracy: 0.6238 - val_loss: 0.8367 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.6690 - accuracy: 0.7048 - val_loss: 0.9273 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 3s 810ms/step - loss: 0.7868 - accuracy: 0.6524 - val_loss: 0.7991 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 3s 821ms/step - loss: 0.7180 - accuracy: 0.5762 - val_loss: 0.8161 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.7109 - accuracy: 0.6524 - val_loss: 0.8085 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.6628 - accuracy: 0.6571 - val_loss: 0.8307 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.7222 - accuracy: 0.6429 - val_loss: 0.8582 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.7170 - accuracy: 0.6286 - val_loss: 0.7482 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 3s 809ms/step - loss: 0.7170 - accuracy: 0.6381 - val_loss: 0.7529 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 3s 788ms/step - loss: 0.6575 - accuracy: 0.6762 - val_loss: 0.8385 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 3s 813ms/step - loss: 0.7400 - accuracy: 0.6286 - val_loss: 0.7144 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 3s 798ms/step - loss: 0.6772 - accuracy: 0.6524 - val_loss: 0.7288 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 3s 806ms/step - loss: 0.7021 - accuracy: 0.6333 - val_loss: 0.7818 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 3s 820ms/step - loss: 0.6533 - accuracy: 0.7238 - val_loss: 0.6966 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 3s 806ms/step - loss: 0.6270 - accuracy: 0.6762 - val_loss: 0.6734 - val_accuracy: 0.7167 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 3s 805ms/step - loss: 0.5909 - accuracy: 0.7000 - val_loss: 0.8467 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.6034 - accuracy: 0.7762 - val_loss: 0.6754 - val_accuracy: 0.7167 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 3s 788ms/step - loss: 0.6193 - accuracy: 0.7000 - val_loss: 0.6348 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.5459 - accuracy: 0.8095 - val_loss: 0.6918 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.4976 - accuracy: 0.7810 - val_loss: 0.6461 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.5666 - accuracy: 0.7524 - val_loss: 0.6759 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.6561 - accuracy: 0.6857 - val_loss: 0.7672 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.6766 - accuracy: 0.6667 - val_loss: 0.6398 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.5573 - accuracy: 0.8000 - val_loss: 0.6398 - val_accuracy: 0.7333 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.5522 - accuracy: 0.7714 - val_loss: 0.5661 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.4677 - accuracy: 0.8143 - val_loss: 0.4985 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.4922 - accuracy: 0.8286 - val_loss: 0.4908 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.4095 - accuracy: 0.8381 - val_loss: 0.5007 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.4575 - accuracy: 0.8286 - val_loss: 0.5230 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.4435 - accuracy: 0.8381 - val_loss: 0.5632 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.4234 - accuracy: 0.8524 - val_loss: 0.4650 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.3828 - accuracy: 0.8524 - val_loss: 0.4450 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 3s 787ms/step - loss: 0.3808 - accuracy: 0.8667 - val_loss: 0.5582 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.3628 - accuracy: 0.8762 - val_loss: 0.4756 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.3605 - accuracy: 0.8667 - val_loss: 0.4481 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.3490 - accuracy: 0.8619 - val_loss: 0.4969 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.3031 - accuracy: 0.8714 - val_loss: 0.4645 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.3590 - accuracy: 0.8476 - val_loss: 0.5039 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.3903 - accuracy: 0.8667 - val_loss: 0.5174 - val_accuracy: 0.8167 - lr: 2.5000e-04\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.3072 - accuracy: 0.8905 - val_loss: 0.4318 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.3472 - accuracy: 0.8667 - val_loss: 0.4340 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.3175 - accuracy: 0.9000 - val_loss: 0.5344 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.2800 - accuracy: 0.8762 - val_loss: 0.4896 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.3051 - accuracy: 0.8667 - val_loss: 0.5132 - val_accuracy: 0.8167 - lr: 2.5000e-04\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.2529 - accuracy: 0.9048 - val_loss: 0.5322 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.2669 - accuracy: 0.9000 - val_loss: 0.4758 - val_accuracy: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.2985 - accuracy: 0.8619 - val_loss: 0.4348 - val_accuracy: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.3049 - accuracy: 0.8762 - val_loss: 0.4333 - val_accuracy: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.2642 - accuracy: 0.8905 - val_loss: 0.5130 - val_accuracy: 0.8167 - lr: 1.2500e-04\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.2673 - accuracy: 0.9190 - val_loss: 0.5408 - val_accuracy: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.2603 - accuracy: 0.9095 - val_loss: 0.4505 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 3s 791ms/step - loss: 0.2660 - accuracy: 0.9000 - val_loss: 0.4246 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.2852 - accuracy: 0.8857 - val_loss: 0.4283 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 3s 785ms/step - loss: 0.2885 - accuracy: 0.8857 - val_loss: 0.4910 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 3s 785ms/step - loss: 0.2643 - accuracy: 0.9000 - val_loss: 0.4315 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 3s 787ms/step - loss: 0.2507 - accuracy: 0.8905 - val_loss: 0.4344 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.2920 - accuracy: 0.8810 - val_loss: 0.4784 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.2588 - accuracy: 0.9000 - val_loss: 0.5552 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.2631 - accuracy: 0.9190 - val_loss: 0.5007 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.2572 - accuracy: 0.9000 - val_loss: 0.4709 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 3s 787ms/step - loss: 0.2544 - accuracy: 0.8857 - val_loss: 0.4827 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 3s 790ms/step - loss: 0.2400 - accuracy: 0.9095 - val_loss: 0.5168 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.2420 - accuracy: 0.9143 - val_loss: 0.5185 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.2383 - accuracy: 0.8952 - val_loss: 0.4773 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.2242 - accuracy: 0.9095 - val_loss: 0.4308 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.2182 - accuracy: 0.9000 - val_loss: 0.4688 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.2275 - accuracy: 0.9048 - val_loss: 0.5254 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.2230 - accuracy: 0.9190 - val_loss: 0.5024 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.2270 - accuracy: 0.9000 - val_loss: 0.4881 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.2425 - accuracy: 0.9048 - val_loss: 0.4578 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.2370 - accuracy: 0.8810 - val_loss: 0.4377 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 3s 792ms/step - loss: 0.1790 - accuracy: 0.9238 - val_loss: 0.5310 - val_accuracy: 0.8500 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "b24becb5-ec39-458b-936b-99922fafd4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Precision: 0.9\n",
            "Recall: 0.9\n",
            "F1: 0.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### As before but rectangular filters"
      ],
      "metadata": {
        "id": "VF8mO4Pa7pY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_1(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "DhPPCaJg3C-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_1 = build_model_1(input_shape, n_genres)\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4d1EuQd3ZeL",
        "outputId": "90f5e12a-bf19-4687-a03a-02611a877950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 128, 2559, 4)      64        \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 128, 2559, 8)      200       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 64, 1279, 8)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 64, 1279, 16)      784       \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 64, 1279, 16)      1552      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 639, 32)       3104      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 319, 64)       12352     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 319, 64)       24640     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 8, 159, 128)       49280     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 4, 79, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 4, 79, 286)        73502     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 186,025\n",
            "Trainable params: 186,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history_1 = model_1.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsrSipol3b7J",
        "outputId": "ca352a99-40bf-4b09-c263-9fe8b182161f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 11s 2s/step - loss: 1.1695 - accuracy: 0.3667 - val_loss: 1.0901 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 1.0979 - accuracy: 0.3476 - val_loss: 1.0906 - val_accuracy: 0.3833 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 1.1021 - accuracy: 0.3714 - val_loss: 1.0847 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 1.0941 - accuracy: 0.3714 - val_loss: 1.0782 - val_accuracy: 0.4833 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 1.0803 - accuracy: 0.4476 - val_loss: 1.0702 - val_accuracy: 0.4000 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 1.0497 - accuracy: 0.4381 - val_loss: 1.0117 - val_accuracy: 0.5333 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 1.0017 - accuracy: 0.5095 - val_loss: 0.9271 - val_accuracy: 0.5333 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.9686 - accuracy: 0.4714 - val_loss: 0.8736 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.9918 - accuracy: 0.4952 - val_loss: 0.8751 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.9738 - accuracy: 0.5190 - val_loss: 0.8772 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.9348 - accuracy: 0.5381 - val_loss: 0.8840 - val_accuracy: 0.5333 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.9509 - accuracy: 0.5333 - val_loss: 0.8722 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.9044 - accuracy: 0.5952 - val_loss: 0.8375 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.8878 - accuracy: 0.5286 - val_loss: 0.8279 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.8726 - accuracy: 0.5524 - val_loss: 0.8333 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.9106 - accuracy: 0.6048 - val_loss: 0.8666 - val_accuracy: 0.5167 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.8827 - accuracy: 0.6190 - val_loss: 0.8198 - val_accuracy: 0.6833 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.8579 - accuracy: 0.6238 - val_loss: 0.8096 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.8272 - accuracy: 0.6000 - val_loss: 0.7700 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.8384 - accuracy: 0.6333 - val_loss: 0.7673 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.7842 - accuracy: 0.6571 - val_loss: 0.7349 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.7980 - accuracy: 0.6952 - val_loss: 0.7021 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.7865 - accuracy: 0.6238 - val_loss: 0.6617 - val_accuracy: 0.7167 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.7302 - accuracy: 0.6429 - val_loss: 0.9788 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.8256 - accuracy: 0.6381 - val_loss: 0.6957 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.7970 - accuracy: 0.6238 - val_loss: 0.6478 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.7443 - accuracy: 0.6476 - val_loss: 0.6390 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.6911 - accuracy: 0.7190 - val_loss: 0.5992 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.7310 - accuracy: 0.7000 - val_loss: 0.7141 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.7104 - accuracy: 0.6762 - val_loss: 0.6698 - val_accuracy: 0.6833 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.7089 - accuracy: 0.6714 - val_loss: 0.5569 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.6867 - accuracy: 0.6952 - val_loss: 0.5551 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.6281 - accuracy: 0.7476 - val_loss: 0.5788 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.6189 - accuracy: 0.7571 - val_loss: 0.4942 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.6036 - accuracy: 0.8048 - val_loss: 0.4666 - val_accuracy: 0.8167 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.5835 - accuracy: 0.7810 - val_loss: 0.5708 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.6510 - accuracy: 0.7381 - val_loss: 0.5876 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.6040 - accuracy: 0.7619 - val_loss: 0.4732 - val_accuracy: 0.8167 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.5535 - accuracy: 0.7952 - val_loss: 0.5053 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.5114 - accuracy: 0.8048 - val_loss: 0.4865 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.5799 - accuracy: 0.8000 - val_loss: 0.4748 - val_accuracy: 0.7667 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.5636 - accuracy: 0.7524 - val_loss: 0.4302 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.4823 - accuracy: 0.8286 - val_loss: 0.3802 - val_accuracy: 0.8833 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.4725 - accuracy: 0.8333 - val_loss: 0.3727 - val_accuracy: 0.9167 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.4861 - accuracy: 0.8524 - val_loss: 0.3916 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.4656 - accuracy: 0.8381 - val_loss: 0.3537 - val_accuracy: 0.8667 - lr: 5.0000e-04\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.4652 - accuracy: 0.8286 - val_loss: 0.3332 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.5328 - accuracy: 0.8095 - val_loss: 0.3159 - val_accuracy: 0.8833 - lr: 5.0000e-04\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.5132 - accuracy: 0.8048 - val_loss: 0.3361 - val_accuracy: 0.8833 - lr: 5.0000e-04\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.4910 - accuracy: 0.8238 - val_loss: 0.4012 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.4974 - accuracy: 0.8048 - val_loss: 0.4124 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.4395 - accuracy: 0.8429 - val_loss: 0.3622 - val_accuracy: 0.8667 - lr: 5.0000e-04\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.4464 - accuracy: 0.8286 - val_loss: 0.3170 - val_accuracy: 0.9167 - lr: 5.0000e-04\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.4771 - accuracy: 0.8381 - val_loss: 0.3382 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3953 - accuracy: 0.8667 - val_loss: 0.3235 - val_accuracy: 0.8667 - lr: 2.5000e-04\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.4029 - accuracy: 0.8714 - val_loss: 0.3007 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.3966 - accuracy: 0.8476 - val_loss: 0.2677 - val_accuracy: 0.9667 - lr: 2.5000e-04\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3746 - accuracy: 0.8619 - val_loss: 0.2686 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.3204 - accuracy: 0.8952 - val_loss: 0.2534 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4059 - accuracy: 0.8476 - val_loss: 0.2517 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.3644 - accuracy: 0.8810 - val_loss: 0.2417 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3619 - accuracy: 0.8714 - val_loss: 0.2377 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.3714 - accuracy: 0.8524 - val_loss: 0.2524 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.3628 - accuracy: 0.8810 - val_loss: 0.2328 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3522 - accuracy: 0.8952 - val_loss: 0.2579 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.3410 - accuracy: 0.8714 - val_loss: 0.3196 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.3522 - accuracy: 0.8619 - val_loss: 0.2684 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.2950 - accuracy: 0.8905 - val_loss: 0.2324 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3441 - accuracy: 0.8905 - val_loss: 0.2679 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.3293 - accuracy: 0.8714 - val_loss: 0.2569 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.3782 - accuracy: 0.8762 - val_loss: 0.2522 - val_accuracy: 0.9667 - lr: 2.5000e-04\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.3562 - accuracy: 0.8619 - val_loss: 0.2297 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.2929 - accuracy: 0.9000 - val_loss: 0.2593 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.3134 - accuracy: 0.8857 - val_loss: 0.2176 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.3019 - accuracy: 0.8952 - val_loss: 0.2275 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.2903 - accuracy: 0.8762 - val_loss: 0.2163 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.2692 - accuracy: 0.9048 - val_loss: 0.2082 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.2354 - accuracy: 0.9000 - val_loss: 0.2252 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.2585 - accuracy: 0.9143 - val_loss: 0.2136 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.2561 - accuracy: 0.9095 - val_loss: 0.2127 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.2700 - accuracy: 0.8667 - val_loss: 0.2247 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.3085 - accuracy: 0.8905 - val_loss: 0.2070 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.2602 - accuracy: 0.9000 - val_loss: 0.2484 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.3099 - accuracy: 0.8810 - val_loss: 0.2513 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.2472 - accuracy: 0.8952 - val_loss: 0.2508 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.2683 - accuracy: 0.9095 - val_loss: 0.2496 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.2417 - accuracy: 0.9048 - val_loss: 0.2371 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.2407 - accuracy: 0.9095 - val_loss: 0.2526 - val_accuracy: 0.9333 - lr: 1.2500e-04\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.2919 - accuracy: 0.8905 - val_loss: 0.2290 - val_accuracy: 0.9333 - lr: 1.2500e-04\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.2981 - accuracy: 0.8857 - val_loss: 0.2218 - val_accuracy: 0.9500 - lr: 1.2500e-04\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.2225 - accuracy: 0.9333 - val_loss: 0.2363 - val_accuracy: 0.9333 - lr: 1.2500e-04\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.2700 - accuracy: 0.9143 - val_loss: 0.2547 - val_accuracy: 0.9333 - lr: 1.2500e-04\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.2558 - accuracy: 0.9000 - val_loss: 0.2338 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.2507 - accuracy: 0.9095 - val_loss: 0.2239 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.2404 - accuracy: 0.8952 - val_loss: 0.2312 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.2328 - accuracy: 0.8857 - val_loss: 0.2213 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.2374 - accuracy: 0.9095 - val_loss: 0.2267 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.2578 - accuracy: 0.9000 - val_loss: 0.2622 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.2518 - accuracy: 0.9000 - val_loss: 0.3156 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.3315 - accuracy: 0.8714 - val_loss: 0.2362 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.2120 - accuracy: 0.9286 - val_loss: 0.2328 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.2911 - accuracy: 0.8857 - val_loss: 0.2444 - val_accuracy: 0.9333 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1 = model_1.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_1= confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_1 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1))\n",
        "precision_1 = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "recall_1 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "f1_1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_1.round(4))\n",
        "print('Precision:',precision_1.round(4))\n",
        "print('Recall:',recall_1.round(4))\n",
        "print('F1:',f1_1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_1.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "Mkhenicd3eRs",
        "outputId": "f451944a-1d5f-48b4-81d8-0a00b49658ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333\n",
            "Precision: 0.9444\n",
            "Recall: 0.9333\n",
            "F1: 0.9346\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###As above, rectangular, adding a double convolution "
      ],
      "metadata": {
        "id": "lszhyCbWTIX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_2(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    conv5_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv5)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5_2)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    pool6= tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv6)\n",
        "\n",
        "    conv7 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(1,2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool6)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cKoqp4HTTIIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_2 = build_model_2(input_shape, n_genres)\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xEC5ICoTZoL",
        "outputId": "6d69a10d-6a09-459f-d328-74bf87b79d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 2559, 4)      64        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 2559, 8)      200       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 1279, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 1279, 16)      784       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 1279, 16)      1552      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 639, 32)       3104      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 319, 64)       12352     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 319, 64)       24640     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 8, 159, 64)        24640     \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 8, 159, 64)        24640     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 79, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 79, 128)        49280     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 128)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151,691\n",
            "Trainable params: 151,691\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history_2 = model_2.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khi35SyrTfF0",
        "outputId": "0efd9168-e851-4f71-aa84-29f06367fcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 21s 2s/step - loss: 1.1084 - accuracy: 0.3571 - val_loss: 1.0980 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 3s 714ms/step - loss: 1.0944 - accuracy: 0.3762 - val_loss: 1.0997 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 3s 713ms/step - loss: 1.1156 - accuracy: 0.3095 - val_loss: 1.1019 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 3s 712ms/step - loss: 1.1086 - accuracy: 0.2952 - val_loss: 1.1003 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 3s 709ms/step - loss: 1.1075 - accuracy: 0.3333 - val_loss: 1.0984 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 1.0995 - accuracy: 0.3524 - val_loss: 1.0979 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 3s 717ms/step - loss: 1.0989 - accuracy: 0.2762 - val_loss: 1.0978 - val_accuracy: 0.3500 - lr: 5.0000e-04\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 3s 716ms/step - loss: 1.0977 - accuracy: 0.4048 - val_loss: 1.0973 - val_accuracy: 0.5333 - lr: 5.0000e-04\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 3s 716ms/step - loss: 1.0987 - accuracy: 0.3381 - val_loss: 1.0967 - val_accuracy: 0.4667 - lr: 5.0000e-04\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 3s 719ms/step - loss: 1.0975 - accuracy: 0.3333 - val_loss: 1.0959 - val_accuracy: 0.3500 - lr: 5.0000e-04\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 3s 717ms/step - loss: 1.0945 - accuracy: 0.3667 - val_loss: 1.0948 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 3s 727ms/step - loss: 1.0954 - accuracy: 0.3714 - val_loss: 1.0911 - val_accuracy: 0.4833 - lr: 5.0000e-04\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 3s 716ms/step - loss: 1.0879 - accuracy: 0.4714 - val_loss: 1.0865 - val_accuracy: 0.4167 - lr: 5.0000e-04\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 1.0878 - accuracy: 0.4190 - val_loss: 1.0725 - val_accuracy: 0.5500 - lr: 5.0000e-04\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 3s 724ms/step - loss: 1.0703 - accuracy: 0.4286 - val_loss: 1.0417 - val_accuracy: 0.4500 - lr: 5.0000e-04\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 3s 716ms/step - loss: 1.0290 - accuracy: 0.4857 - val_loss: 1.0002 - val_accuracy: 0.4333 - lr: 5.0000e-04\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 3s 720ms/step - loss: 0.9958 - accuracy: 0.4762 - val_loss: 0.9274 - val_accuracy: 0.5333 - lr: 5.0000e-04\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 3s 720ms/step - loss: 1.0095 - accuracy: 0.4619 - val_loss: 0.9563 - val_accuracy: 0.5500 - lr: 5.0000e-04\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 3s 721ms/step - loss: 1.0070 - accuracy: 0.4857 - val_loss: 0.9289 - val_accuracy: 0.5167 - lr: 5.0000e-04\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 3s 719ms/step - loss: 0.9528 - accuracy: 0.5000 - val_loss: 0.9572 - val_accuracy: 0.5333 - lr: 5.0000e-04\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.9304 - accuracy: 0.5571 - val_loss: 0.9203 - val_accuracy: 0.5500 - lr: 5.0000e-04\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 3s 721ms/step - loss: 0.9089 - accuracy: 0.5762 - val_loss: 0.8840 - val_accuracy: 0.5167 - lr: 5.0000e-04\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.8611 - accuracy: 0.6143 - val_loss: 0.8310 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 3s 716ms/step - loss: 0.8715 - accuracy: 0.5905 - val_loss: 0.8483 - val_accuracy: 0.5667 - lr: 5.0000e-04\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 3s 717ms/step - loss: 0.8679 - accuracy: 0.5667 - val_loss: 0.8432 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 3s 722ms/step - loss: 0.8377 - accuracy: 0.5810 - val_loss: 0.8394 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 3s 722ms/step - loss: 0.7929 - accuracy: 0.6190 - val_loss: 0.8021 - val_accuracy: 0.6333 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 3s 726ms/step - loss: 0.8395 - accuracy: 0.5762 - val_loss: 0.7772 - val_accuracy: 0.6000 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.8292 - accuracy: 0.6000 - val_loss: 0.7743 - val_accuracy: 0.6333 - lr: 5.0000e-04\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 0.8034 - accuracy: 0.6000 - val_loss: 0.7510 - val_accuracy: 0.6000 - lr: 5.0000e-04\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 0.8101 - accuracy: 0.5952 - val_loss: 0.7275 - val_accuracy: 0.6333 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 3s 719ms/step - loss: 0.7494 - accuracy: 0.6476 - val_loss: 0.7046 - val_accuracy: 0.6333 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 3s 725ms/step - loss: 0.7770 - accuracy: 0.6000 - val_loss: 0.6810 - val_accuracy: 0.6500 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 3s 721ms/step - loss: 0.8164 - accuracy: 0.6000 - val_loss: 0.6834 - val_accuracy: 0.7167 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 0.8108 - accuracy: 0.6095 - val_loss: 0.6834 - val_accuracy: 0.6667 - lr: 5.0000e-04\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.7577 - accuracy: 0.6429 - val_loss: 0.6765 - val_accuracy: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.7127 - accuracy: 0.6762 - val_loss: 0.6650 - val_accuracy: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.7568 - accuracy: 0.6000 - val_loss: 0.6545 - val_accuracy: 0.6833 - lr: 5.0000e-04\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.6796 - accuracy: 0.7238 - val_loss: 0.6172 - val_accuracy: 0.7167 - lr: 5.0000e-04\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.7107 - accuracy: 0.6810 - val_loss: 0.5865 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 3s 726ms/step - loss: 0.7139 - accuracy: 0.6952 - val_loss: 0.6124 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.6611 - accuracy: 0.7333 - val_loss: 0.5819 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 3s 726ms/step - loss: 0.7142 - accuracy: 0.6810 - val_loss: 0.6000 - val_accuracy: 0.6833 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.7044 - accuracy: 0.6714 - val_loss: 0.5773 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 3s 727ms/step - loss: 0.5911 - accuracy: 0.8000 - val_loss: 0.5256 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 0.5609 - accuracy: 0.7524 - val_loss: 0.5372 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.5835 - accuracy: 0.7381 - val_loss: 0.4573 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 3s 729ms/step - loss: 0.6019 - accuracy: 0.7381 - val_loss: 0.4432 - val_accuracy: 0.8667 - lr: 5.0000e-04\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 3s 729ms/step - loss: 0.4902 - accuracy: 0.8000 - val_loss: 0.4128 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 3s 729ms/step - loss: 0.5379 - accuracy: 0.8190 - val_loss: 0.3749 - val_accuracy: 0.8667 - lr: 5.0000e-04\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 3s 729ms/step - loss: 0.5711 - accuracy: 0.7810 - val_loss: 0.3985 - val_accuracy: 0.9000 - lr: 5.0000e-04\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.5233 - accuracy: 0.7905 - val_loss: 0.4008 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 3s 725ms/step - loss: 0.4946 - accuracy: 0.8000 - val_loss: 0.4613 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.6553 - accuracy: 0.7048 - val_loss: 0.6801 - val_accuracy: 0.7000 - lr: 5.0000e-04\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 0.7967 - accuracy: 0.6571 - val_loss: 0.9908 - val_accuracy: 0.4167 - lr: 5.0000e-04\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 3s 726ms/step - loss: 0.9425 - accuracy: 0.5381 - val_loss: 0.7254 - val_accuracy: 0.6500 - lr: 2.5000e-04\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.7816 - accuracy: 0.6667 - val_loss: 0.5951 - val_accuracy: 0.8667 - lr: 2.5000e-04\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 0.6689 - accuracy: 0.7571 - val_loss: 0.5480 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.5954 - accuracy: 0.7476 - val_loss: 0.5332 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.5942 - accuracy: 0.7476 - val_loss: 0.4768 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 3s 726ms/step - loss: 0.6025 - accuracy: 0.7333 - val_loss: 0.4748 - val_accuracy: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 3s 728ms/step - loss: 0.6163 - accuracy: 0.7524 - val_loss: 0.4736 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 0.5967 - accuracy: 0.7333 - val_loss: 0.4824 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 3s 718ms/step - loss: 0.5663 - accuracy: 0.7619 - val_loss: 0.4712 - val_accuracy: 0.7833 - lr: 1.2500e-04\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 0.5530 - accuracy: 0.7714 - val_loss: 0.4442 - val_accuracy: 0.8667 - lr: 1.2500e-04\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 0.5594 - accuracy: 0.7619 - val_loss: 0.4455 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 0.6112 - accuracy: 0.7619 - val_loss: 0.4454 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 0.5749 - accuracy: 0.7429 - val_loss: 0.4833 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 3s 725ms/step - loss: 0.5764 - accuracy: 0.7667 - val_loss: 0.4495 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 3s 731ms/step - loss: 0.5508 - accuracy: 0.7857 - val_loss: 0.4512 - val_accuracy: 0.8333 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_2 = model_2.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_2= confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_2 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1))\n",
        "precision_2 = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "recall_2 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "f1_2 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_2.round(4))\n",
        "print('Precision:',precision_2.round(4))\n",
        "print('Recall:',recall_2.round(4))\n",
        "print('F1:',f1_2.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_2.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "89f234LUTmhi",
        "outputId": "c4e336c3-07cf-44b7-e0fb-c2bad77ab7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Precision: 0.9231\n",
            "Recall: 0.9\n",
            "F1: 0.8977\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving best model"
      ],
      "metadata": {
        "id": "QcfHrS5T9dRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.save('/gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_3_classes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8bz29KK9gOz",
        "outputId": "a7768d1b-271d-4b85-8cc6-c3a8b589c100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_3_classes/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_3_classes/assets\n"
          ]
        }
      ]
    }
  ]
}