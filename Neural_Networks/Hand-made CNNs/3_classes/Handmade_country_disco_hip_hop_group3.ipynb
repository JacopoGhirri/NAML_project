{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_3_classes_group3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "M6wcp-yyg48g",
        "ezzh-uhS5VGv",
        "vRkXU25Vgx8t",
        "KgRGNCArXmMK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##5 classes: rock, metal, country, hip hop, disco\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b91f916-1e0a-44a9-f1fc-432aa704479f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/Colab Notebooks/NAML/Project"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e3b5bb-9761-461e-8209-675633900261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks/NAML/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "# genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "\n",
        "genres = { 'country': 0, 'disco': 1, 'hiphop': 2}\n",
        "\n",
        "n_genres=3\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48dd5b3d-a695-4b2d-c3b7-f2d8cb30fe8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "country done\n",
            "disco done\n",
            "hiphop done\n",
            "metal done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(3):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, n_genres))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, n_genres))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, n_genres))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 conv e doppi conv + max pool, last GAP, 2 dense, square filt  "
      ],
      "metadata": {
        "id": "M6wcp-yyg48g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RNThcfPx1m0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, n_genres)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d022f362-4fd4-48c7-c0f0-1e47c8098821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 2559, 4)      104       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 2559, 8)      296       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 1279, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 1279, 16)      1168      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 1279, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 639, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 319, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 8, 159, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 79, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 79, 286)        36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,315\n",
            "Trainable params: 195,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ba34cc-3f3f-47ba-86ef-01376edf4308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 24s 2s/step - loss: 1.5381 - accuracy: 0.3476 - val_loss: 1.3630 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 1.4801 - accuracy: 0.3095 - val_loss: 1.3262 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 3s 729ms/step - loss: 1.3874 - accuracy: 0.3619 - val_loss: 1.3559 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 1.3721 - accuracy: 0.3714 - val_loss: 1.2321 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 3s 732ms/step - loss: 1.3466 - accuracy: 0.3238 - val_loss: 1.2173 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 1.2975 - accuracy: 0.3762 - val_loss: 1.2033 - val_accuracy: 0.4500 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 1.3025 - accuracy: 0.3143 - val_loss: 1.1604 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 1.3641 - accuracy: 0.3143 - val_loss: 1.2255 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 1.2596 - accuracy: 0.4429 - val_loss: 1.2042 - val_accuracy: 0.4500 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 1.2780 - accuracy: 0.3524 - val_loss: 1.1006 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 1.2056 - accuracy: 0.3429 - val_loss: 1.0850 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 1.1967 - accuracy: 0.4381 - val_loss: 1.0892 - val_accuracy: 0.5167 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 1.1674 - accuracy: 0.4619 - val_loss: 0.9950 - val_accuracy: 0.5333 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 1.1036 - accuracy: 0.4381 - val_loss: 0.9514 - val_accuracy: 0.5500 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 1.0882 - accuracy: 0.5000 - val_loss: 0.8943 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 1.0227 - accuracy: 0.5048 - val_loss: 0.7932 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.9186 - accuracy: 0.5381 - val_loss: 0.8985 - val_accuracy: 0.5167 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 1.0265 - accuracy: 0.5476 - val_loss: 1.0575 - val_accuracy: 0.5167 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 1.0054 - accuracy: 0.5667 - val_loss: 0.9063 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.9311 - accuracy: 0.5810 - val_loss: 0.8427 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.9408 - accuracy: 0.5619 - val_loss: 0.7733 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.9636 - accuracy: 0.5714 - val_loss: 0.7392 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.7544 - accuracy: 0.6810 - val_loss: 0.7301 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.7708 - accuracy: 0.6714 - val_loss: 0.5689 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.8291 - accuracy: 0.6095 - val_loss: 0.6091 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.8019 - accuracy: 0.6429 - val_loss: 0.6395 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.7005 - accuracy: 0.7190 - val_loss: 0.5526 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.6936 - accuracy: 0.7238 - val_loss: 0.5140 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.6258 - accuracy: 0.7238 - val_loss: 0.5171 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.6785 - accuracy: 0.7095 - val_loss: 0.6261 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.6606 - accuracy: 0.7238 - val_loss: 0.4438 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.6405 - accuracy: 0.6905 - val_loss: 0.4679 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.6370 - accuracy: 0.7143 - val_loss: 0.5583 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.7659 - accuracy: 0.6905 - val_loss: 0.4616 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.6454 - accuracy: 0.7333 - val_loss: 0.5180 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.6428 - accuracy: 0.7762 - val_loss: 0.5173 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.5873 - accuracy: 0.8000 - val_loss: 0.4858 - val_accuracy: 0.7667 - lr: 5.0000e-04\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.5660 - accuracy: 0.8000 - val_loss: 0.4298 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.5155 - accuracy: 0.7905 - val_loss: 0.4640 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.5839 - accuracy: 0.7667 - val_loss: 0.3792 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.4710 - accuracy: 0.8000 - val_loss: 0.3640 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.5059 - accuracy: 0.8286 - val_loss: 0.4203 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.4379 - accuracy: 0.8286 - val_loss: 0.3276 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.5094 - accuracy: 0.8143 - val_loss: 0.4980 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.5383 - accuracy: 0.7619 - val_loss: 0.3598 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.4947 - accuracy: 0.7714 - val_loss: 0.4544 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.4797 - accuracy: 0.8048 - val_loss: 0.3465 - val_accuracy: 0.8833 - lr: 5.0000e-04\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.4622 - accuracy: 0.8524 - val_loss: 0.3593 - val_accuracy: 0.8667 - lr: 5.0000e-04\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.4862 - accuracy: 0.8095 - val_loss: 0.3433 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.4135 - accuracy: 0.8524 - val_loss: 0.3310 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.4707 - accuracy: 0.8048 - val_loss: 0.3707 - val_accuracy: 0.8667 - lr: 2.5000e-04\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.4563 - accuracy: 0.8286 - val_loss: 0.2969 - val_accuracy: 0.8167 - lr: 2.5000e-04\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.4167 - accuracy: 0.8571 - val_loss: 0.3078 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.4090 - accuracy: 0.8333 - val_loss: 0.2872 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.4344 - accuracy: 0.8143 - val_loss: 0.2873 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3898 - accuracy: 0.8619 - val_loss: 0.4353 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.4812 - accuracy: 0.7905 - val_loss: 0.2794 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.5662 - accuracy: 0.7857 - val_loss: 0.3284 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.3831 - accuracy: 0.8381 - val_loss: 0.4099 - val_accuracy: 0.8167 - lr: 2.5000e-04\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.4007 - accuracy: 0.8190 - val_loss: 0.2961 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.4659 - accuracy: 0.8143 - val_loss: 0.2741 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.4637 - accuracy: 0.8095 - val_loss: 0.4271 - val_accuracy: 0.7833 - lr: 2.5000e-04\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.3903 - accuracy: 0.8524 - val_loss: 0.2658 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3638 - accuracy: 0.8714 - val_loss: 0.2977 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.4046 - accuracy: 0.8333 - val_loss: 0.3141 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3579 - accuracy: 0.8524 - val_loss: 0.2521 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3957 - accuracy: 0.8857 - val_loss: 0.2867 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3316 - accuracy: 0.8952 - val_loss: 0.2664 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3682 - accuracy: 0.8619 - val_loss: 0.2419 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3771 - accuracy: 0.8810 - val_loss: 0.2747 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.3168 - accuracy: 0.8905 - val_loss: 0.2721 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.3756 - accuracy: 0.8476 - val_loss: 0.2255 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3819 - accuracy: 0.8571 - val_loss: 0.2997 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3321 - accuracy: 0.8714 - val_loss: 0.2319 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.4632 - accuracy: 0.8286 - val_loss: 0.2154 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3872 - accuracy: 0.8714 - val_loss: 0.2618 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3238 - accuracy: 0.8857 - val_loss: 0.2528 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.4383 - accuracy: 0.8333 - val_loss: 0.3532 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3314 - accuracy: 0.8810 - val_loss: 0.2227 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.3970 - accuracy: 0.8905 - val_loss: 0.2137 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.3727 - accuracy: 0.8857 - val_loss: 0.2716 - val_accuracy: 0.8667 - lr: 2.5000e-04\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3546 - accuracy: 0.8905 - val_loss: 0.2201 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3259 - accuracy: 0.9048 - val_loss: 0.2721 - val_accuracy: 0.8667 - lr: 2.5000e-04\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.2436 - accuracy: 0.9048 - val_loss: 0.2656 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3394 - accuracy: 0.8762 - val_loss: 0.2064 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.3311 - accuracy: 0.8952 - val_loss: 0.1890 - val_accuracy: 0.9333 - lr: 2.5000e-04\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3828 - accuracy: 0.8714 - val_loss: 0.3552 - val_accuracy: 0.8167 - lr: 2.5000e-04\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3013 - accuracy: 0.9095 - val_loss: 0.2457 - val_accuracy: 0.8667 - lr: 2.5000e-04\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3884 - accuracy: 0.8524 - val_loss: 0.2747 - val_accuracy: 0.8833 - lr: 2.5000e-04\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3049 - accuracy: 0.8857 - val_loss: 0.2232 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.2747 - accuracy: 0.9095 - val_loss: 0.1843 - val_accuracy: 0.9500 - lr: 2.5000e-04\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.3400 - accuracy: 0.8952 - val_loss: 0.2395 - val_accuracy: 0.9000 - lr: 2.5000e-04\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.3443 - accuracy: 0.8714 - val_loss: 0.2012 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.2721 - accuracy: 0.9000 - val_loss: 0.3040 - val_accuracy: 0.8667 - lr: 2.5000e-04\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.3602 - accuracy: 0.8810 - val_loss: 0.1924 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 0.2846 - accuracy: 0.9048 - val_loss: 0.2229 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.2903 - accuracy: 0.9048 - val_loss: 0.1853 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.2555 - accuracy: 0.9238 - val_loss: 0.3218 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.2726 - accuracy: 0.9143 - val_loss: 0.2347 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.2335 - accuracy: 0.9143 - val_loss: 0.2046 - val_accuracy: 0.9000 - lr: 1.2500e-04\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.2591 - accuracy: 0.9000 - val_loss: 0.2031 - val_accuracy: 0.8833 - lr: 1.2500e-04\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.2710 - accuracy: 0.9095 - val_loss: 0.2010 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.2117 - accuracy: 0.9143 - val_loss: 0.2096 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.2364 - accuracy: 0.9095 - val_loss: 0.2196 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.2555 - accuracy: 0.9238 - val_loss: 0.2537 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.1972 - accuracy: 0.9333 - val_loss: 0.2344 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.1960 - accuracy: 0.9476 - val_loss: 0.1720 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.2062 - accuracy: 0.9381 - val_loss: 0.2130 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.1998 - accuracy: 0.9333 - val_loss: 0.2505 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.2531 - accuracy: 0.9381 - val_loss: 0.2747 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.2283 - accuracy: 0.9095 - val_loss: 0.2310 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.1925 - accuracy: 0.9429 - val_loss: 0.1993 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.2028 - accuracy: 0.9333 - val_loss: 0.1849 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.2311 - accuracy: 0.9048 - val_loss: 0.2626 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.2367 - accuracy: 0.9143 - val_loss: 0.2302 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.1755 - accuracy: 0.9333 - val_loss: 0.2064 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.2446 - accuracy: 0.9190 - val_loss: 0.2061 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.2015 - accuracy: 0.9238 - val_loss: 0.2243 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.2447 - accuracy: 0.9048 - val_loss: 0.1806 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.1845 - accuracy: 0.9381 - val_loss: 0.1880 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.2062 - accuracy: 0.9381 - val_loss: 0.1723 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.1965 - accuracy: 0.9190 - val_loss: 0.1939 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.1751 - accuracy: 0.9381 - val_loss: 0.2362 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.2245 - accuracy: 0.9190 - val_loss: 0.1795 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.2394 - accuracy: 0.9333 - val_loss: 0.1753 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.1452 - accuracy: 0.9476 - val_loss: 0.2522 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.1824 - accuracy: 0.9333 - val_loss: 0.2672 - val_accuracy: 0.8500 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "0c68e327-3885-4787-f03c-8b852789c5ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333\n",
            "Precision: 0.9444\n",
            "Recall: 0.9333\n",
            "F1: 0.9346\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###As before but rect filt"
      ],
      "metadata": {
        "id": "ezzh-uhS5VGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_1(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "s1LzDfg45bYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_1 = build_model_1(input_shape, n_genres)\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z02qBdCF5hHI",
        "outputId": "489d6408-4be4-4381-99a5-0717fad72f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 128, 2559, 4)      64        \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 128, 2559, 8)      200       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 64, 1279, 8)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 64, 1279, 16)      784       \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 64, 1279, 16)      1552      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 639, 32)       3104      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 319, 64)       12352     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 319, 64)       24640     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 8, 159, 128)       49280     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 4, 79, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 4, 79, 286)        73502     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 186,091\n",
            "Trainable params: 186,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history_1 = model_1.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "xlS82usv5kJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1 = model_1.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_1 = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_1 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1))\n",
        "precision_1 = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "recall_1 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "f1_1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_1.round(4))\n",
        "print('Precision:',precision_1.round(4))\n",
        "print('Recall:',recall_1.round(4))\n",
        "print('F1:',f1_1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_1.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "8NwAhCEP5pRs",
        "outputId": "3913e52c-d95c-46c3-c86d-214b03ee7c58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8667\n",
            "Precision: 0.8897\n",
            "Recall: 0.8667\n",
            "F1: 0.8644\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cqqTYlXfXT1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 conv + max pool, 2 dense, square filt but last 2 rect"
      ],
      "metadata": {
        "id": "vRkXU25Vgx8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_2(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 3)\n",
        "    )(conv4)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 3)\n",
        "    )(conv5)\n",
        "\n",
        "\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    classifier_layer = tfkl.Dropout(0.2, seed=seed)(classifier_layer)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "vbTCYkHKhp_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_2 = build_model_2(input_shape, n_genres)\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "vnsAjSP9hsz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641eb9bd-4145-4f2d-f74b-6f13a85de7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 128, 2559, 16)     160       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 64, 1279, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 64, 1279, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 32, 639, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 32, 639, 64)       18496     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 16, 319, 64)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 8, 106, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 8, 106, 128)       32896     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 4, 35, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 17920)             0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 17920)             0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                1146944   \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,240,389\n",
            "Trainable params: 1,240,389\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first_callbacks = create_folders_and_callbacks(model_name='first')\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=2)\n",
        "\n",
        "standard_history_2 = model_2.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 90,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping]\n",
        "    )"
      ],
      "metadata": {
        "id": "6Ms4zNzfhvuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1c447a-81b6-4326-a00e-7364a0b11812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/90\n",
            "4/4 [==============================] - 10s 2s/step - loss: 7.0698 - accuracy: 0.2381 - val_loss: 1.8804 - val_accuracy: 0.3333\n",
            "Epoch 2/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 1.8617 - accuracy: 0.3286 - val_loss: 1.3072 - val_accuracy: 0.3333\n",
            "Epoch 3/90\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.2761 - accuracy: 0.3238 - val_loss: 1.1462 - val_accuracy: 0.4000\n",
            "Epoch 4/90\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 1.1948 - accuracy: 0.3810 - val_loss: 1.0836 - val_accuracy: 0.5667\n",
            "Epoch 5/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 1.0922 - accuracy: 0.4095 - val_loss: 1.0522 - val_accuracy: 0.3833\n",
            "Epoch 6/90\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 1.0963 - accuracy: 0.4524 - val_loss: 0.9730 - val_accuracy: 0.5833\n",
            "Epoch 7/90\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 1.0015 - accuracy: 0.5476 - val_loss: 0.9021 - val_accuracy: 0.6833\n",
            "Epoch 8/90\n",
            "4/4 [==============================] - 2s 562ms/step - loss: 0.8781 - accuracy: 0.6048 - val_loss: 0.8033 - val_accuracy: 0.6500\n",
            "Epoch 9/90\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.7796 - accuracy: 0.6524 - val_loss: 0.7341 - val_accuracy: 0.7000\n",
            "Epoch 10/90\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.7641 - accuracy: 0.6571 - val_loss: 0.7306 - val_accuracy: 0.7000\n",
            "Epoch 11/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.7161 - accuracy: 0.6905 - val_loss: 0.7026 - val_accuracy: 0.6500\n",
            "Epoch 12/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.6731 - accuracy: 0.6667 - val_loss: 0.5995 - val_accuracy: 0.7667\n",
            "Epoch 13/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.6703 - accuracy: 0.7381 - val_loss: 0.6308 - val_accuracy: 0.7333\n",
            "Epoch 14/90\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.6636 - accuracy: 0.7095 - val_loss: 0.6597 - val_accuracy: 0.7333\n",
            "Epoch 15/90\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.6323 - accuracy: 0.7238 - val_loss: 0.6194 - val_accuracy: 0.7333\n",
            "Epoch 16/90\n",
            "4/4 [==============================] - 2s 618ms/step - loss: 0.5912 - accuracy: 0.7571 - val_loss: 0.6136 - val_accuracy: 0.7833\n",
            "Epoch 17/90\n",
            "4/4 [==============================] - 3s 625ms/step - loss: 0.4835 - accuracy: 0.8286 - val_loss: 0.4751 - val_accuracy: 0.8167\n",
            "Epoch 18/90\n",
            "4/4 [==============================] - 2s 596ms/step - loss: 0.4707 - accuracy: 0.8286 - val_loss: 0.5435 - val_accuracy: 0.7833\n",
            "Epoch 19/90\n",
            "4/4 [==============================] - 2s 612ms/step - loss: 0.4744 - accuracy: 0.8190 - val_loss: 0.4070 - val_accuracy: 0.7833\n",
            "Epoch 20/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.3231 - accuracy: 0.8762 - val_loss: 0.4007 - val_accuracy: 0.8500\n",
            "Epoch 21/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.3465 - accuracy: 0.8619 - val_loss: 0.4907 - val_accuracy: 0.7667\n",
            "Epoch 22/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.3240 - accuracy: 0.8810 - val_loss: 0.4123 - val_accuracy: 0.8667\n",
            "Epoch 23/90\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.3154 - accuracy: 0.9000 - val_loss: 0.3731 - val_accuracy: 0.8333\n",
            "Epoch 24/90\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.2503 - accuracy: 0.9048 - val_loss: 0.3863 - val_accuracy: 0.8667\n",
            "Epoch 25/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.2668 - accuracy: 0.9095 - val_loss: 0.3814 - val_accuracy: 0.8667\n",
            "Epoch 26/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.3016 - accuracy: 0.9000 - val_loss: 0.4933 - val_accuracy: 0.8333\n",
            "Epoch 27/90\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.2233 - accuracy: 0.9143 - val_loss: 0.3958 - val_accuracy: 0.8667\n",
            "Epoch 28/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.1975 - accuracy: 0.9238 - val_loss: 0.4475 - val_accuracy: 0.8167\n",
            "Epoch 29/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.1816 - accuracy: 0.9381 - val_loss: 0.4357 - val_accuracy: 0.8833\n",
            "Epoch 30/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.1794 - accuracy: 0.9286 - val_loss: 0.3907 - val_accuracy: 0.8667\n",
            "Epoch 31/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.1547 - accuracy: 0.9381 - val_loss: 0.3503 - val_accuracy: 0.9000\n",
            "Epoch 32/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.1158 - accuracy: 0.9524 - val_loss: 0.3834 - val_accuracy: 0.9000\n",
            "Epoch 33/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.1112 - accuracy: 0.9667 - val_loss: 0.3824 - val_accuracy: 0.8667\n",
            "Epoch 34/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.1383 - accuracy: 0.9429 - val_loss: 0.4361 - val_accuracy: 0.8833\n",
            "Epoch 35/90\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.1657 - accuracy: 0.9286 - val_loss: 0.3697 - val_accuracy: 0.9000\n",
            "Epoch 36/90\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.1512 - accuracy: 0.9095 - val_loss: 0.3232 - val_accuracy: 0.9167\n",
            "Epoch 37/90\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.1823 - accuracy: 0.9381 - val_loss: 0.3352 - val_accuracy: 0.9000\n",
            "Epoch 38/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.1716 - accuracy: 0.9429 - val_loss: 0.3515 - val_accuracy: 0.8833\n",
            "Epoch 39/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.1801 - accuracy: 0.9571 - val_loss: 0.3639 - val_accuracy: 0.8500\n",
            "Epoch 40/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.1531 - accuracy: 0.9476 - val_loss: 0.5527 - val_accuracy: 0.8000\n",
            "Epoch 41/90\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.1247 - accuracy: 0.9571 - val_loss: 0.3983 - val_accuracy: 0.8833\n",
            "Epoch 42/90\n",
            "4/4 [==============================] - 2s 565ms/step - loss: 0.1108 - accuracy: 0.9571 - val_loss: 0.3814 - val_accuracy: 0.8833\n",
            "Epoch 43/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.0969 - accuracy: 0.9619 - val_loss: 0.5838 - val_accuracy: 0.8333\n",
            "Epoch 44/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.0933 - accuracy: 0.9714 - val_loss: 0.4959 - val_accuracy: 0.8500\n",
            "Epoch 45/90\n",
            "4/4 [==============================] - 2s 563ms/step - loss: 0.0885 - accuracy: 0.9714 - val_loss: 0.4706 - val_accuracy: 0.9000\n",
            "Epoch 46/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.0790 - accuracy: 0.9762 - val_loss: 0.4373 - val_accuracy: 0.9167\n",
            "Epoch 47/90\n",
            "4/4 [==============================] - 2s 566ms/step - loss: 0.0552 - accuracy: 0.9857 - val_loss: 0.4500 - val_accuracy: 0.9167\n",
            "Epoch 48/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.0490 - accuracy: 0.9810 - val_loss: 0.5583 - val_accuracy: 0.9000\n",
            "Epoch 49/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.0449 - accuracy: 0.9857 - val_loss: 0.4726 - val_accuracy: 0.9167\n",
            "Epoch 50/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.6041 - val_accuracy: 0.8833\n",
            "Epoch 51/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.0408 - accuracy: 0.9905 - val_loss: 0.6084 - val_accuracy: 0.8667\n",
            "Epoch 52/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.0357 - accuracy: 0.9857 - val_loss: 0.5799 - val_accuracy: 0.9167\n",
            "Epoch 53/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.5427 - val_accuracy: 0.8833\n",
            "Epoch 54/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.0346 - accuracy: 0.9810 - val_loss: 0.5500 - val_accuracy: 0.8667\n",
            "Epoch 55/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.4959 - val_accuracy: 0.9333\n",
            "Epoch 56/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.9333\n",
            "Epoch 56: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_2 = model_2.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_2 = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_2 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1))\n",
        "precision_2 = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "recall_2 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "f1_2 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_2.round(4))\n",
        "print('Precision:',precision_2.round(4))\n",
        "print('Recall:',recall_2.round(4))\n",
        "print('F1:',f1_2.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_2.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "yjuu8Ddlhywr",
        "outputId": "ea6bfaa8-272c-4d4d-dc9e-9052326699c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8333\n",
            "Precision: 0.8625\n",
            "Recall: 0.8333\n",
            "F1: 0.8256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8YCa6CaOXjk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing convolutions a bit from model 1\n"
      ],
      "metadata": {
        "id": "KgRGNCArXmMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_3(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "    conv5_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv5)\n",
        "    pool5_2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5_2)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(1,2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5_2)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "STLVE_q9X2kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_3 = build_model_3(input_shape, n_genres)\n",
        "\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWU2sptAYC2P",
        "outputId": "bfff1c16-d333-4113-e37d-71818f81a80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 2559, 4)      64        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 2559, 8)      200       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 1279, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 1279, 16)      784       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 1279, 16)      1552      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 639, 32)       3104      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 319, 64)       12352     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 319, 64)       24640     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 8, 159, 128)       49280     \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 8, 159, 64)        49216     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 79, 64)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 79, 128)        16512     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 128)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 168,205\n",
            "Trainable params: 168,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history_3 = model_3.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM6sAgO1YH_L",
        "outputId": "fe232f07-d06c-441d-c846-8cb4f12def34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 23s 2s/step - loss: 1.5391 - accuracy: 0.2476 - val_loss: 1.4066 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.4609 - accuracy: 0.3048 - val_loss: 1.4093 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 3s 764ms/step - loss: 1.4133 - accuracy: 0.3714 - val_loss: 1.3592 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 1.3697 - accuracy: 0.2952 - val_loss: 1.2658 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 1.3987 - accuracy: 0.3048 - val_loss: 1.3043 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 3s 757ms/step - loss: 1.3308 - accuracy: 0.3238 - val_loss: 1.2764 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 3s 758ms/step - loss: 1.3422 - accuracy: 0.2905 - val_loss: 1.2192 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 1.2220 - accuracy: 0.3524 - val_loss: 1.1867 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 1.2523 - accuracy: 0.4000 - val_loss: 1.1840 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 1.2689 - accuracy: 0.3190 - val_loss: 1.2355 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 3s 756ms/step - loss: 1.2621 - accuracy: 0.3619 - val_loss: 1.1522 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 3s 756ms/step - loss: 1.2290 - accuracy: 0.3190 - val_loss: 1.1235 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 1.2013 - accuracy: 0.3381 - val_loss: 1.1278 - val_accuracy: 0.4667 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 1.1526 - accuracy: 0.3952 - val_loss: 1.0853 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 1.1585 - accuracy: 0.4190 - val_loss: 1.0763 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 1.2366 - accuracy: 0.3381 - val_loss: 1.1031 - val_accuracy: 0.5167 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 3s 757ms/step - loss: 1.1732 - accuracy: 0.3762 - val_loss: 1.1168 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 1.1690 - accuracy: 0.3667 - val_loss: 1.0445 - val_accuracy: 0.3667 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 1.0533 - accuracy: 0.4810 - val_loss: 0.9277 - val_accuracy: 0.4500 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 1.0133 - accuracy: 0.5048 - val_loss: 0.8097 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.9377 - accuracy: 0.5238 - val_loss: 0.9956 - val_accuracy: 0.4833 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.9896 - accuracy: 0.4762 - val_loss: 1.4825 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 1.1261 - accuracy: 0.5190 - val_loss: 1.0455 - val_accuracy: 0.4500 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 1.0140 - accuracy: 0.5667 - val_loss: 0.9787 - val_accuracy: 0.5167 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 1.0786 - accuracy: 0.4571 - val_loss: 0.8725 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.8828 - accuracy: 0.5762 - val_loss: 0.8427 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.8814 - accuracy: 0.6048 - val_loss: 0.7678 - val_accuracy: 0.6333 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.8213 - accuracy: 0.5667 - val_loss: 0.8373 - val_accuracy: 0.5833 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.7622 - accuracy: 0.6429 - val_loss: 0.7291 - val_accuracy: 0.6333 - lr: 5.0000e-04\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.8520 - accuracy: 0.5667 - val_loss: 0.7623 - val_accuracy: 0.6500 - lr: 5.0000e-04\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.7297 - accuracy: 0.6524 - val_loss: 0.6627 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.8575 - accuracy: 0.6143 - val_loss: 0.6980 - val_accuracy: 0.6667 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.7069 - accuracy: 0.6524 - val_loss: 0.6937 - val_accuracy: 0.6667 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.7116 - accuracy: 0.5905 - val_loss: 0.6396 - val_accuracy: 0.7333 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.7149 - accuracy: 0.6524 - val_loss: 0.6418 - val_accuracy: 0.6833 - lr: 5.0000e-04\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.6732 - accuracy: 0.6571 - val_loss: 0.5968 - val_accuracy: 0.7167 - lr: 5.0000e-04\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.6979 - accuracy: 0.6571 - val_loss: 0.6038 - val_accuracy: 0.6833 - lr: 5.0000e-04\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.7105 - accuracy: 0.6952 - val_loss: 0.5423 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.7544 - accuracy: 0.6810 - val_loss: 0.5579 - val_accuracy: 0.7167 - lr: 5.0000e-04\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.7016 - accuracy: 0.6476 - val_loss: 0.7766 - val_accuracy: 0.6000 - lr: 5.0000e-04\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.7527 - accuracy: 0.6286 - val_loss: 0.6761 - val_accuracy: 0.6500 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.8256 - accuracy: 0.6000 - val_loss: 0.5920 - val_accuracy: 0.7167 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.8065 - accuracy: 0.5714 - val_loss: 0.7276 - val_accuracy: 0.6500 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.7730 - accuracy: 0.6476 - val_loss: 0.5948 - val_accuracy: 0.7333 - lr: 2.5000e-04\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.7017 - accuracy: 0.6714 - val_loss: 0.5791 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.6816 - accuracy: 0.7048 - val_loss: 0.5705 - val_accuracy: 0.7333 - lr: 2.5000e-04\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.6901 - accuracy: 0.7000 - val_loss: 0.6050 - val_accuracy: 0.6500 - lr: 2.5000e-04\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.6989 - accuracy: 0.6762 - val_loss: 0.5547 - val_accuracy: 0.7000 - lr: 2.5000e-04\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.6373 - accuracy: 0.7429 - val_loss: 0.5204 - val_accuracy: 0.7333 - lr: 1.2500e-04\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 3s 756ms/step - loss: 0.6407 - accuracy: 0.7095 - val_loss: 0.5119 - val_accuracy: 0.7500 - lr: 1.2500e-04\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.6279 - accuracy: 0.7190 - val_loss: 0.5257 - val_accuracy: 0.7167 - lr: 1.2500e-04\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.6170 - accuracy: 0.7190 - val_loss: 0.5682 - val_accuracy: 0.6833 - lr: 1.2500e-04\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.6307 - accuracy: 0.7143 - val_loss: 0.5406 - val_accuracy: 0.6833 - lr: 1.2500e-04\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.6461 - accuracy: 0.6952 - val_loss: 0.5048 - val_accuracy: 0.7333 - lr: 1.2500e-04\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.6506 - accuracy: 0.7381 - val_loss: 0.4853 - val_accuracy: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.5882 - accuracy: 0.7381 - val_loss: 0.4824 - val_accuracy: 0.7667 - lr: 1.2500e-04\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.6249 - accuracy: 0.7190 - val_loss: 0.5020 - val_accuracy: 0.7000 - lr: 1.2500e-04\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.6046 - accuracy: 0.7095 - val_loss: 0.4970 - val_accuracy: 0.7000 - lr: 1.2500e-04\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.6112 - accuracy: 0.7714 - val_loss: 0.4905 - val_accuracy: 0.7000 - lr: 1.2500e-04\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.5897 - accuracy: 0.7524 - val_loss: 0.4661 - val_accuracy: 0.7500 - lr: 1.2500e-04\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.6314 - accuracy: 0.7381 - val_loss: 0.4717 - val_accuracy: 0.7167 - lr: 1.2500e-04\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.6127 - accuracy: 0.7333 - val_loss: 0.4833 - val_accuracy: 0.7000 - lr: 1.2500e-04\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.6287 - accuracy: 0.7429 - val_loss: 0.5181 - val_accuracy: 0.7333 - lr: 1.2500e-04\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.6384 - accuracy: 0.7429 - val_loss: 0.4623 - val_accuracy: 0.7167 - lr: 1.2500e-04\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.5843 - accuracy: 0.7714 - val_loss: 0.4378 - val_accuracy: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.6140 - accuracy: 0.7286 - val_loss: 0.4456 - val_accuracy: 0.7667 - lr: 1.2500e-04\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.5918 - accuracy: 0.7333 - val_loss: 0.4861 - val_accuracy: 0.7167 - lr: 1.2500e-04\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.6031 - accuracy: 0.7333 - val_loss: 0.5082 - val_accuracy: 0.7167 - lr: 1.2500e-04\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.5818 - accuracy: 0.7667 - val_loss: 0.4601 - val_accuracy: 0.7667 - lr: 1.2500e-04\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.5306 - accuracy: 0.7857 - val_loss: 0.4418 - val_accuracy: 0.7833 - lr: 1.2500e-04\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.6101 - accuracy: 0.7286 - val_loss: 0.4520 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.5934 - accuracy: 0.7714 - val_loss: 0.4397 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.6029 - accuracy: 0.7810 - val_loss: 0.4203 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.5619 - accuracy: 0.7762 - val_loss: 0.4335 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.6126 - accuracy: 0.7143 - val_loss: 0.5535 - val_accuracy: 0.7167 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.6300 - accuracy: 0.6952 - val_loss: 0.4335 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.5713 - accuracy: 0.7524 - val_loss: 0.4153 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.6623 - accuracy: 0.7143 - val_loss: 0.4100 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.5729 - accuracy: 0.7524 - val_loss: 0.4798 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.5201 - accuracy: 0.7952 - val_loss: 0.4890 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.5910 - accuracy: 0.7524 - val_loss: 0.4177 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.6269 - accuracy: 0.7286 - val_loss: 0.4092 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.5826 - accuracy: 0.7190 - val_loss: 0.4434 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.5369 - accuracy: 0.7476 - val_loss: 0.5135 - val_accuracy: 0.7167 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.6080 - accuracy: 0.7190 - val_loss: 0.4478 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 3s 756ms/step - loss: 0.5526 - accuracy: 0.7571 - val_loss: 0.3935 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.5417 - accuracy: 0.7714 - val_loss: 0.3925 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.6320 - accuracy: 0.7571 - val_loss: 0.4259 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.5766 - accuracy: 0.7238 - val_loss: 0.4188 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.5474 - accuracy: 0.7429 - val_loss: 0.4174 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.5295 - accuracy: 0.7810 - val_loss: 0.4106 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.5344 - accuracy: 0.7429 - val_loss: 0.3919 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.4784 - accuracy: 0.8048 - val_loss: 0.4175 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.5987 - accuracy: 0.7429 - val_loss: 0.3990 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.4986 - accuracy: 0.8048 - val_loss: 0.3956 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.5552 - accuracy: 0.7619 - val_loss: 0.3775 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.5089 - accuracy: 0.7857 - val_loss: 0.3721 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.5881 - accuracy: 0.7429 - val_loss: 0.4311 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.5610 - accuracy: 0.7857 - val_loss: 0.3902 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.5125 - accuracy: 0.7667 - val_loss: 0.3623 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.5261 - accuracy: 0.7619 - val_loss: 0.3879 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4590 - accuracy: 0.8238 - val_loss: 0.3863 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.5352 - accuracy: 0.7905 - val_loss: 0.3923 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.5062 - accuracy: 0.8048 - val_loss: 0.3899 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.5090 - accuracy: 0.7762 - val_loss: 0.3736 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.5228 - accuracy: 0.7762 - val_loss: 0.3703 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.4919 - accuracy: 0.7714 - val_loss: 0.3844 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.5631 - accuracy: 0.7571 - val_loss: 0.4261 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.4869 - accuracy: 0.7905 - val_loss: 0.3616 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.5342 - accuracy: 0.7857 - val_loss: 0.3821 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.5163 - accuracy: 0.7952 - val_loss: 0.3629 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.5534 - accuracy: 0.7762 - val_loss: 0.3812 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4531 - accuracy: 0.8190 - val_loss: 0.3936 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.5406 - accuracy: 0.7476 - val_loss: 0.3788 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.4713 - accuracy: 0.8048 - val_loss: 0.3934 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.5793 - accuracy: 0.7619 - val_loss: 0.3805 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.4705 - accuracy: 0.8190 - val_loss: 0.3773 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.5104 - accuracy: 0.8095 - val_loss: 0.3550 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4781 - accuracy: 0.7810 - val_loss: 0.3739 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.4936 - accuracy: 0.8095 - val_loss: 0.3660 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.4918 - accuracy: 0.8190 - val_loss: 0.3644 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.5082 - accuracy: 0.8048 - val_loss: 0.3452 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.4457 - accuracy: 0.8286 - val_loss: 0.3644 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.4842 - accuracy: 0.8095 - val_loss: 0.3678 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.4520 - accuracy: 0.8095 - val_loss: 0.3538 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4572 - accuracy: 0.8000 - val_loss: 0.3288 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.4733 - accuracy: 0.7667 - val_loss: 0.3452 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.4868 - accuracy: 0.8238 - val_loss: 0.3556 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4622 - accuracy: 0.8095 - val_loss: 0.3701 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.4320 - accuracy: 0.8143 - val_loss: 0.3679 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.4614 - accuracy: 0.8238 - val_loss: 0.3147 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.4239 - accuracy: 0.8190 - val_loss: 0.3329 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4867 - accuracy: 0.8238 - val_loss: 0.3396 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4327 - accuracy: 0.8476 - val_loss: 0.3349 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4795 - accuracy: 0.8143 - val_loss: 0.3508 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.4970 - accuracy: 0.8095 - val_loss: 0.3726 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4260 - accuracy: 0.8476 - val_loss: 0.3105 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.4556 - accuracy: 0.8095 - val_loss: 0.3778 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4759 - accuracy: 0.8190 - val_loss: 0.3094 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.4550 - accuracy: 0.8095 - val_loss: 0.4281 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 141/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.5081 - accuracy: 0.7762 - val_loss: 0.3255 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 142/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.4116 - accuracy: 0.8143 - val_loss: 0.3115 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 143/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.4681 - accuracy: 0.7952 - val_loss: 0.4180 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 144/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.4403 - accuracy: 0.8238 - val_loss: 0.4355 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 145/500\n",
            "4/4 [==============================] - 3s 756ms/step - loss: 0.4775 - accuracy: 0.7905 - val_loss: 0.3075 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 146/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.5060 - accuracy: 0.7762 - val_loss: 0.3074 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 147/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4425 - accuracy: 0.8143 - val_loss: 0.3172 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 148/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4255 - accuracy: 0.8619 - val_loss: 0.3479 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 149/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.4235 - accuracy: 0.8190 - val_loss: 0.3075 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 150/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.4588 - accuracy: 0.8429 - val_loss: 0.3193 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 151/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.4680 - accuracy: 0.8000 - val_loss: 0.3450 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 152/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.4329 - accuracy: 0.8286 - val_loss: 0.3065 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 153/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.4492 - accuracy: 0.8000 - val_loss: 0.3169 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 154/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4155 - accuracy: 0.8429 - val_loss: 0.4790 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 155/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.4433 - accuracy: 0.8619 - val_loss: 0.3068 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 156/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.4279 - accuracy: 0.8381 - val_loss: 0.3108 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 157/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4298 - accuracy: 0.8238 - val_loss: 0.4092 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 158/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.4587 - accuracy: 0.8286 - val_loss: 0.3419 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 159/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.4045 - accuracy: 0.8571 - val_loss: 0.2989 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 160/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.3895 - accuracy: 0.8381 - val_loss: 0.4210 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 161/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.4010 - accuracy: 0.8476 - val_loss: 0.3485 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 162/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.3990 - accuracy: 0.8095 - val_loss: 0.2843 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 163/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.4690 - accuracy: 0.8095 - val_loss: 0.3624 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 164/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.4059 - accuracy: 0.8429 - val_loss: 0.3106 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 165/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.4292 - accuracy: 0.8571 - val_loss: 0.3699 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 166/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.4486 - accuracy: 0.8190 - val_loss: 0.3697 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 167/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.3751 - accuracy: 0.8571 - val_loss: 0.2894 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 168/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4124 - accuracy: 0.8476 - val_loss: 0.3734 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 169/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4469 - accuracy: 0.7857 - val_loss: 0.3099 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 170/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.3953 - accuracy: 0.8667 - val_loss: 0.2898 - val_accuracy: 0.9000 - lr: 1.0000e-04\n",
            "Epoch 171/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.3923 - accuracy: 0.8381 - val_loss: 0.3855 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 172/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4406 - accuracy: 0.8286 - val_loss: 0.2838 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 173/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.3813 - accuracy: 0.8762 - val_loss: 0.3885 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 174/500\n",
            "4/4 [==============================] - 3s 752ms/step - loss: 0.3747 - accuracy: 0.8571 - val_loss: 0.3085 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 175/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.3644 - accuracy: 0.8476 - val_loss: 0.2977 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.3709 - accuracy: 0.8524 - val_loss: 0.3565 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.3898 - accuracy: 0.8571 - val_loss: 0.3040 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.4119 - accuracy: 0.8381 - val_loss: 0.2702 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.3515 - accuracy: 0.8762 - val_loss: 0.4591 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4632 - accuracy: 0.8190 - val_loss: 0.3286 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.3456 - accuracy: 0.8667 - val_loss: 0.3122 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "4/4 [==============================] - 3s 759ms/step - loss: 0.3697 - accuracy: 0.8810 - val_loss: 0.4096 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.4328 - accuracy: 0.8381 - val_loss: 0.3149 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "4/4 [==============================] - 3s 754ms/step - loss: 0.3566 - accuracy: 0.8857 - val_loss: 0.3403 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.4037 - accuracy: 0.8524 - val_loss: 0.3125 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.4119 - accuracy: 0.8381 - val_loss: 0.2888 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "4/4 [==============================] - 3s 750ms/step - loss: 0.4031 - accuracy: 0.8476 - val_loss: 0.3256 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.3954 - accuracy: 0.8381 - val_loss: 0.4316 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "4/4 [==============================] - 3s 759ms/step - loss: 0.3979 - accuracy: 0.8095 - val_loss: 0.2911 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 190/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.3619 - accuracy: 0.8762 - val_loss: 0.3145 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 191/500\n",
            "4/4 [==============================] - 3s 753ms/step - loss: 0.3719 - accuracy: 0.8667 - val_loss: 0.3462 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 192/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.3466 - accuracy: 0.8762 - val_loss: 0.3036 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 193/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.4033 - accuracy: 0.8524 - val_loss: 0.2911 - val_accuracy: 0.9333 - lr: 1.0000e-04\n",
            "Epoch 194/500\n",
            "4/4 [==============================] - 3s 755ms/step - loss: 0.3396 - accuracy: 0.8619 - val_loss: 0.4014 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 195/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.3611 - accuracy: 0.8667 - val_loss: 0.3805 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 196/500\n",
            "4/4 [==============================] - 3s 749ms/step - loss: 0.3726 - accuracy: 0.8714 - val_loss: 0.3927 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 197/500\n",
            "4/4 [==============================] - 3s 748ms/step - loss: 0.3680 - accuracy: 0.8810 - val_loss: 0.3158 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 198/500\n",
            "4/4 [==============================] - 3s 757ms/step - loss: 0.3096 - accuracy: 0.8952 - val_loss: 0.3128 - val_accuracy: 0.8833 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_3 = model_3.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_3 = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_3 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1))\n",
        "precision_3= precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1), average='macro')\n",
        "recall_3 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1), average='macro')\n",
        "f1_3 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_3.round(4))\n",
        "print('Precision:',precision_3.round(4))\n",
        "print('Recall:',recall_3.round(4))\n",
        "print('F1:',f1_3.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_3.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "dzHq69TMYT_g",
        "outputId": "942eccf3-6d2a-4b5b-9bc1-fef56bc4cc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8667\n",
            "Precision: 0.8897\n",
            "Recall: 0.8667\n",
            "F1: 0.8644\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving best model"
      ],
      "metadata": {
        "id": "5cYjUmBo9rwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " model_1.save('/gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_5_classes_group1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgWvtaW69sHk",
        "outputId": "3d1cfcea-2d8d-43d5-9424-7d50ca6b5258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_5_classes_group1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_5_classes_group1/assets\n"
          ]
        }
      ]
    }
  ]
}