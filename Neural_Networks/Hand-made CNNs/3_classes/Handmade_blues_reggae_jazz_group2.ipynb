{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_3_classes_group2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "M6wcp-yyg48g",
        "ezzh-uhS5VGv",
        "vRkXU25Vgx8t",
        "qVwce4lBcRI4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##5 classes: blues, reggae, jazz, country, pop\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eff4b8b-8ea0-4f4b-e681-d6ad091b3a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/Colab Notebooks/NAML/Project"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d96c37-8c24-434d-8380-c755f1eee95d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks/NAML/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "# genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "\n",
        "genres = {  'blues': 0, 'reggae': 1, 'jazz': 2}\n",
        "\n",
        "n_genres=3\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6125af35-aeac-48dd-e47e-b4b6bf3b5a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blues done\n",
            "reggae done\n",
            "jazz done\n",
            "country done\n",
            "pop done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(3):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, n_genres))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, n_genres))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, n_genres))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 conv e doppi conv + max pool, last GAP, 2 dense, square filt  "
      ],
      "metadata": {
        "id": "M6wcp-yyg48g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "RNThcfPx1m0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, n_genres)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67f8f67-2098-4fb6-c9fa-1a499bdc7eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 2559, 4)      104       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 2559, 8)      296       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 1279, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 1279, 16)      1168      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 1279, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 639, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 319, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 8, 159, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 79, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 79, 286)        36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,315\n",
            "Trainable params: 195,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c721319-1faa-4cfe-bf8e-69ca117736b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 25s 2s/step - loss: 1.4518 - accuracy: 0.2667 - val_loss: 1.1885 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 3s 763ms/step - loss: 1.2698 - accuracy: 0.3714 - val_loss: 1.1998 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 1.2359 - accuracy: 0.3524 - val_loss: 1.1319 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 3s 766ms/step - loss: 1.2220 - accuracy: 0.3238 - val_loss: 1.1487 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 3s 763ms/step - loss: 1.2229 - accuracy: 0.3429 - val_loss: 1.1419 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 1.2163 - accuracy: 0.3762 - val_loss: 1.1302 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 3s 764ms/step - loss: 1.2251 - accuracy: 0.3476 - val_loss: 1.1689 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.2359 - accuracy: 0.3286 - val_loss: 1.1590 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.1771 - accuracy: 0.3381 - val_loss: 1.1297 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.1963 - accuracy: 0.3714 - val_loss: 1.1207 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 3s 768ms/step - loss: 1.2147 - accuracy: 0.3429 - val_loss: 1.1558 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.2066 - accuracy: 0.3905 - val_loss: 1.1309 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 1.1770 - accuracy: 0.3667 - val_loss: 1.1103 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 1.1574 - accuracy: 0.3524 - val_loss: 1.1072 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.1869 - accuracy: 0.3048 - val_loss: 1.1158 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.1609 - accuracy: 0.3333 - val_loss: 1.1270 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.1764 - accuracy: 0.3190 - val_loss: 1.1183 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.1780 - accuracy: 0.3524 - val_loss: 1.1179 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1655 - accuracy: 0.3190 - val_loss: 1.1156 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.1322 - accuracy: 0.3857 - val_loss: 1.1103 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.1525 - accuracy: 0.3857 - val_loss: 1.1068 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 1.1837 - accuracy: 0.3095 - val_loss: 1.1033 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 1.1488 - accuracy: 0.3667 - val_loss: 1.1064 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 3s 770ms/step - loss: 1.1163 - accuracy: 0.4286 - val_loss: 1.1047 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1549 - accuracy: 0.3048 - val_loss: 1.1044 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1594 - accuracy: 0.3286 - val_loss: 1.1053 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 1.1331 - accuracy: 0.3333 - val_loss: 1.1079 - val_accuracy: 0.3333 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.1494 - accuracy: 0.3762 - val_loss: 1.1084 - val_accuracy: 0.3333 - lr: 2.5000e-04\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1770 - accuracy: 0.3000 - val_loss: 1.1117 - val_accuracy: 0.3333 - lr: 2.5000e-04\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1713 - accuracy: 0.3095 - val_loss: 1.1164 - val_accuracy: 0.3333 - lr: 2.5000e-04\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.1557 - accuracy: 0.3524 - val_loss: 1.1145 - val_accuracy: 0.3333 - lr: 2.5000e-04\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1257 - accuracy: 0.4286 - val_loss: 1.1053 - val_accuracy: 0.3333 - lr: 2.5000e-04\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.1334 - accuracy: 0.3714 - val_loss: 1.1018 - val_accuracy: 0.3333 - lr: 1.2500e-04\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.1680 - accuracy: 0.3286 - val_loss: 1.1005 - val_accuracy: 0.3333 - lr: 1.2500e-04\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 3s 768ms/step - loss: 1.1612 - accuracy: 0.3143 - val_loss: 1.1005 - val_accuracy: 0.3333 - lr: 1.2500e-04\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 3s 769ms/step - loss: 1.1316 - accuracy: 0.3905 - val_loss: 1.1011 - val_accuracy: 0.3333 - lr: 1.2500e-04\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 1.1462 - accuracy: 0.3810 - val_loss: 1.1012 - val_accuracy: 0.3333 - lr: 1.2500e-04\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 1.1502 - accuracy: 0.3667 - val_loss: 1.1010 - val_accuracy: 0.3833 - lr: 1.2500e-04\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 1.1439 - accuracy: 0.3571 - val_loss: 1.1020 - val_accuracy: 0.4500 - lr: 1.2500e-04\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 1.1366 - accuracy: 0.3619 - val_loss: 1.1019 - val_accuracy: 0.5167 - lr: 1.0000e-04\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1132 - accuracy: 0.4190 - val_loss: 1.0982 - val_accuracy: 0.4833 - lr: 1.0000e-04\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 1.1516 - accuracy: 0.3619 - val_loss: 1.0959 - val_accuracy: 0.4833 - lr: 1.0000e-04\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.1787 - accuracy: 0.3190 - val_loss: 1.0965 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1468 - accuracy: 0.3429 - val_loss: 1.0976 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.1301 - accuracy: 0.3857 - val_loss: 1.0951 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 1.1000 - accuracy: 0.4048 - val_loss: 1.0868 - val_accuracy: 0.4333 - lr: 1.0000e-04\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.1289 - accuracy: 0.3619 - val_loss: 1.0794 - val_accuracy: 0.3833 - lr: 1.0000e-04\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.1473 - accuracy: 0.3476 - val_loss: 1.0762 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.1549 - accuracy: 0.3429 - val_loss: 1.0758 - val_accuracy: 0.4500 - lr: 1.0000e-04\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 1.1355 - accuracy: 0.3571 - val_loss: 1.0753 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 1.1376 - accuracy: 0.3333 - val_loss: 1.0710 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.1178 - accuracy: 0.3857 - val_loss: 1.0684 - val_accuracy: 0.4667 - lr: 1.0000e-04\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.1215 - accuracy: 0.3905 - val_loss: 1.0656 - val_accuracy: 0.5167 - lr: 1.0000e-04\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 3s 770ms/step - loss: 1.1017 - accuracy: 0.4000 - val_loss: 1.0588 - val_accuracy: 0.3833 - lr: 1.0000e-04\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.0946 - accuracy: 0.4238 - val_loss: 1.0525 - val_accuracy: 0.4000 - lr: 1.0000e-04\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 1.1702 - accuracy: 0.3238 - val_loss: 1.0549 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 3s 768ms/step - loss: 1.0995 - accuracy: 0.3286 - val_loss: 1.0555 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 1.1340 - accuracy: 0.3857 - val_loss: 1.0446 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 1.0869 - accuracy: 0.4429 - val_loss: 1.0350 - val_accuracy: 0.5000 - lr: 1.0000e-04\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.0969 - accuracy: 0.4333 - val_loss: 1.0359 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.0818 - accuracy: 0.4286 - val_loss: 1.0393 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 1.0838 - accuracy: 0.4238 - val_loss: 1.0274 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 1.0687 - accuracy: 0.4667 - val_loss: 1.0087 - val_accuracy: 0.5333 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 1.0788 - accuracy: 0.4000 - val_loss: 1.0000 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 1.0582 - accuracy: 0.4619 - val_loss: 1.0110 - val_accuracy: 0.6000 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 1.0730 - accuracy: 0.4381 - val_loss: 1.0137 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.0969 - accuracy: 0.4048 - val_loss: 0.9910 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 1.0443 - accuracy: 0.4619 - val_loss: 0.9757 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.0947 - accuracy: 0.3952 - val_loss: 0.9747 - val_accuracy: 0.6167 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 1.0650 - accuracy: 0.4429 - val_loss: 0.9885 - val_accuracy: 0.5667 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 1.0366 - accuracy: 0.4714 - val_loss: 0.9859 - val_accuracy: 0.5500 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 1.0660 - accuracy: 0.4619 - val_loss: 0.9761 - val_accuracy: 0.6333 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 1.0283 - accuracy: 0.5190 - val_loss: 0.9552 - val_accuracy: 0.6500 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 1.0638 - accuracy: 0.4476 - val_loss: 0.9359 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 1.0232 - accuracy: 0.5381 - val_loss: 0.9380 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 1.0281 - accuracy: 0.4810 - val_loss: 0.9543 - val_accuracy: 0.7167 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 1.0469 - accuracy: 0.5143 - val_loss: 0.9322 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 1.0129 - accuracy: 0.4810 - val_loss: 0.8867 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.9906 - accuracy: 0.5429 - val_loss: 0.8795 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.9554 - accuracy: 0.5905 - val_loss: 0.8671 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 0.9402 - accuracy: 0.5905 - val_loss: 0.8616 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.9507 - accuracy: 0.5524 - val_loss: 0.8434 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.9494 - accuracy: 0.5667 - val_loss: 0.8010 - val_accuracy: 0.7167 - lr: 1.0000e-04\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 0.9047 - accuracy: 0.6095 - val_loss: 0.7782 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.8758 - accuracy: 0.6048 - val_loss: 0.7599 - val_accuracy: 0.7667 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.8869 - accuracy: 0.6238 - val_loss: 0.7713 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 3s 770ms/step - loss: 0.9128 - accuracy: 0.6286 - val_loss: 0.7667 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.8473 - accuracy: 0.6238 - val_loss: 0.7372 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.8329 - accuracy: 0.6476 - val_loss: 0.7248 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 3s 769ms/step - loss: 0.9013 - accuracy: 0.6524 - val_loss: 0.7287 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.7986 - accuracy: 0.6619 - val_loss: 0.7085 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.8123 - accuracy: 0.6952 - val_loss: 0.6932 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 0.7960 - accuracy: 0.7143 - val_loss: 0.6846 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 0.8837 - accuracy: 0.6429 - val_loss: 0.6789 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 3s 769ms/step - loss: 0.7671 - accuracy: 0.6905 - val_loss: 0.6781 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.7840 - accuracy: 0.7190 - val_loss: 0.6660 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.7292 - accuracy: 0.7048 - val_loss: 0.6592 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 3s 766ms/step - loss: 0.8262 - accuracy: 0.6476 - val_loss: 0.6871 - val_accuracy: 0.7167 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.7609 - accuracy: 0.6857 - val_loss: 0.6499 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.7737 - accuracy: 0.7286 - val_loss: 0.6325 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.7510 - accuracy: 0.7000 - val_loss: 0.6475 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.7731 - accuracy: 0.7048 - val_loss: 0.6303 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.7736 - accuracy: 0.7000 - val_loss: 0.6502 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.7692 - accuracy: 0.6857 - val_loss: 0.6524 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.7720 - accuracy: 0.7333 - val_loss: 0.6218 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.7367 - accuracy: 0.7333 - val_loss: 0.6229 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.7163 - accuracy: 0.7333 - val_loss: 0.6057 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "4/4 [==============================] - 3s 769ms/step - loss: 0.7229 - accuracy: 0.7286 - val_loss: 0.6088 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 0.7203 - accuracy: 0.7429 - val_loss: 0.5880 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.7166 - accuracy: 0.7524 - val_loss: 0.5910 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.7205 - accuracy: 0.7190 - val_loss: 0.5865 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.6918 - accuracy: 0.7381 - val_loss: 0.5747 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.6823 - accuracy: 0.7524 - val_loss: 0.5874 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.7233 - accuracy: 0.7476 - val_loss: 0.5638 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.6967 - accuracy: 0.7333 - val_loss: 0.5609 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 0.7190 - accuracy: 0.7571 - val_loss: 0.6461 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 0.6668 - accuracy: 0.7571 - val_loss: 0.5477 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.7038 - accuracy: 0.7048 - val_loss: 0.5496 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "4/4 [==============================] - 3s 772ms/step - loss: 0.7494 - accuracy: 0.7429 - val_loss: 0.5613 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.6524 - accuracy: 0.7429 - val_loss: 0.5614 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.6550 - accuracy: 0.7286 - val_loss: 0.5491 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "4/4 [==============================] - 3s 770ms/step - loss: 0.6081 - accuracy: 0.7429 - val_loss: 0.5529 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.5756 - accuracy: 0.7810 - val_loss: 0.5322 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.6123 - accuracy: 0.7524 - val_loss: 0.5172 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.6613 - accuracy: 0.7476 - val_loss: 0.5232 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 0.6727 - accuracy: 0.7810 - val_loss: 0.5431 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.6377 - accuracy: 0.7524 - val_loss: 0.5093 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.6317 - accuracy: 0.8095 - val_loss: 0.5904 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.6697 - accuracy: 0.7571 - val_loss: 0.5576 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.6460 - accuracy: 0.7429 - val_loss: 0.5647 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.6653 - accuracy: 0.7762 - val_loss: 0.5196 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.6397 - accuracy: 0.7429 - val_loss: 0.5642 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.6363 - accuracy: 0.7381 - val_loss: 0.5616 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.6086 - accuracy: 0.7762 - val_loss: 0.5286 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.6020 - accuracy: 0.7524 - val_loss: 0.5396 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.6090 - accuracy: 0.8048 - val_loss: 0.5075 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "4/4 [==============================] - 3s 771ms/step - loss: 0.6203 - accuracy: 0.7857 - val_loss: 0.5300 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.6153 - accuracy: 0.7571 - val_loss: 0.5311 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "4/4 [==============================] - 3s 788ms/step - loss: 0.5870 - accuracy: 0.7905 - val_loss: 0.5031 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.5886 - accuracy: 0.8048 - val_loss: 0.5206 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 141/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.5853 - accuracy: 0.7905 - val_loss: 0.4890 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 142/500\n",
            "4/4 [==============================] - 3s 784ms/step - loss: 0.5704 - accuracy: 0.7810 - val_loss: 0.4957 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 143/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.5688 - accuracy: 0.8048 - val_loss: 0.4917 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 144/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.5063 - accuracy: 0.8000 - val_loss: 0.4804 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 145/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.5459 - accuracy: 0.7952 - val_loss: 0.4824 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 146/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.5430 - accuracy: 0.8143 - val_loss: 0.4782 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 147/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.4557 - accuracy: 0.8286 - val_loss: 0.4919 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 148/500\n",
            "4/4 [==============================] - 3s 785ms/step - loss: 0.5358 - accuracy: 0.7667 - val_loss: 0.4947 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 149/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.4929 - accuracy: 0.8095 - val_loss: 0.5136 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 150/500\n",
            "4/4 [==============================] - 3s 783ms/step - loss: 0.4927 - accuracy: 0.7952 - val_loss: 0.4864 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 151/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.5886 - accuracy: 0.8095 - val_loss: 0.5572 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 152/500\n",
            "4/4 [==============================] - 3s 781ms/step - loss: 0.6429 - accuracy: 0.7762 - val_loss: 0.4767 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 153/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.5927 - accuracy: 0.8000 - val_loss: 0.4801 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 154/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.5528 - accuracy: 0.7857 - val_loss: 0.5533 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 155/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.5601 - accuracy: 0.7905 - val_loss: 0.4805 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 156/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.5018 - accuracy: 0.8286 - val_loss: 0.5173 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 157/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.5665 - accuracy: 0.7952 - val_loss: 0.4903 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 158/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.5301 - accuracy: 0.8190 - val_loss: 0.5043 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 159/500\n",
            "4/4 [==============================] - 3s 774ms/step - loss: 0.5181 - accuracy: 0.7857 - val_loss: 0.5217 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 160/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.5039 - accuracy: 0.8000 - val_loss: 0.4750 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 161/500\n",
            "4/4 [==============================] - 3s 785ms/step - loss: 0.4803 - accuracy: 0.8238 - val_loss: 0.4750 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 162/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.5559 - accuracy: 0.7857 - val_loss: 0.5557 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 163/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.5299 - accuracy: 0.7857 - val_loss: 0.5511 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 164/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.6159 - accuracy: 0.7905 - val_loss: 0.4951 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 165/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.5339 - accuracy: 0.8000 - val_loss: 0.5330 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 166/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.5446 - accuracy: 0.8095 - val_loss: 0.4632 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 167/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.5233 - accuracy: 0.8190 - val_loss: 0.5143 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 168/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.5444 - accuracy: 0.8000 - val_loss: 0.4863 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 169/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.5263 - accuracy: 0.8143 - val_loss: 0.4672 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 170/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.5259 - accuracy: 0.8238 - val_loss: 0.4699 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 171/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.4922 - accuracy: 0.8333 - val_loss: 0.4750 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 172/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 0.4785 - accuracy: 0.8143 - val_loss: 0.4865 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 173/500\n",
            "4/4 [==============================] - 3s 773ms/step - loss: 0.5193 - accuracy: 0.7952 - val_loss: 0.4718 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 174/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.4620 - accuracy: 0.8429 - val_loss: 0.4711 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 175/500\n",
            "4/4 [==============================] - 3s 782ms/step - loss: 0.4727 - accuracy: 0.8095 - val_loss: 0.4813 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.4264 - accuracy: 0.8667 - val_loss: 0.5192 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.4255 - accuracy: 0.8286 - val_loss: 0.5017 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.4949 - accuracy: 0.8048 - val_loss: 0.4833 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "4/4 [==============================] - 3s 779ms/step - loss: 0.4658 - accuracy: 0.8381 - val_loss: 0.4717 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.4421 - accuracy: 0.8476 - val_loss: 0.4827 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "4/4 [==============================] - 3s 778ms/step - loss: 0.5130 - accuracy: 0.8048 - val_loss: 0.5187 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.4277 - accuracy: 0.8286 - val_loss: 0.5010 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "4/4 [==============================] - 3s 776ms/step - loss: 0.4131 - accuracy: 0.8476 - val_loss: 0.5456 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "4/4 [==============================] - 3s 777ms/step - loss: 0.4516 - accuracy: 0.8476 - val_loss: 0.4726 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "4/4 [==============================] - 3s 775ms/step - loss: 0.4556 - accuracy: 0.7952 - val_loss: 0.4742 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "4/4 [==============================] - 3s 780ms/step - loss: 0.4043 - accuracy: 0.8952 - val_loss: 0.5082 - val_accuracy: 0.8667 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "cafe14fa-a9d9-4094-c937-fd8e1b879e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8667\n",
            "Precision: 0.869\n",
            "Recall: 0.8667\n",
            "F1: 0.8664\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###As before but rect filt"
      ],
      "metadata": {
        "id": "ezzh-uhS5VGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_1(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "s1LzDfg45bYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_1 = build_model_1(input_shape, n_genres)\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "Z02qBdCF5hHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191c86b9-ae83-416f-837e-a6ac54e3cbb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 128, 2559, 4)      64        \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 128, 2559, 8)      200       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 64, 1279, 8)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 64, 1279, 16)      784       \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 64, 1279, 16)      1552      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 32, 639, 32)       3104      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 319, 64)       12352     \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 16, 319, 64)       24640     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 8, 159, 128)       49280     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 4, 79, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 4, 79, 286)        73502     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 186,091\n",
            "Trainable params: 186,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history_1 = model_1.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "xlS82usv5kJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3009968f-10a8-4767-e9e6-a8f3f9b5a435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 11s 2s/step - loss: 1.5429 - accuracy: 0.2905 - val_loss: 1.2273 - val_accuracy: 0.3667 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 1.4290 - accuracy: 0.2571 - val_loss: 1.3078 - val_accuracy: 0.3833 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 1.2816 - accuracy: 0.4000 - val_loss: 1.2013 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 1.3354 - accuracy: 0.2952 - val_loss: 1.1566 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 1.2781 - accuracy: 0.3714 - val_loss: 1.1777 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 1.2869 - accuracy: 0.2857 - val_loss: 1.2030 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 1.2834 - accuracy: 0.2952 - val_loss: 1.1749 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 1.2593 - accuracy: 0.2714 - val_loss: 1.1377 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 1.2605 - accuracy: 0.2905 - val_loss: 1.1458 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 3s 730ms/step - loss: 1.2157 - accuracy: 0.3571 - val_loss: 1.1565 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 3s 733ms/step - loss: 1.2237 - accuracy: 0.3571 - val_loss: 1.1320 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 1.2269 - accuracy: 0.3143 - val_loss: 1.1244 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 1.2167 - accuracy: 0.3333 - val_loss: 1.1362 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 1.2142 - accuracy: 0.3286 - val_loss: 1.1359 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 1.2129 - accuracy: 0.3381 - val_loss: 1.1271 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 1.1672 - accuracy: 0.3714 - val_loss: 1.1182 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 1.1712 - accuracy: 0.3476 - val_loss: 1.0862 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 1.2211 - accuracy: 0.3524 - val_loss: 1.0663 - val_accuracy: 0.3833 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 1.1249 - accuracy: 0.3905 - val_loss: 1.0716 - val_accuracy: 0.3500 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 1.1360 - accuracy: 0.3952 - val_loss: 1.0569 - val_accuracy: 0.5167 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 1.0909 - accuracy: 0.4667 - val_loss: 0.9975 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 1.1584 - accuracy: 0.4000 - val_loss: 1.0722 - val_accuracy: 0.3833 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 1.0924 - accuracy: 0.4429 - val_loss: 1.1181 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 1.1325 - accuracy: 0.3810 - val_loss: 1.0874 - val_accuracy: 0.3667 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 1.0778 - accuracy: 0.4333 - val_loss: 1.0206 - val_accuracy: 0.5333 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 1.0632 - accuracy: 0.4762 - val_loss: 0.9489 - val_accuracy: 0.4500 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.9634 - accuracy: 0.5095 - val_loss: 0.9791 - val_accuracy: 0.4833 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 1.0143 - accuracy: 0.5143 - val_loss: 1.0427 - val_accuracy: 0.4333 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.9821 - accuracy: 0.5190 - val_loss: 0.8581 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.9171 - accuracy: 0.5905 - val_loss: 0.8665 - val_accuracy: 0.5833 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.8759 - accuracy: 0.5810 - val_loss: 0.7260 - val_accuracy: 0.6000 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.7836 - accuracy: 0.6381 - val_loss: 0.7040 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.8046 - accuracy: 0.6095 - val_loss: 0.8506 - val_accuracy: 0.6333 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.7887 - accuracy: 0.6143 - val_loss: 0.6669 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.7219 - accuracy: 0.6952 - val_loss: 0.6285 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.7002 - accuracy: 0.6571 - val_loss: 0.6232 - val_accuracy: 0.6833 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.6976 - accuracy: 0.6524 - val_loss: 0.7258 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.6720 - accuracy: 0.6762 - val_loss: 0.6347 - val_accuracy: 0.7167 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.7469 - accuracy: 0.6524 - val_loss: 0.5741 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.7627 - accuracy: 0.6810 - val_loss: 0.8303 - val_accuracy: 0.6167 - lr: 0.0010\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.8630 - accuracy: 0.6048 - val_loss: 0.5720 - val_accuracy: 0.8000 - lr: 0.0010\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.7829 - accuracy: 0.6571 - val_loss: 1.0498 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.9073 - accuracy: 0.6000 - val_loss: 0.7503 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.8910 - accuracy: 0.6190 - val_loss: 0.6753 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.7055 - accuracy: 0.7571 - val_loss: 0.7598 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 46/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.6747 - accuracy: 0.7000 - val_loss: 0.6091 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 47/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.6976 - accuracy: 0.6762 - val_loss: 0.6680 - val_accuracy: 0.7333 - lr: 5.0000e-04\n",
            "Epoch 48/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.6610 - accuracy: 0.7429 - val_loss: 0.5623 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 49/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.5964 - accuracy: 0.7476 - val_loss: 0.5664 - val_accuracy: 0.7667 - lr: 5.0000e-04\n",
            "Epoch 50/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.5852 - accuracy: 0.7905 - val_loss: 0.5790 - val_accuracy: 0.7667 - lr: 5.0000e-04\n",
            "Epoch 51/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.5935 - accuracy: 0.7810 - val_loss: 0.5013 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 52/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.5735 - accuracy: 0.7952 - val_loss: 0.5569 - val_accuracy: 0.7667 - lr: 5.0000e-04\n",
            "Epoch 53/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.6181 - accuracy: 0.7762 - val_loss: 0.5685 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 54/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.7014 - accuracy: 0.7095 - val_loss: 0.4800 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 55/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.5359 - accuracy: 0.7952 - val_loss: 0.5756 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 56/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.6011 - accuracy: 0.7667 - val_loss: 0.4899 - val_accuracy: 0.7667 - lr: 5.0000e-04\n",
            "Epoch 57/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.5431 - accuracy: 0.7905 - val_loss: 0.4786 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 58/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.5084 - accuracy: 0.8238 - val_loss: 0.6311 - val_accuracy: 0.7500 - lr: 5.0000e-04\n",
            "Epoch 59/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.5496 - accuracy: 0.7762 - val_loss: 0.4481 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 60/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.5606 - accuracy: 0.7905 - val_loss: 0.4226 - val_accuracy: 0.8667 - lr: 5.0000e-04\n",
            "Epoch 61/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.5235 - accuracy: 0.8429 - val_loss: 0.5893 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 62/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.5159 - accuracy: 0.8095 - val_loss: 0.4460 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 63/500\n",
            "4/4 [==============================] - 3s 746ms/step - loss: 0.4956 - accuracy: 0.8190 - val_loss: 0.4362 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 64/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.4660 - accuracy: 0.8333 - val_loss: 0.4917 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 65/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.4593 - accuracy: 0.8190 - val_loss: 0.4988 - val_accuracy: 0.8500 - lr: 5.0000e-04\n",
            "Epoch 66/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.5313 - accuracy: 0.8095 - val_loss: 0.4615 - val_accuracy: 0.8167 - lr: 2.5000e-04\n",
            "Epoch 67/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.4496 - accuracy: 0.8238 - val_loss: 0.4520 - val_accuracy: 0.7833 - lr: 2.5000e-04\n",
            "Epoch 68/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.4479 - accuracy: 0.8333 - val_loss: 0.4102 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 69/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.4116 - accuracy: 0.8476 - val_loss: 0.4079 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 70/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.4219 - accuracy: 0.8714 - val_loss: 0.4569 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 71/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.4417 - accuracy: 0.8333 - val_loss: 0.4883 - val_accuracy: 0.7833 - lr: 2.5000e-04\n",
            "Epoch 72/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.4279 - accuracy: 0.8524 - val_loss: 0.4048 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 73/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.4492 - accuracy: 0.8619 - val_loss: 0.4670 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 74/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.4265 - accuracy: 0.8429 - val_loss: 0.4600 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 75/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.4143 - accuracy: 0.8524 - val_loss: 0.4205 - val_accuracy: 0.8500 - lr: 2.5000e-04\n",
            "Epoch 76/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.4376 - accuracy: 0.8286 - val_loss: 0.4220 - val_accuracy: 0.8667 - lr: 2.5000e-04\n",
            "Epoch 77/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.4049 - accuracy: 0.8571 - val_loss: 0.4082 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 78/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3616 - accuracy: 0.8714 - val_loss: 0.4087 - val_accuracy: 0.8667 - lr: 1.2500e-04\n",
            "Epoch 79/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.3763 - accuracy: 0.8571 - val_loss: 0.4132 - val_accuracy: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 80/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.4075 - accuracy: 0.8476 - val_loss: 0.4126 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 81/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.3936 - accuracy: 0.8762 - val_loss: 0.4230 - val_accuracy: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 82/500\n",
            "4/4 [==============================] - 3s 747ms/step - loss: 0.3924 - accuracy: 0.8810 - val_loss: 0.3972 - val_accuracy: 0.8333 - lr: 1.2500e-04\n",
            "Epoch 83/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.3999 - accuracy: 0.8381 - val_loss: 0.3723 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 84/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3745 - accuracy: 0.8667 - val_loss: 0.3992 - val_accuracy: 0.8667 - lr: 1.2500e-04\n",
            "Epoch 85/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.3540 - accuracy: 0.8714 - val_loss: 0.4153 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 86/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.3474 - accuracy: 0.8619 - val_loss: 0.3985 - val_accuracy: 0.8667 - lr: 1.2500e-04\n",
            "Epoch 87/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3708 - accuracy: 0.8619 - val_loss: 0.4016 - val_accuracy: 0.8500 - lr: 1.2500e-04\n",
            "Epoch 88/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3625 - accuracy: 0.8667 - val_loss: 0.4003 - val_accuracy: 0.8667 - lr: 1.2500e-04\n",
            "Epoch 89/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3701 - accuracy: 0.8619 - val_loss: 0.4044 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3775 - accuracy: 0.8524 - val_loss: 0.4120 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "4/4 [==============================] - 3s 734ms/step - loss: 0.3227 - accuracy: 0.9000 - val_loss: 0.3960 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3569 - accuracy: 0.8476 - val_loss: 0.4050 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3617 - accuracy: 0.8810 - val_loss: 0.3854 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.3503 - accuracy: 0.8667 - val_loss: 0.3768 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3793 - accuracy: 0.8667 - val_loss: 0.4082 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3581 - accuracy: 0.8619 - val_loss: 0.4372 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3628 - accuracy: 0.8905 - val_loss: 0.3975 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.4228 - accuracy: 0.8190 - val_loss: 0.3655 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.3741 - accuracy: 0.8429 - val_loss: 0.3652 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3422 - accuracy: 0.8857 - val_loss: 0.3979 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "4/4 [==============================] - 3s 738ms/step - loss: 0.3113 - accuracy: 0.8857 - val_loss: 0.4557 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "4/4 [==============================] - 3s 732ms/step - loss: 0.3393 - accuracy: 0.8714 - val_loss: 0.4369 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3786 - accuracy: 0.8857 - val_loss: 0.3965 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.3402 - accuracy: 0.8905 - val_loss: 0.3665 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.3453 - accuracy: 0.8667 - val_loss: 0.3634 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3615 - accuracy: 0.8714 - val_loss: 0.3748 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "4/4 [==============================] - 3s 736ms/step - loss: 0.3186 - accuracy: 0.9000 - val_loss: 0.4350 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3864 - accuracy: 0.8762 - val_loss: 0.4204 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "4/4 [==============================] - 3s 767ms/step - loss: 0.3643 - accuracy: 0.8810 - val_loss: 0.3827 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3172 - accuracy: 0.9048 - val_loss: 0.3926 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.2948 - accuracy: 0.9143 - val_loss: 0.3900 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "4/4 [==============================] - 3s 737ms/step - loss: 0.3326 - accuracy: 0.8857 - val_loss: 0.3936 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3467 - accuracy: 0.8714 - val_loss: 0.3948 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "4/4 [==============================] - 3s 740ms/step - loss: 0.3544 - accuracy: 0.8714 - val_loss: 0.4004 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "4/4 [==============================] - 3s 741ms/step - loss: 0.3203 - accuracy: 0.9000 - val_loss: 0.3735 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "4/4 [==============================] - 3s 739ms/step - loss: 0.3179 - accuracy: 0.9000 - val_loss: 0.3655 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "4/4 [==============================] - 3s 735ms/step - loss: 0.3317 - accuracy: 0.8762 - val_loss: 0.4040 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.2997 - accuracy: 0.8952 - val_loss: 0.4117 - val_accuracy: 0.8167 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "4/4 [==============================] - 3s 745ms/step - loss: 0.3365 - accuracy: 0.8857 - val_loss: 0.3903 - val_accuracy: 0.8500 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "4/4 [==============================] - 3s 744ms/step - loss: 0.2915 - accuracy: 0.8905 - val_loss: 0.3728 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.3332 - accuracy: 0.8857 - val_loss: 0.3852 - val_accuracy: 0.8667 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.3108 - accuracy: 0.8857 - val_loss: 0.4752 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "4/4 [==============================] - 3s 743ms/step - loss: 0.3582 - accuracy: 0.8714 - val_loss: 0.5058 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "4/4 [==============================] - 3s 742ms/step - loss: 0.2919 - accuracy: 0.8857 - val_loss: 0.3971 - val_accuracy: 0.8333 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "4/4 [==============================] - 3s 751ms/step - loss: 0.2817 - accuracy: 0.9333 - val_loss: 0.3715 - val_accuracy: 0.8833 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1 = model_1.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_1 = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_1 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1))\n",
        "precision_1 = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "recall_1 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "f1_1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_1.round(4))\n",
        "print('Precision:',precision_1.round(4))\n",
        "print('Recall:',recall_1.round(4))\n",
        "print('F1:',f1_1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_1.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8NwAhCEP5pRs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "d0305ce9-2919-4b88-aedb-f26f0a777790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Precision: 0.9141\n",
            "Recall: 0.9\n",
            "F1: 0.895\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 conv + max pool, 2 dense, square filt but last 2 rect"
      ],
      "metadata": {
        "id": "vRkXU25Vgx8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_2(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 3)\n",
        "    )(conv4)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 3)\n",
        "    )(conv5)\n",
        "\n",
        "\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    classifier_layer = tfkl.Dropout(0.2, seed=seed)(classifier_layer)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "vbTCYkHKhp_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_2 = build_model_2(input_shape, n_genres)\n",
        "\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "vnsAjSP9hsz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6339afb9-ab89-4982-d73c-a67aad6549b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 128, 2559, 16)     160       \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 64, 1279, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 64, 1279, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 32, 639, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 32, 639, 64)       18496     \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 16, 319, 64)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 8, 106, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 8, 106, 128)       32896     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 4, 35, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 17920)             0         \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 17920)             0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                1146944   \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,240,389\n",
            "Trainable params: 1,240,389\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first_callbacks = create_folders_and_callbacks(model_name='first')\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=2)\n",
        "\n",
        "standard_history_2 = model_2.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 90,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping]\n",
        "    )"
      ],
      "metadata": {
        "id": "6Ms4zNzfhvuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f93ac4-e18c-4601-8682-e41ba601a022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/90\n",
            "4/4 [==============================] - 11s 2s/step - loss: 14.8571 - accuracy: 0.3381 - val_loss: 2.4329 - val_accuracy: 0.3333\n",
            "Epoch 2/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 2.4970 - accuracy: 0.3619 - val_loss: 1.5233 - val_accuracy: 0.4333\n",
            "Epoch 3/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.4612 - accuracy: 0.3333 - val_loss: 1.1270 - val_accuracy: 0.3333\n",
            "Epoch 4/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.1439 - accuracy: 0.3952 - val_loss: 1.1197 - val_accuracy: 0.3333\n",
            "Epoch 5/90\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 1.1632 - accuracy: 0.3286 - val_loss: 1.1113 - val_accuracy: 0.3333\n",
            "Epoch 6/90\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 1.1336 - accuracy: 0.3429 - val_loss: 1.0912 - val_accuracy: 0.3333\n",
            "Epoch 7/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 1.0947 - accuracy: 0.3810 - val_loss: 1.1028 - val_accuracy: 0.3333\n",
            "Epoch 8/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 1.1285 - accuracy: 0.3619 - val_loss: 1.0637 - val_accuracy: 0.4000\n",
            "Epoch 9/90\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 1.0936 - accuracy: 0.3952 - val_loss: 1.0637 - val_accuracy: 0.4167\n",
            "Epoch 10/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 1.0781 - accuracy: 0.4429 - val_loss: 1.0312 - val_accuracy: 0.4333\n",
            "Epoch 11/90\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 1.0708 - accuracy: 0.4048 - val_loss: 0.9948 - val_accuracy: 0.4500\n",
            "Epoch 12/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.9962 - accuracy: 0.4714 - val_loss: 0.9582 - val_accuracy: 0.6000\n",
            "Epoch 13/90\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.9823 - accuracy: 0.5333 - val_loss: 0.9096 - val_accuracy: 0.6000\n",
            "Epoch 14/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.9031 - accuracy: 0.5810 - val_loss: 0.8935 - val_accuracy: 0.5500\n",
            "Epoch 15/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.9474 - accuracy: 0.5524 - val_loss: 0.8254 - val_accuracy: 0.6833\n",
            "Epoch 16/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.8572 - accuracy: 0.6333 - val_loss: 0.7916 - val_accuracy: 0.7000\n",
            "Epoch 17/90\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.8370 - accuracy: 0.6524 - val_loss: 0.7428 - val_accuracy: 0.7667\n",
            "Epoch 18/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.7359 - accuracy: 0.7000 - val_loss: 0.7146 - val_accuracy: 0.7167\n",
            "Epoch 19/90\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.7425 - accuracy: 0.7143 - val_loss: 0.6353 - val_accuracy: 0.7500\n",
            "Epoch 20/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.6768 - accuracy: 0.7238 - val_loss: 0.6388 - val_accuracy: 0.7833\n",
            "Epoch 21/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.6298 - accuracy: 0.7000 - val_loss: 0.6578 - val_accuracy: 0.7667\n",
            "Epoch 22/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.5555 - accuracy: 0.8143 - val_loss: 0.6270 - val_accuracy: 0.7667\n",
            "Epoch 23/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.5381 - accuracy: 0.7857 - val_loss: 0.5402 - val_accuracy: 0.7667\n",
            "Epoch 24/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.5503 - accuracy: 0.7762 - val_loss: 0.5564 - val_accuracy: 0.8000\n",
            "Epoch 25/90\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.5348 - accuracy: 0.7762 - val_loss: 0.5902 - val_accuracy: 0.7833\n",
            "Epoch 26/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.4602 - accuracy: 0.8333 - val_loss: 0.5571 - val_accuracy: 0.7833\n",
            "Epoch 27/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.4849 - accuracy: 0.8190 - val_loss: 0.6848 - val_accuracy: 0.7500\n",
            "Epoch 28/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.5257 - accuracy: 0.7857 - val_loss: 0.5875 - val_accuracy: 0.7500\n",
            "Epoch 29/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.4612 - accuracy: 0.8095 - val_loss: 0.5649 - val_accuracy: 0.7833\n",
            "Epoch 30/90\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.3682 - accuracy: 0.8667 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
            "Epoch 31/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.3603 - accuracy: 0.8476 - val_loss: 0.5628 - val_accuracy: 0.8167\n",
            "Epoch 32/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.3272 - accuracy: 0.8857 - val_loss: 0.6541 - val_accuracy: 0.7833\n",
            "Epoch 33/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.2851 - accuracy: 0.8857 - val_loss: 0.5287 - val_accuracy: 0.8167\n",
            "Epoch 34/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.2977 - accuracy: 0.8857 - val_loss: 0.5316 - val_accuracy: 0.8000\n",
            "Epoch 35/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.2684 - accuracy: 0.9238 - val_loss: 0.5817 - val_accuracy: 0.8000\n",
            "Epoch 36/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.2405 - accuracy: 0.9095 - val_loss: 0.7297 - val_accuracy: 0.7667\n",
            "Epoch 37/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.2095 - accuracy: 0.9429 - val_loss: 0.6302 - val_accuracy: 0.7833\n",
            "Epoch 38/90\n",
            "4/4 [==============================] - 2s 567ms/step - loss: 0.1935 - accuracy: 0.9333 - val_loss: 0.9905 - val_accuracy: 0.7000\n",
            "Epoch 39/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.1921 - accuracy: 0.9333 - val_loss: 0.7405 - val_accuracy: 0.7667\n",
            "Epoch 40/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.2259 - accuracy: 0.9143 - val_loss: 0.7748 - val_accuracy: 0.7333\n",
            "Epoch 41/90\n",
            "4/4 [==============================] - 2s 573ms/step - loss: 0.1821 - accuracy: 0.9333 - val_loss: 0.6622 - val_accuracy: 0.8000\n",
            "Epoch 42/90\n",
            "4/4 [==============================] - 2s 574ms/step - loss: 0.1206 - accuracy: 0.9429 - val_loss: 0.8239 - val_accuracy: 0.8000\n",
            "Epoch 43/90\n",
            "4/4 [==============================] - 2s 564ms/step - loss: 0.1069 - accuracy: 0.9714 - val_loss: 0.8075 - val_accuracy: 0.7500\n",
            "Epoch 44/90\n",
            "4/4 [==============================] - 2s 569ms/step - loss: 0.1986 - accuracy: 0.9238 - val_loss: 0.7306 - val_accuracy: 0.8000\n",
            "Epoch 45/90\n",
            "4/4 [==============================] - 2s 572ms/step - loss: 0.1485 - accuracy: 0.9476 - val_loss: 0.7051 - val_accuracy: 0.7833\n",
            "Epoch 46/90\n",
            "4/4 [==============================] - 2s 591ms/step - loss: 0.1109 - accuracy: 0.9571 - val_loss: 0.7625 - val_accuracy: 0.8000\n",
            "Epoch 47/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.0936 - accuracy: 0.9667 - val_loss: 0.9629 - val_accuracy: 0.7833\n",
            "Epoch 48/90\n",
            "4/4 [==============================] - 2s 575ms/step - loss: 0.0629 - accuracy: 0.9714 - val_loss: 0.9716 - val_accuracy: 0.8000\n",
            "Epoch 49/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.0749 - accuracy: 0.9714 - val_loss: 0.9405 - val_accuracy: 0.7667\n",
            "Epoch 50/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.0656 - accuracy: 0.9714 - val_loss: 1.1050 - val_accuracy: 0.8167\n",
            "Epoch 51/90\n",
            "4/4 [==============================] - 2s 568ms/step - loss: 0.1627 - accuracy: 0.9476 - val_loss: 0.7570 - val_accuracy: 0.8167\n",
            "Epoch 52/90\n",
            "4/4 [==============================] - 2s 571ms/step - loss: 0.0798 - accuracy: 0.9667 - val_loss: 0.8141 - val_accuracy: 0.7833\n",
            "Epoch 53/90\n",
            "4/4 [==============================] - 2s 570ms/step - loss: 0.0780 - accuracy: 0.9714 - val_loss: 0.8079 - val_accuracy: 0.7833\n",
            "Epoch 53: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_2 = model_2.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_2 = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_2 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1))\n",
        "precision_2 = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "recall_2 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "f1_2 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_2, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_2.round(4))\n",
        "print('Precision:',precision_2.round(4))\n",
        "print('Recall:',recall_2.round(4))\n",
        "print('F1:',f1_2.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_2.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "yjuu8Ddlhywr",
        "outputId": "d4373995-34b8-4e88-9c8a-5503a5cfc115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9333\n",
            "Precision: 0.9333\n",
            "Recall: 0.9333\n",
            "F1: 0.9333\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2 with rectangular filters, adaptive learning "
      ],
      "metadata": {
        "id": "qVwce4lBcRI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_3(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 3)\n",
        "    )(conv4)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(1, 2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 3)\n",
        "    )(conv5)\n",
        "\n",
        "\n",
        "    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    classifier_layer = tfkl.Dropout(0.2, seed=seed)(classifier_layer)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "CN_545HecWIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_3 = build_model_3(input_shape, n_genres)\n",
        "\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhZ62HvKcexm",
        "outputId": "316a424b-3ff7-415f-a8e6-5b211ddaf1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 128, 2559, 16)     112       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 64, 1279, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 64, 1279, 32)      3104      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 32, 639, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 639, 64)       12352     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 16, 319, 64)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 319, 64)       24640     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 8, 106, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 8, 106, 128)       16512     \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 4, 35, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " Flatten (Flatten)           (None, 17920)             0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 17920)             0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                1146944   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,203,989\n",
            "Trainable params: 1,203,989\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history_3 = model_3.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWVxtuwacoYG",
        "outputId": "5e5ebd4e-08a8-4255-ffa0-ef52ff2a9230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "4/4 [==============================] - 10s 2s/step - loss: 10.9307 - accuracy: 0.2667 - val_loss: 4.7307 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "4/4 [==============================] - 3s 613ms/step - loss: 4.7754 - accuracy: 0.3143 - val_loss: 2.2994 - val_accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "4/4 [==============================] - 3s 612ms/step - loss: 2.0871 - accuracy: 0.3381 - val_loss: 1.1315 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "4/4 [==============================] - 3s 616ms/step - loss: 1.2559 - accuracy: 0.3905 - val_loss: 1.0698 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "4/4 [==============================] - 3s 616ms/step - loss: 1.1552 - accuracy: 0.3714 - val_loss: 1.0592 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "4/4 [==============================] - 3s 615ms/step - loss: 1.0921 - accuracy: 0.4095 - val_loss: 1.0073 - val_accuracy: 0.4333 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "4/4 [==============================] - 3s 614ms/step - loss: 1.0741 - accuracy: 0.4429 - val_loss: 0.9827 - val_accuracy: 0.4167 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "4/4 [==============================] - 2s 610ms/step - loss: 1.0369 - accuracy: 0.4810 - val_loss: 1.0058 - val_accuracy: 0.4667 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "4/4 [==============================] - 3s 613ms/step - loss: 0.9689 - accuracy: 0.5095 - val_loss: 0.9842 - val_accuracy: 0.5667 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "4/4 [==============================] - 3s 613ms/step - loss: 1.0241 - accuracy: 0.5238 - val_loss: 0.9520 - val_accuracy: 0.4667 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "4/4 [==============================] - 3s 615ms/step - loss: 0.9300 - accuracy: 0.5190 - val_loss: 0.8430 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "4/4 [==============================] - 3s 612ms/step - loss: 0.8529 - accuracy: 0.6476 - val_loss: 0.7685 - val_accuracy: 0.7167 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.8320 - accuracy: 0.6048 - val_loss: 0.7219 - val_accuracy: 0.8333 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "4/4 [==============================] - 2s 609ms/step - loss: 0.7539 - accuracy: 0.6905 - val_loss: 0.7314 - val_accuracy: 0.6500 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "4/4 [==============================] - 3s 615ms/step - loss: 0.6666 - accuracy: 0.7381 - val_loss: 0.6305 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "4/4 [==============================] - 3s 611ms/step - loss: 0.6475 - accuracy: 0.7571 - val_loss: 0.6316 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "4/4 [==============================] - 3s 613ms/step - loss: 0.5443 - accuracy: 0.8048 - val_loss: 0.6360 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "4/4 [==============================] - 3s 614ms/step - loss: 0.5317 - accuracy: 0.8190 - val_loss: 0.5906 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "4/4 [==============================] - 3s 611ms/step - loss: 0.5001 - accuracy: 0.8381 - val_loss: 0.6401 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "4/4 [==============================] - 3s 614ms/step - loss: 0.4179 - accuracy: 0.8476 - val_loss: 0.5422 - val_accuracy: 0.8167 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "4/4 [==============================] - 3s 609ms/step - loss: 0.4132 - accuracy: 0.8429 - val_loss: 0.5741 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "4/4 [==============================] - 2s 607ms/step - loss: 0.3684 - accuracy: 0.8714 - val_loss: 0.5502 - val_accuracy: 0.8167 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "4/4 [==============================] - 3s 611ms/step - loss: 0.2698 - accuracy: 0.9143 - val_loss: 0.5894 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "4/4 [==============================] - 3s 611ms/step - loss: 0.2970 - accuracy: 0.8857 - val_loss: 0.5493 - val_accuracy: 0.8167 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "4/4 [==============================] - 3s 612ms/step - loss: 0.2166 - accuracy: 0.9238 - val_loss: 0.5374 - val_accuracy: 0.7833 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "4/4 [==============================] - 2s 606ms/step - loss: 0.2212 - accuracy: 0.9238 - val_loss: 0.6819 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "4/4 [==============================] - 3s 614ms/step - loss: 0.2112 - accuracy: 0.9286 - val_loss: 0.6887 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "4/4 [==============================] - 3s 608ms/step - loss: 0.1563 - accuracy: 0.9524 - val_loss: 0.8998 - val_accuracy: 0.7667 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "4/4 [==============================] - 2s 606ms/step - loss: 0.1999 - accuracy: 0.9238 - val_loss: 0.7996 - val_accuracy: 0.7333 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.1741 - accuracy: 0.9571 - val_loss: 0.9796 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "4/4 [==============================] - 2s 607ms/step - loss: 0.1856 - accuracy: 0.9190 - val_loss: 0.8563 - val_accuracy: 0.7833 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "4/4 [==============================] - 2s 609ms/step - loss: 0.1201 - accuracy: 0.9619 - val_loss: 0.7186 - val_accuracy: 0.7167 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "4/4 [==============================] - 2s 605ms/step - loss: 0.0846 - accuracy: 0.9762 - val_loss: 0.7040 - val_accuracy: 0.8333 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "4/4 [==============================] - 3s 612ms/step - loss: 0.0711 - accuracy: 0.9762 - val_loss: 0.8781 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.0796 - accuracy: 0.9762 - val_loss: 0.8184 - val_accuracy: 0.8000 - lr: 5.0000e-04\n",
            "Epoch 36/500\n",
            "4/4 [==============================] - 3s 613ms/step - loss: 0.0676 - accuracy: 0.9810 - val_loss: 0.7871 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 37/500\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.7840 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 38/500\n",
            "4/4 [==============================] - 2s 604ms/step - loss: 0.0507 - accuracy: 0.9857 - val_loss: 0.7849 - val_accuracy: 0.8333 - lr: 2.5000e-04\n",
            "Epoch 39/500\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.0466 - accuracy: 0.9905 - val_loss: 0.7955 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 40/500\n",
            "4/4 [==============================] - 2s 607ms/step - loss: 0.0450 - accuracy: 0.9905 - val_loss: 0.8196 - val_accuracy: 0.8000 - lr: 2.5000e-04\n",
            "Epoch 41/500\n",
            "4/4 [==============================] - 3s 608ms/step - loss: 0.0508 - accuracy: 0.9857 - val_loss: 0.8145 - val_accuracy: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 42/500\n",
            "4/4 [==============================] - 2s 608ms/step - loss: 0.0494 - accuracy: 0.9857 - val_loss: 0.8211 - val_accuracy: 0.7833 - lr: 1.2500e-04\n",
            "Epoch 43/500\n",
            "4/4 [==============================] - 3s 607ms/step - loss: 0.0364 - accuracy: 0.9952 - val_loss: 0.8390 - val_accuracy: 0.7833 - lr: 1.2500e-04\n",
            "Epoch 44/500\n",
            "4/4 [==============================] - 2s 601ms/step - loss: 0.0507 - accuracy: 0.9857 - val_loss: 0.8561 - val_accuracy: 0.7667 - lr: 1.2500e-04\n",
            "Epoch 45/500\n",
            "4/4 [==============================] - 3s 611ms/step - loss: 0.0383 - accuracy: 0.9905 - val_loss: 0.8852 - val_accuracy: 0.8000 - lr: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_3 = model_3.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_3 = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_3 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1))\n",
        "precision_3 = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1), average='macro')\n",
        "recall_3 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1), average='macro')\n",
        "f1_3 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_3, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_3.round(4))\n",
        "print('Precision:',precision_3.round(4))\n",
        "print('Recall:',recall_3.round(4))\n",
        "print('F1:',f1_3.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_3.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "lj8kiZaKcwzh",
        "outputId": "31507522-6ffe-477d-da0e-acd01e822ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Precision: 0.8993\n",
            "Recall: 0.9\n",
            "F1: 0.8982\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving best model\n"
      ],
      "metadata": {
        "id": "dzl0LsK69yGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save('/gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_5_classes_group2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E4EIjEL91AR",
        "outputId": "e1ad2f4a-d0ff-4bc5-c5a3-9ed5d1ae0c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_5_classes_group2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/Colab Notebooks/NAML/Project/models/Handmade_5_classes_group2/assets\n"
          ]
        }
      ]
    }
  ]
}