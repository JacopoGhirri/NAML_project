{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning_complete.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning - ResNet50\n",
        "\n",
        "In this approach we try and leverage large pre-trained Convolutional Neural Networks for tackling the classification problem over all 10 genres"
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c968dc-45fe-4100-83d3-7b7ba871e0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf6ca93-e688-4032-b817-a73bf73d904a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "n_genres = 10\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1761c918-9eb2-41a3-a35c-38ca21c2a0b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blues done\n",
            "classical done\n",
            "country done\n",
            "disco done\n",
            "hiphop done\n",
            "jazz done\n",
            "metal done\n",
            "pop done\n",
            "reggae done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(seed)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(n_genres):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, n_genres))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, n_genres))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, n_genres))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supernet = tfk.applications.ResNet50(\n",
        "\n",
        "    include_top=False,\n",
        "\n",
        "    weights=\"imagenet\",\n",
        "\n",
        "    input_shape = (128, 2559, 3)\n",
        "\n",
        ")\n",
        "\n",
        "supernet.summary()"
      ],
      "metadata": {
        "id": "wfHsh1bXQ4WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, supernet, n_units):\n",
        "\n",
        "    # Build the neural network layer by layer\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "    \n",
        "    add_channels = tf.keras.layers.Conv2D(filters = 3, kernel_size = (3,3),\n",
        "                                          padding=\"same\", name = 'Channel_adder')(input_layer)\n",
        "\n",
        "\n",
        "    resnet50 = supernet(add_channels)\n",
        "\n",
        "    glob_pooling = tfkl.GlobalAveragePooling2D(name='GloablPooling')(resnet50)\n",
        "\n",
        "\n",
        "\n",
        "    classifier_layer = tfkl.Dense(\n",
        "\n",
        "        units=32,  \n",
        "\n",
        "        activation='relu',\n",
        "\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "\n",
        "        name='Classifier')(glob_pooling)\n",
        "\n",
        "    classifier_layer = tfkl.Dropout(0.2, seed=seed, name='ClassifierDropout')(classifier_layer)\n",
        "\n",
        "\n",
        "\n",
        "    output_layer = tfkl.Dense(\n",
        "\n",
        "        units=n_units, \n",
        "\n",
        "        activation='softmax', \n",
        "\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "\n",
        "        name='Output')(classifier_layer)\n",
        "\n",
        "\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "\n",
        "\n",
        "    # Compile the model\n",
        "\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supernet.trainable = False\n",
        "\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, supernet, n_genres)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd56531-c729-4995-ca4d-01ffeadc65ab"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " Channel_adder (Conv2D)      (None, 128, 2559, 3)      30        \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 4, 80, 2048)       23587712  \n",
            "                                                                 \n",
            " GloablPooling (GlobalAverag  (None, 2048)             0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 32)                65568     \n",
            "                                                                 \n",
            " ClassifierDropout (Dropout)  (None, 32)               0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,653,640\n",
            "Trainable params: 65,928\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 16,#small batch size to avoid out of memory issues\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1459a61-a10b-4b2b-8e6b-6cbb1001af48"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "44/44 [==============================] - 47s 929ms/step - loss: 2.1284 - accuracy: 0.2157 - val_loss: 1.7625 - val_accuracy: 0.3450 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "44/44 [==============================] - 37s 839ms/step - loss: 1.6637 - accuracy: 0.3871 - val_loss: 1.5181 - val_accuracy: 0.4600 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "44/44 [==============================] - 38s 858ms/step - loss: 1.4876 - accuracy: 0.4843 - val_loss: 1.3924 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "44/44 [==============================] - 38s 870ms/step - loss: 1.3380 - accuracy: 0.5329 - val_loss: 1.2754 - val_accuracy: 0.5850 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "44/44 [==============================] - 39s 884ms/step - loss: 1.2614 - accuracy: 0.5600 - val_loss: 1.2154 - val_accuracy: 0.5550 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "44/44 [==============================] - 39s 900ms/step - loss: 1.1468 - accuracy: 0.6143 - val_loss: 1.0961 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "44/44 [==============================] - 40s 908ms/step - loss: 1.0938 - accuracy: 0.6329 - val_loss: 1.0590 - val_accuracy: 0.6550 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "44/44 [==============================] - 40s 905ms/step - loss: 1.0212 - accuracy: 0.6557 - val_loss: 1.0391 - val_accuracy: 0.6700 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 1.0014 - accuracy: 0.6686 - val_loss: 0.9930 - val_accuracy: 0.6750 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.9419 - accuracy: 0.6814 - val_loss: 0.9883 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.9030 - accuracy: 0.6971 - val_loss: 0.9880 - val_accuracy: 0.6650 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "44/44 [==============================] - 40s 905ms/step - loss: 0.8841 - accuracy: 0.7057 - val_loss: 0.9685 - val_accuracy: 0.6600 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "44/44 [==============================] - 40s 906ms/step - loss: 0.8279 - accuracy: 0.7057 - val_loss: 0.9275 - val_accuracy: 0.6950 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "44/44 [==============================] - 40s 905ms/step - loss: 0.8259 - accuracy: 0.7300 - val_loss: 0.8844 - val_accuracy: 0.7400 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "44/44 [==============================] - 40s 906ms/step - loss: 0.7838 - accuracy: 0.7343 - val_loss: 0.8544 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.7826 - accuracy: 0.7329 - val_loss: 0.8978 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.7796 - accuracy: 0.7386 - val_loss: 0.9484 - val_accuracy: 0.6800 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.7469 - accuracy: 0.7357 - val_loss: 0.8778 - val_accuracy: 0.7350 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.7038 - accuracy: 0.7643 - val_loss: 0.8301 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.6966 - accuracy: 0.7600 - val_loss: 0.8431 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.6330 - accuracy: 0.7671 - val_loss: 0.8683 - val_accuracy: 0.7200 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.6703 - accuracy: 0.7657 - val_loss: 0.8861 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.6568 - accuracy: 0.7700 - val_loss: 0.8405 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.6385 - accuracy: 0.7686 - val_loss: 0.8267 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "44/44 [==============================] - 40s 909ms/step - loss: 0.6128 - accuracy: 0.7786 - val_loss: 0.7673 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "44/44 [==============================] - 39s 900ms/step - loss: 0.5600 - accuracy: 0.8029 - val_loss: 0.8022 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.5735 - accuracy: 0.8086 - val_loss: 0.8177 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.5512 - accuracy: 0.8014 - val_loss: 0.8063 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.5553 - accuracy: 0.8129 - val_loss: 0.7985 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "44/44 [==============================] - 40s 907ms/step - loss: 0.5775 - accuracy: 0.8029 - val_loss: 0.7526 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 31/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.5206 - accuracy: 0.8214 - val_loss: 0.8306 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 32/500\n",
            "44/44 [==============================] - 40s 905ms/step - loss: 0.5395 - accuracy: 0.8043 - val_loss: 0.8027 - val_accuracy: 0.7300 - lr: 0.0010\n",
            "Epoch 33/500\n",
            "44/44 [==============================] - 40s 905ms/step - loss: 0.5145 - accuracy: 0.8386 - val_loss: 0.7964 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 34/500\n",
            "44/44 [==============================] - 40s 908ms/step - loss: 0.5140 - accuracy: 0.8186 - val_loss: 0.7503 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 35/500\n",
            "44/44 [==============================] - 40s 905ms/step - loss: 0.4850 - accuracy: 0.8300 - val_loss: 0.7614 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 36/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.4582 - accuracy: 0.8443 - val_loss: 0.7924 - val_accuracy: 0.7450 - lr: 0.0010\n",
            "Epoch 37/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.4812 - accuracy: 0.8214 - val_loss: 0.7646 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 38/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.4772 - accuracy: 0.8200 - val_loss: 0.7641 - val_accuracy: 0.7700 - lr: 0.0010\n",
            "Epoch 39/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.4537 - accuracy: 0.8300 - val_loss: 0.7724 - val_accuracy: 0.7600 - lr: 0.0010\n",
            "Epoch 40/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.4049 - accuracy: 0.8743 - val_loss: 0.7582 - val_accuracy: 0.7750 - lr: 5.0000e-04\n",
            "Epoch 41/500\n",
            "44/44 [==============================] - 40s 906ms/step - loss: 0.3949 - accuracy: 0.8600 - val_loss: 0.7480 - val_accuracy: 0.7850 - lr: 5.0000e-04\n",
            "Epoch 42/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.3930 - accuracy: 0.8700 - val_loss: 0.7804 - val_accuracy: 0.7750 - lr: 5.0000e-04\n",
            "Epoch 43/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.4102 - accuracy: 0.8486 - val_loss: 0.7494 - val_accuracy: 0.7800 - lr: 5.0000e-04\n",
            "Epoch 44/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.4289 - accuracy: 0.8486 - val_loss: 0.7840 - val_accuracy: 0.7700 - lr: 5.0000e-04\n",
            "Epoch 45/500\n",
            "44/44 [==============================] - 40s 905ms/step - loss: 0.4201 - accuracy: 0.8514 - val_loss: 0.7535 - val_accuracy: 0.7900 - lr: 5.0000e-04\n",
            "Epoch 46/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.3829 - accuracy: 0.8700 - val_loss: 0.7605 - val_accuracy: 0.7750 - lr: 5.0000e-04\n",
            "Epoch 47/500\n",
            "44/44 [==============================] - 40s 906ms/step - loss: 0.3855 - accuracy: 0.8629 - val_loss: 0.7417 - val_accuracy: 0.7900 - lr: 2.5000e-04\n",
            "Epoch 48/500\n",
            "44/44 [==============================] - 40s 907ms/step - loss: 0.3692 - accuracy: 0.8714 - val_loss: 0.7416 - val_accuracy: 0.8100 - lr: 2.5000e-04\n",
            "Epoch 49/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.4047 - accuracy: 0.8471 - val_loss: 0.7564 - val_accuracy: 0.7900 - lr: 2.5000e-04\n",
            "Epoch 50/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.3735 - accuracy: 0.8814 - val_loss: 0.7444 - val_accuracy: 0.8050 - lr: 2.5000e-04\n",
            "Epoch 51/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.3475 - accuracy: 0.8771 - val_loss: 0.7602 - val_accuracy: 0.7900 - lr: 2.5000e-04\n",
            "Epoch 52/500\n",
            "44/44 [==============================] - 40s 904ms/step - loss: 0.3432 - accuracy: 0.8886 - val_loss: 0.7575 - val_accuracy: 0.7850 - lr: 2.5000e-04\n",
            "Epoch 53/500\n",
            "44/44 [==============================] - 40s 905ms/step - loss: 0.3485 - accuracy: 0.8857 - val_loss: 0.7517 - val_accuracy: 0.7900 - lr: 2.5000e-04\n",
            "Epoch 54/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.3618 - accuracy: 0.8700 - val_loss: 0.7472 - val_accuracy: 0.7850 - lr: 1.2500e-04\n",
            "Epoch 55/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.3520 - accuracy: 0.8886 - val_loss: 0.7517 - val_accuracy: 0.7900 - lr: 1.2500e-04\n",
            "Epoch 56/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.3560 - accuracy: 0.8771 - val_loss: 0.7448 - val_accuracy: 0.7950 - lr: 1.2500e-04\n",
            "Epoch 57/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.3570 - accuracy: 0.8829 - val_loss: 0.7510 - val_accuracy: 0.7900 - lr: 1.2500e-04\n",
            "Epoch 58/500\n",
            "44/44 [==============================] - 40s 906ms/step - loss: 0.3884 - accuracy: 0.8643 - val_loss: 0.7384 - val_accuracy: 0.7950 - lr: 1.2500e-04\n",
            "Epoch 59/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.3615 - accuracy: 0.8829 - val_loss: 0.7453 - val_accuracy: 0.7900 - lr: 1.2500e-04\n",
            "Epoch 60/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.3394 - accuracy: 0.8843 - val_loss: 0.7470 - val_accuracy: 0.7950 - lr: 1.2500e-04\n",
            "Epoch 61/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.3380 - accuracy: 0.8843 - val_loss: 0.7443 - val_accuracy: 0.8050 - lr: 1.2500e-04\n",
            "Epoch 62/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.3279 - accuracy: 0.8857 - val_loss: 0.7544 - val_accuracy: 0.8000 - lr: 1.2500e-04\n",
            "Epoch 63/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.3261 - accuracy: 0.9029 - val_loss: 0.7637 - val_accuracy: 0.7800 - lr: 1.2500e-04\n",
            "Epoch 64/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.3641 - accuracy: 0.8743 - val_loss: 0.7496 - val_accuracy: 0.7950 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.3591 - accuracy: 0.8843 - val_loss: 0.7443 - val_accuracy: 0.7850 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.3623 - accuracy: 0.8857 - val_loss: 0.7559 - val_accuracy: 0.7900 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.3463 - accuracy: 0.8743 - val_loss: 0.7611 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "44/44 [==============================] - 40s 900ms/step - loss: 0.3292 - accuracy: 0.8871 - val_loss: 0.7522 - val_accuracy: 0.7950 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.3454 - accuracy: 0.8871 - val_loss: 0.7548 - val_accuracy: 0.7950 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "44/44 [==============================] - 40s 900ms/step - loss: 0.3217 - accuracy: 0.8929 - val_loss: 0.7536 - val_accuracy: 0.8050 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "44/44 [==============================] - 40s 900ms/step - loss: 0.3339 - accuracy: 0.8914 - val_loss: 0.7612 - val_accuracy: 0.7750 - lr: 1.0000e-04\n",
            "Epoch 72/500\n",
            "44/44 [==============================] - 39s 900ms/step - loss: 0.3411 - accuracy: 0.8843 - val_loss: 0.7505 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 73/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.3357 - accuracy: 0.8829 - val_loss: 0.7554 - val_accuracy: 0.7800 - lr: 1.0000e-04\n",
            "Epoch 74/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.3233 - accuracy: 0.9029 - val_loss: 0.7546 - val_accuracy: 0.8000 - lr: 1.0000e-04\n",
            "Epoch 75/500\n",
            "44/44 [==============================] - 40s 901ms/step - loss: 0.3612 - accuracy: 0.8829 - val_loss: 0.7516 - val_accuracy: 0.7950 - lr: 1.0000e-04\n",
            "Epoch 76/500\n",
            "44/44 [==============================] - 40s 902ms/step - loss: 0.3345 - accuracy: 0.8814 - val_loss: 0.7492 - val_accuracy: 0.8050 - lr: 1.0000e-04\n",
            "Epoch 77/500\n",
            "44/44 [==============================] - 40s 903ms/step - loss: 0.3249 - accuracy: 0.9000 - val_loss: 0.7511 - val_accuracy: 0.7950 - lr: 1.0000e-04\n",
            "Epoch 78/500\n",
            "44/44 [==============================] - 40s 906ms/step - loss: 0.3191 - accuracy: 0.8957 - val_loss: 0.7568 - val_accuracy: 0.7900 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "960c8479-566b-401f-d749-6f33f1e26b2f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8\n",
            "Precision: 0.8188\n",
            "Recall: 0.8\n",
            "F1: 0.8023\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/transfer_learning/tl_complete')"
      ],
      "metadata": {
        "id": "4mpw33y3WoGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e06b9a9-0aa9-450b-d5cf-4bf6ab40da36"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/transfer_learning/tl_complete/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/transfer_learning/tl_complete/assets\n"
          ]
        }
      ]
    }
  ]
}