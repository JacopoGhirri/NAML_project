{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dirty_handmade_metal_classical.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for 2 genres classification - Country vs Blues\n",
        "\n",
        "We aim at training a Neural Network to distinguish between two genres: country and blues."
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd1d268-5e07-43ef-87be-cf9fb16aeb88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef1ab24-2bff-4db9-92da-d11c894778ef"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "IoV9bIbPfg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "#genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "genres = {'metal': 0, 'classical': 1}\n",
        "outliers = {'blues': 0, 'disco': 1, 'country': 2, 'jazz': 3, 'hiphop': 4, 'pop': 5, 'reggae': 6, 'rock': 7}\n",
        "n_dirty_per_genre_per_type = 6\n",
        "\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "        \n",
        "    print(str(genre+' done'))\n",
        "\n",
        "for genre, genre_number in outliers.items():\n",
        "    count = 0\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        if count < 2*n_dirty_per_genre_per_type:\n",
        "          if count < n_dirty_per_genre_per_type:\n",
        "            dataset.append( (ps, 0) )\n",
        "          else:\n",
        "            dataset.append( (ps, 1) )\n",
        "        else:\n",
        "          break\n",
        "    print(str(genre+' done')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pu8r54LJMSj",
        "outputId": "c9b0d501-429d-4d5f-f5c3-afb312645856"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metal done\n",
            "classical done\n",
            "blues done\n",
            "disco done\n",
            "country done\n",
            "jazz done\n",
            "hiphop done\n",
            "pop done\n",
            "reggae done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "0sgOQfv-gZ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(2):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])\n",
        "\n",
        "for j in range(8):\n",
        "  for t in range(2):\n",
        "    for b in range(5):\n",
        "      training.append(dataset[200 + t*8*n_dirty_per_genre_per_type + j*n_dirty_per_genre_per_type + b])\n",
        "    validation.append(dataset[i*100 + t*8*n_dirty_per_genre_per_type + j*n_dirty_per_genre_per_type + 5])\n"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNsfoewZARn8",
        "outputId": "617b23c3-9c88-4e19-a980-88cabe0be817"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 2559)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, 2))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, 2))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, 2))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "O6AvTMw2hgxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_units = 2\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, n_units)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eef0386-3ef6-4662-b26a-255f8ea7c47f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 128, 2559, 4)      104       \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 128, 2559, 8)      296       \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 64, 1279, 8)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 64, 1279, 16)      1168      \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 64, 1279, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 32, 639, 16)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 32, 639, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 16, 319, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 16, 319, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 8, 159, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 8, 159, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 4, 79, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 4, 79, 286)        36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,216\n",
            "Trainable params: 195,216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 20,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1662222-2e00-4b32-d46a-954771d5d776"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 5s 357ms/step - loss: 0.6299 - accuracy: 0.6409 - val_loss: 0.8329 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.5075 - accuracy: 0.6773 - val_loss: 0.7291 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.4748 - accuracy: 0.6818 - val_loss: 0.6439 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.4577 - accuracy: 0.8091 - val_loss: 0.5746 - val_accuracy: 0.8393 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.4027 - accuracy: 0.8909 - val_loss: 0.5700 - val_accuracy: 0.8214 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 3s 322ms/step - loss: 0.3600 - accuracy: 0.8864 - val_loss: 0.4696 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.2918 - accuracy: 0.9273 - val_loss: 0.2512 - val_accuracy: 0.9286 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.3000 - accuracy: 0.9136 - val_loss: 0.2230 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.1978 - accuracy: 0.9318 - val_loss: 0.1332 - val_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 3s 322ms/step - loss: 0.1617 - accuracy: 0.9545 - val_loss: 0.0648 - val_accuracy: 0.9821 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 4s 325ms/step - loss: 0.2021 - accuracy: 0.9227 - val_loss: 0.1677 - val_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1224 - accuracy: 0.9500 - val_loss: 0.1205 - val_accuracy: 0.9286 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.1117 - accuracy: 0.9636 - val_loss: 0.0306 - val_accuracy: 0.9821 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0492 - accuracy: 0.9773 - val_loss: 0.0611 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0419 - accuracy: 0.9818 - val_loss: 0.0536 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0540 - accuracy: 0.9818 - val_loss: 0.0917 - val_accuracy: 0.9821 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.1078 - accuracy: 0.9636 - val_loss: 0.1826 - val_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1434 - accuracy: 0.9455 - val_loss: 0.0454 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0694 - accuracy: 0.9818 - val_loss: 0.0305 - val_accuracy: 0.9821 - lr: 5.0000e-04\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.0433 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0297 - accuracy: 0.9864 - val_loss: 0.0772 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.0765 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 4s 322ms/step - loss: 0.0237 - accuracy: 0.9955 - val_loss: 0.0116 - val_accuracy: 1.0000 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 0.0950 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 4s 352ms/step - loss: 0.0186 - accuracy: 0.9864 - val_loss: 0.0280 - val_accuracy: 0.9821 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0105 - accuracy: 0.9955 - val_loss: 0.0991 - val_accuracy: 0.9821 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9821 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9821 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0079 - accuracy: 0.9955 - val_loss: 0.0206 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.0674 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9821 - lr: 1.2500e-04\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0093 - accuracy: 0.9955 - val_loss: 0.0674 - val_accuracy: 0.9821 - lr: 1.2500e-04\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 0.9821 - lr: 1.2500e-04\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9821 - lr: 1.2500e-04\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9821 - lr: 1.2500e-04\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0596 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 3s 322ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9821 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "cbfed27d-19df-403a-c2c5-364a0bcc04f8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "Precision: 0.9\n",
            "Recall: 0.9\n",
            "F1: 0.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/dirty_hiphopvclassical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "2f852ded-d34a-4623-d6a3-97eccaf9f962"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/dirty_hiphopvclassical/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/dirty_hiphopvclassical/assets\n"
          ]
        }
      ]
    }
  ]
}