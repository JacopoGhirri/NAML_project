{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handmade_5_classes_group1_dirty_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##5 classes: rock, metal, country, hip hop, disco\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2ad2d3-8892-41e2-d5ec-485ab0d54c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/Colab Notebooks/NAML/Project"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6379eb1-1c40-4d46-c200-874c66c25d7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks/NAML/Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "# genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "\n",
        "genres = { 'country': 0, 'disco': 1, 'hiphop': 2,  'metal': 3,  'rock': 4, 'classical':5}\n",
        "\n",
        "n_genres=5\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "    print(str(genre+' done'))"
      ],
      "metadata": {
        "id": "oiT5mkVqQ_lt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ff15e7-58cc-433c-ac53-592c0137bf8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "country done\n",
            "disco done\n",
            "hiphop done\n",
            "metal done\n",
            "rock done\n",
            "classical done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(5):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])\n",
        "\n",
        "#dirt the dataset \n",
        "i=5\n",
        "t=3 #wrong songs added to training \n",
        "v=1 #wrong songs added to validation\n",
        "\n",
        "for j in range(5):\n",
        "    for k in range(t):\n",
        "        training.append((dataset[i*100+k+j*(t+v)][0],j))\n",
        "    for l in range(v):\n",
        "        validation.append((dataset[i*100+l+t+j*(t+v)][0],j))\n",
        "\n",
        "# accuracy on test set \n",
        "# 3 e 1: 80%, 76%, 80%\n",
        "# 5 e 2: 82%, 78%, 82%\n",
        "# 7 e 3: 32%, 56%, 58%\n",
        "# 8 e 3: 68%, 78%, 76%\n",
        "# 10 e 3: 82%, 73%, 68%\n",
        "\n"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, n_genres))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, n_genres))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, n_genres))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###As before but rect filt"
      ],
      "metadata": {
        "id": "ezzh-uhS5VGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model_1(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(3, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(2, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,2),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "s1LzDfg45bYC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model_1 = build_model_1(input_shape, n_genres)\n",
        "\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z02qBdCF5hHI",
        "outputId": "e798d13e-2409-42d8-ea91-d55a87512212"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 128, 2559, 4)      64        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 2559, 8)      200       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 1279, 8)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 1279, 16)      784       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 1279, 16)      1552      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 639, 16)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 639, 32)       3104      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 319, 32)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 319, 64)       12352     \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 16, 319, 64)       24640     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 8, 159, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 8, 159, 128)       49280     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 4, 79, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 79, 286)        73502     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 186,091\n",
            "Trainable params: 186,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history_1 = model_1.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 64,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "xlS82usv5kJo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05aebc0b-5d86-4799-fdac-9e0188d7a898"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 24s 2s/step - loss: 1.6490 - accuracy: 0.1945 - val_loss: 1.6069 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 5s 915ms/step - loss: 1.6208 - accuracy: 0.2027 - val_loss: 1.6076 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 5s 912ms/step - loss: 1.6138 - accuracy: 0.1699 - val_loss: 1.6091 - val_accuracy: 0.2857 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 5s 915ms/step - loss: 1.6087 - accuracy: 0.2027 - val_loss: 1.6083 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 5s 916ms/step - loss: 1.6062 - accuracy: 0.2000 - val_loss: 1.6070 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 5s 911ms/step - loss: 1.6088 - accuracy: 0.2027 - val_loss: 1.6076 - val_accuracy: 0.2000 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 5s 914ms/step - loss: 1.6098 - accuracy: 0.1890 - val_loss: 1.6072 - val_accuracy: 0.2000 - lr: 5.0000e-04\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 1.6094 - accuracy: 0.2137 - val_loss: 1.6074 - val_accuracy: 0.2000 - lr: 5.0000e-04\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 1.6037 - accuracy: 0.2438 - val_loss: 1.6062 - val_accuracy: 0.2000 - lr: 5.0000e-04\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 1.6083 - accuracy: 0.1836 - val_loss: 1.6052 - val_accuracy: 0.2000 - lr: 5.0000e-04\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 1.6102 - accuracy: 0.1918 - val_loss: 1.6064 - val_accuracy: 0.2000 - lr: 5.0000e-04\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 1.6043 - accuracy: 0.2274 - val_loss: 1.6059 - val_accuracy: 0.2000 - lr: 5.0000e-04\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 1.6045 - accuracy: 0.2082 - val_loss: 1.6041 - val_accuracy: 0.2190 - lr: 5.0000e-04\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 1.5954 - accuracy: 0.2767 - val_loss: 1.5987 - val_accuracy: 0.2000 - lr: 5.0000e-04\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 1.6008 - accuracy: 0.2329 - val_loss: 1.5975 - val_accuracy: 0.3619 - lr: 5.0000e-04\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 5s 911ms/step - loss: 1.5918 - accuracy: 0.2219 - val_loss: 1.5745 - val_accuracy: 0.3810 - lr: 5.0000e-04\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 1.5708 - accuracy: 0.2493 - val_loss: 1.5632 - val_accuracy: 0.3810 - lr: 5.0000e-04\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 1.5634 - accuracy: 0.2384 - val_loss: 1.5569 - val_accuracy: 0.4286 - lr: 5.0000e-04\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 1.5448 - accuracy: 0.2685 - val_loss: 1.5669 - val_accuracy: 0.2857 - lr: 5.0000e-04\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.5395 - accuracy: 0.2630 - val_loss: 1.5185 - val_accuracy: 0.3429 - lr: 5.0000e-04\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 1.5205 - accuracy: 0.3014 - val_loss: 1.4907 - val_accuracy: 0.3524 - lr: 5.0000e-04\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.5367 - accuracy: 0.2575 - val_loss: 1.4421 - val_accuracy: 0.2857 - lr: 5.0000e-04\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 1.4954 - accuracy: 0.3397 - val_loss: 1.4044 - val_accuracy: 0.3619 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 1.4434 - accuracy: 0.3644 - val_loss: 1.3760 - val_accuracy: 0.3524 - lr: 5.0000e-04\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 1.3832 - accuracy: 0.3562 - val_loss: 1.3300 - val_accuracy: 0.3905 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 1.3951 - accuracy: 0.3863 - val_loss: 1.3153 - val_accuracy: 0.4857 - lr: 5.0000e-04\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 1.3844 - accuracy: 0.4027 - val_loss: 1.2842 - val_accuracy: 0.4286 - lr: 5.0000e-04\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.3646 - accuracy: 0.3863 - val_loss: 1.2628 - val_accuracy: 0.4286 - lr: 5.0000e-04\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 1.3256 - accuracy: 0.4247 - val_loss: 1.2465 - val_accuracy: 0.4952 - lr: 5.0000e-04\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 1.3592 - accuracy: 0.4027 - val_loss: 1.2212 - val_accuracy: 0.4762 - lr: 5.0000e-04\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 5s 900ms/step - loss: 1.3019 - accuracy: 0.4082 - val_loss: 1.2484 - val_accuracy: 0.5143 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 1.2910 - accuracy: 0.4384 - val_loss: 1.1583 - val_accuracy: 0.5714 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 1.2417 - accuracy: 0.5068 - val_loss: 1.1301 - val_accuracy: 0.5810 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.2887 - accuracy: 0.4603 - val_loss: 1.2866 - val_accuracy: 0.4762 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 1.4854 - accuracy: 0.3068 - val_loss: 1.3115 - val_accuracy: 0.5048 - lr: 5.0000e-04\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 1.3540 - accuracy: 0.4000 - val_loss: 1.2044 - val_accuracy: 0.4762 - lr: 5.0000e-04\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 1.2716 - accuracy: 0.4575 - val_loss: 1.2139 - val_accuracy: 0.5429 - lr: 5.0000e-04\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 1.2909 - accuracy: 0.4712 - val_loss: 1.1315 - val_accuracy: 0.5429 - lr: 5.0000e-04\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 1.1656 - accuracy: 0.5260 - val_loss: 1.1441 - val_accuracy: 0.5333 - lr: 2.5000e-04\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 1.1865 - accuracy: 0.4959 - val_loss: 1.0762 - val_accuracy: 0.5905 - lr: 2.5000e-04\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 1.2033 - accuracy: 0.4959 - val_loss: 1.1170 - val_accuracy: 0.5238 - lr: 2.5000e-04\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 1.1906 - accuracy: 0.5260 - val_loss: 1.0519 - val_accuracy: 0.6190 - lr: 2.5000e-04\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.1799 - accuracy: 0.5205 - val_loss: 1.0459 - val_accuracy: 0.5619 - lr: 2.5000e-04\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 1.1779 - accuracy: 0.4740 - val_loss: 1.0956 - val_accuracy: 0.5333 - lr: 2.5000e-04\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 1.1672 - accuracy: 0.5068 - val_loss: 1.0297 - val_accuracy: 0.6381 - lr: 2.5000e-04\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 1.1622 - accuracy: 0.5507 - val_loss: 1.0745 - val_accuracy: 0.5238 - lr: 2.5000e-04\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 1.1352 - accuracy: 0.5233 - val_loss: 1.0183 - val_accuracy: 0.6286 - lr: 2.5000e-04\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 5s 912ms/step - loss: 1.1738 - accuracy: 0.5260 - val_loss: 1.0103 - val_accuracy: 0.5905 - lr: 2.5000e-04\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 1.1413 - accuracy: 0.5233 - val_loss: 1.0008 - val_accuracy: 0.5714 - lr: 2.5000e-04\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 1.0956 - accuracy: 0.5151 - val_loss: 1.0321 - val_accuracy: 0.5524 - lr: 2.5000e-04\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 1.1263 - accuracy: 0.5370 - val_loss: 0.9768 - val_accuracy: 0.5619 - lr: 2.5000e-04\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 1.1181 - accuracy: 0.5616 - val_loss: 1.0036 - val_accuracy: 0.5714 - lr: 2.5000e-04\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 1.0973 - accuracy: 0.5397 - val_loss: 1.0624 - val_accuracy: 0.5619 - lr: 2.5000e-04\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 1.1246 - accuracy: 0.5425 - val_loss: 0.9641 - val_accuracy: 0.5810 - lr: 2.5000e-04\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.1034 - accuracy: 0.5562 - val_loss: 0.9605 - val_accuracy: 0.6000 - lr: 2.5000e-04\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 1.0514 - accuracy: 0.5863 - val_loss: 0.9658 - val_accuracy: 0.6000 - lr: 2.5000e-04\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 1.0454 - accuracy: 0.5836 - val_loss: 0.9222 - val_accuracy: 0.6000 - lr: 2.5000e-04\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 1.0343 - accuracy: 0.5342 - val_loss: 0.9623 - val_accuracy: 0.5524 - lr: 2.5000e-04\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.0194 - accuracy: 0.5534 - val_loss: 0.9445 - val_accuracy: 0.6095 - lr: 2.5000e-04\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.0981 - accuracy: 0.5726 - val_loss: 1.0448 - val_accuracy: 0.5619 - lr: 2.5000e-04\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 1.1188 - accuracy: 0.5342 - val_loss: 1.0075 - val_accuracy: 0.5810 - lr: 2.5000e-04\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 1.0522 - accuracy: 0.5836 - val_loss: 1.0741 - val_accuracy: 0.5524 - lr: 2.5000e-04\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 1.0708 - accuracy: 0.5863 - val_loss: 0.9237 - val_accuracy: 0.6476 - lr: 1.2500e-04\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 1.0867 - accuracy: 0.5452 - val_loss: 0.9250 - val_accuracy: 0.6571 - lr: 1.2500e-04\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 1.0025 - accuracy: 0.6164 - val_loss: 0.9215 - val_accuracy: 0.6095 - lr: 1.2500e-04\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9894 - accuracy: 0.6027 - val_loss: 0.8847 - val_accuracy: 0.6095 - lr: 1.2500e-04\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 1.0714 - accuracy: 0.5890 - val_loss: 0.8823 - val_accuracy: 0.6286 - lr: 1.2500e-04\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 1.0275 - accuracy: 0.5918 - val_loss: 0.9287 - val_accuracy: 0.6000 - lr: 1.2500e-04\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 1.0019 - accuracy: 0.5945 - val_loss: 0.8846 - val_accuracy: 0.6286 - lr: 1.2500e-04\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 1.0216 - accuracy: 0.6055 - val_loss: 0.8924 - val_accuracy: 0.6190 - lr: 1.2500e-04\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.9939 - accuracy: 0.5945 - val_loss: 0.8720 - val_accuracy: 0.6190 - lr: 1.2500e-04\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9767 - accuracy: 0.6219 - val_loss: 0.8607 - val_accuracy: 0.6476 - lr: 1.2500e-04\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.9727 - accuracy: 0.5945 - val_loss: 0.8840 - val_accuracy: 0.6000 - lr: 1.2500e-04\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 1.0114 - accuracy: 0.6000 - val_loss: 0.8588 - val_accuracy: 0.6381 - lr: 1.2500e-04\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 1.0092 - accuracy: 0.5890 - val_loss: 0.8679 - val_accuracy: 0.6190 - lr: 1.2500e-04\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.9711 - accuracy: 0.6247 - val_loss: 0.8603 - val_accuracy: 0.6286 - lr: 1.2500e-04\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.9757 - accuracy: 0.6164 - val_loss: 0.8414 - val_accuracy: 0.6381 - lr: 1.2500e-04\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.9660 - accuracy: 0.6000 - val_loss: 0.8487 - val_accuracy: 0.6190 - lr: 1.2500e-04\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.9158 - accuracy: 0.6438 - val_loss: 0.8269 - val_accuracy: 0.6762 - lr: 1.2500e-04\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.9559 - accuracy: 0.6356 - val_loss: 0.8352 - val_accuracy: 0.6381 - lr: 1.2500e-04\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.9995 - accuracy: 0.5945 - val_loss: 0.8332 - val_accuracy: 0.6381 - lr: 1.2500e-04\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.9818 - accuracy: 0.6329 - val_loss: 0.8527 - val_accuracy: 0.6286 - lr: 1.2500e-04\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 0.9673 - accuracy: 0.6274 - val_loss: 0.8321 - val_accuracy: 0.6667 - lr: 1.2500e-04\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 5s 912ms/step - loss: 0.9512 - accuracy: 0.6438 - val_loss: 0.8369 - val_accuracy: 0.6381 - lr: 1.2500e-04\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9834 - accuracy: 0.6082 - val_loss: 0.8219 - val_accuracy: 0.6571 - lr: 1.0000e-04\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.9521 - accuracy: 0.6082 - val_loss: 0.8191 - val_accuracy: 0.6571 - lr: 1.0000e-04\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.9439 - accuracy: 0.6411 - val_loss: 0.8193 - val_accuracy: 0.6571 - lr: 1.0000e-04\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.9729 - accuracy: 0.6137 - val_loss: 0.8186 - val_accuracy: 0.6476 - lr: 1.0000e-04\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9491 - accuracy: 0.6301 - val_loss: 0.8366 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.9348 - accuracy: 0.6301 - val_loss: 0.8165 - val_accuracy: 0.6381 - lr: 1.0000e-04\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.9314 - accuracy: 0.6384 - val_loss: 0.8011 - val_accuracy: 0.6571 - lr: 1.0000e-04\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.9201 - accuracy: 0.6110 - val_loss: 0.8100 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9881 - accuracy: 0.6301 - val_loss: 0.8080 - val_accuracy: 0.6762 - lr: 1.0000e-04\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9525 - accuracy: 0.6658 - val_loss: 0.8171 - val_accuracy: 0.6571 - lr: 1.0000e-04\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.9092 - accuracy: 0.6301 - val_loss: 0.8063 - val_accuracy: 0.6762 - lr: 1.0000e-04\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.9111 - accuracy: 0.6356 - val_loss: 0.7944 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.9020 - accuracy: 0.6658 - val_loss: 0.7925 - val_accuracy: 0.6571 - lr: 1.0000e-04\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.9159 - accuracy: 0.6521 - val_loss: 0.7818 - val_accuracy: 0.6952 - lr: 1.0000e-04\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9423 - accuracy: 0.6137 - val_loss: 0.7974 - val_accuracy: 0.6571 - lr: 1.0000e-04\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.9215 - accuracy: 0.6356 - val_loss: 0.7952 - val_accuracy: 0.6762 - lr: 1.0000e-04\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.8848 - accuracy: 0.6630 - val_loss: 0.7916 - val_accuracy: 0.6952 - lr: 1.0000e-04\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.8692 - accuracy: 0.6767 - val_loss: 0.7918 - val_accuracy: 0.6762 - lr: 1.0000e-04\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.9126 - accuracy: 0.6411 - val_loss: 0.7861 - val_accuracy: 0.6286 - lr: 1.0000e-04\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9000 - accuracy: 0.6411 - val_loss: 0.7666 - val_accuracy: 0.6762 - lr: 1.0000e-04\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.8865 - accuracy: 0.6658 - val_loss: 0.7839 - val_accuracy: 0.6286 - lr: 1.0000e-04\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.9111 - accuracy: 0.6356 - val_loss: 0.7852 - val_accuracy: 0.6762 - lr: 1.0000e-04\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.8932 - accuracy: 0.6384 - val_loss: 0.7842 - val_accuracy: 0.6857 - lr: 1.0000e-04\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.8953 - accuracy: 0.6521 - val_loss: 0.7760 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.9085 - accuracy: 0.6575 - val_loss: 0.7703 - val_accuracy: 0.6857 - lr: 1.0000e-04\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.8855 - accuracy: 0.6356 - val_loss: 0.7759 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.9286 - accuracy: 0.6384 - val_loss: 0.7680 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.8510 - accuracy: 0.6575 - val_loss: 0.7949 - val_accuracy: 0.6476 - lr: 1.0000e-04\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.9021 - accuracy: 0.6685 - val_loss: 0.7729 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.8816 - accuracy: 0.6411 - val_loss: 0.7822 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.8527 - accuracy: 0.6767 - val_loss: 0.7599 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 0.8933 - accuracy: 0.6795 - val_loss: 0.7547 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.8738 - accuracy: 0.6795 - val_loss: 0.7832 - val_accuracy: 0.6667 - lr: 1.0000e-04\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.8791 - accuracy: 0.6740 - val_loss: 0.7516 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.8848 - accuracy: 0.6767 - val_loss: 0.7586 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 0.8934 - accuracy: 0.6192 - val_loss: 0.7506 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.8679 - accuracy: 0.6795 - val_loss: 0.7587 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.8489 - accuracy: 0.6795 - val_loss: 0.7433 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.8821 - accuracy: 0.6603 - val_loss: 0.7414 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.8624 - accuracy: 0.6548 - val_loss: 0.7355 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.8450 - accuracy: 0.6521 - val_loss: 0.7305 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.8419 - accuracy: 0.6658 - val_loss: 0.7284 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.8172 - accuracy: 0.6795 - val_loss: 0.7667 - val_accuracy: 0.6476 - lr: 1.0000e-04\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 5s 899ms/step - loss: 0.8720 - accuracy: 0.6548 - val_loss: 0.7331 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.8369 - accuracy: 0.7041 - val_loss: 0.7526 - val_accuracy: 0.6571 - lr: 1.0000e-04\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 5s 898ms/step - loss: 0.8606 - accuracy: 0.6986 - val_loss: 0.7398 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.8441 - accuracy: 0.6603 - val_loss: 0.7608 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.8624 - accuracy: 0.6740 - val_loss: 0.7340 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 0.8178 - accuracy: 0.6822 - val_loss: 0.7350 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 0.8319 - accuracy: 0.6849 - val_loss: 0.7405 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.7844 - accuracy: 0.6932 - val_loss: 0.7242 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.8481 - accuracy: 0.6493 - val_loss: 0.7490 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.7941 - accuracy: 0.6877 - val_loss: 0.7199 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.8565 - accuracy: 0.6630 - val_loss: 0.7294 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.8538 - accuracy: 0.6712 - val_loss: 0.7238 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.8146 - accuracy: 0.6822 - val_loss: 0.7266 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 5s 911ms/step - loss: 0.8199 - accuracy: 0.6658 - val_loss: 0.7139 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.8538 - accuracy: 0.6630 - val_loss: 0.7308 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7959 - accuracy: 0.6849 - val_loss: 0.7225 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.8363 - accuracy: 0.6904 - val_loss: 0.7304 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7821 - accuracy: 0.7041 - val_loss: 0.7209 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 0.8141 - accuracy: 0.7014 - val_loss: 0.7131 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.8290 - accuracy: 0.6658 - val_loss: 0.7268 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 5s 912ms/step - loss: 0.8556 - accuracy: 0.6904 - val_loss: 0.7109 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.7791 - accuracy: 0.6986 - val_loss: 0.7315 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7827 - accuracy: 0.7151 - val_loss: 0.7081 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.8074 - accuracy: 0.6932 - val_loss: 0.7371 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7531 - accuracy: 0.7014 - val_loss: 0.7012 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.8023 - accuracy: 0.6795 - val_loss: 0.7145 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7748 - accuracy: 0.6986 - val_loss: 0.7043 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.7741 - accuracy: 0.7233 - val_loss: 0.6987 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 0.7834 - accuracy: 0.6959 - val_loss: 0.7097 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.8284 - accuracy: 0.6630 - val_loss: 0.7362 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.8185 - accuracy: 0.6904 - val_loss: 0.7095 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.7908 - accuracy: 0.6959 - val_loss: 0.7312 - val_accuracy: 0.6952 - lr: 1.0000e-04\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.8040 - accuracy: 0.7096 - val_loss: 0.7116 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7989 - accuracy: 0.7068 - val_loss: 0.7339 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.7939 - accuracy: 0.6904 - val_loss: 0.7273 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7569 - accuracy: 0.7068 - val_loss: 0.7347 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.7623 - accuracy: 0.7096 - val_loss: 0.6994 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7186 - accuracy: 0.7233 - val_loss: 0.7031 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7733 - accuracy: 0.7233 - val_loss: 0.7033 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 5s 900ms/step - loss: 0.7436 - accuracy: 0.7096 - val_loss: 0.7092 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.7927 - accuracy: 0.6849 - val_loss: 0.7007 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7427 - accuracy: 0.7178 - val_loss: 0.7017 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.7693 - accuracy: 0.7123 - val_loss: 0.6973 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.7445 - accuracy: 0.7370 - val_loss: 0.7020 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7658 - accuracy: 0.7397 - val_loss: 0.6921 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.7596 - accuracy: 0.7288 - val_loss: 0.6872 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7701 - accuracy: 0.6986 - val_loss: 0.7066 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.7807 - accuracy: 0.6877 - val_loss: 0.7272 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.7809 - accuracy: 0.6986 - val_loss: 0.7003 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7526 - accuracy: 0.7178 - val_loss: 0.7069 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7903 - accuracy: 0.7068 - val_loss: 0.6935 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7588 - accuracy: 0.7178 - val_loss: 0.6869 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.7230 - accuracy: 0.7342 - val_loss: 0.7172 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 5s 922ms/step - loss: 0.7161 - accuracy: 0.7178 - val_loss: 0.6972 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7824 - accuracy: 0.6932 - val_loss: 0.7292 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.7409 - accuracy: 0.7096 - val_loss: 0.6888 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 5s 912ms/step - loss: 0.7736 - accuracy: 0.7014 - val_loss: 0.6933 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 5s 912ms/step - loss: 0.7589 - accuracy: 0.7205 - val_loss: 0.7092 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7431 - accuracy: 0.7178 - val_loss: 0.6895 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 0.7047 - accuracy: 0.7370 - val_loss: 0.7140 - val_accuracy: 0.6952 - lr: 1.0000e-04\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7843 - accuracy: 0.7178 - val_loss: 0.7014 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7523 - accuracy: 0.7178 - val_loss: 0.6885 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 5s 914ms/step - loss: 0.7654 - accuracy: 0.7205 - val_loss: 0.6892 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 5s 926ms/step - loss: 0.7628 - accuracy: 0.7205 - val_loss: 0.7018 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 0.7668 - accuracy: 0.7096 - val_loss: 0.6968 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 5s 913ms/step - loss: 0.7578 - accuracy: 0.7507 - val_loss: 0.6863 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.7214 - accuracy: 0.7288 - val_loss: 0.6952 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7471 - accuracy: 0.7041 - val_loss: 0.7019 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 5s 914ms/step - loss: 0.7619 - accuracy: 0.7123 - val_loss: 0.7554 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.7323 - accuracy: 0.7041 - val_loss: 0.7530 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.7583 - accuracy: 0.6932 - val_loss: 0.7522 - val_accuracy: 0.6952 - lr: 1.0000e-04\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.7484 - accuracy: 0.7151 - val_loss: 0.7084 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 0.7319 - accuracy: 0.7123 - val_loss: 0.7136 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.7169 - accuracy: 0.7479 - val_loss: 0.6765 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.7321 - accuracy: 0.7151 - val_loss: 0.6748 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7380 - accuracy: 0.7233 - val_loss: 0.6760 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.7304 - accuracy: 0.7123 - val_loss: 0.6878 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7204 - accuracy: 0.7123 - val_loss: 0.6814 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.7102 - accuracy: 0.7151 - val_loss: 0.6703 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.7115 - accuracy: 0.7562 - val_loss: 0.7208 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7120 - accuracy: 0.7288 - val_loss: 0.6830 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 0.7351 - accuracy: 0.7151 - val_loss: 0.6961 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7709 - accuracy: 0.7014 - val_loss: 0.7080 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7807 - accuracy: 0.7205 - val_loss: 0.7306 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.7346 - accuracy: 0.7178 - val_loss: 0.7048 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.7726 - accuracy: 0.7096 - val_loss: 0.6758 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.6637 - accuracy: 0.7507 - val_loss: 0.6982 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.6840 - accuracy: 0.7370 - val_loss: 0.6765 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7151 - accuracy: 0.7288 - val_loss: 0.6827 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.6904 - accuracy: 0.7425 - val_loss: 0.6699 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.7018 - accuracy: 0.7589 - val_loss: 0.7000 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 0.7294 - accuracy: 0.7342 - val_loss: 0.6759 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.6679 - accuracy: 0.7479 - val_loss: 0.7115 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 0.7166 - accuracy: 0.7288 - val_loss: 0.6806 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.7234 - accuracy: 0.7370 - val_loss: 0.6929 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7093 - accuracy: 0.7123 - val_loss: 0.7065 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.6578 - accuracy: 0.7425 - val_loss: 0.6896 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.6606 - accuracy: 0.7616 - val_loss: 0.6567 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 5s 903ms/step - loss: 0.6971 - accuracy: 0.7479 - val_loss: 0.6855 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.6841 - accuracy: 0.7534 - val_loss: 0.6567 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.6815 - accuracy: 0.7315 - val_loss: 0.7006 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 5s 905ms/step - loss: 0.6948 - accuracy: 0.7425 - val_loss: 0.6847 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 5s 902ms/step - loss: 0.7367 - accuracy: 0.7288 - val_loss: 0.7289 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.7339 - accuracy: 0.7014 - val_loss: 0.6967 - val_accuracy: 0.6952 - lr: 1.0000e-04\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 5s 912ms/step - loss: 0.6968 - accuracy: 0.7397 - val_loss: 0.6744 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.6495 - accuracy: 0.7452 - val_loss: 0.6640 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 0.7016 - accuracy: 0.7123 - val_loss: 0.6636 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 0.6527 - accuracy: 0.7616 - val_loss: 0.7424 - val_accuracy: 0.7143 - lr: 1.0000e-04\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 5s 909ms/step - loss: 0.6834 - accuracy: 0.7260 - val_loss: 0.6765 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 5s 908ms/step - loss: 0.6507 - accuracy: 0.7452 - val_loss: 0.6912 - val_accuracy: 0.7524 - lr: 1.0000e-04\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.6808 - accuracy: 0.7425 - val_loss: 0.6653 - val_accuracy: 0.7048 - lr: 1.0000e-04\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 5s 901ms/step - loss: 0.6832 - accuracy: 0.7589 - val_loss: 0.6776 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.6408 - accuracy: 0.7534 - val_loss: 0.6788 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 5s 911ms/step - loss: 0.6936 - accuracy: 0.7479 - val_loss: 0.6908 - val_accuracy: 0.7333 - lr: 1.0000e-04\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 5s 906ms/step - loss: 0.6714 - accuracy: 0.7507 - val_loss: 0.6780 - val_accuracy: 0.7429 - lr: 1.0000e-04\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 5s 910ms/step - loss: 0.6738 - accuracy: 0.7671 - val_loss: 0.6611 - val_accuracy: 0.7714 - lr: 1.0000e-04\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.6496 - accuracy: 0.7671 - val_loss: 0.6679 - val_accuracy: 0.7619 - lr: 1.0000e-04\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.6799 - accuracy: 0.7479 - val_loss: 0.6648 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 5s 907ms/step - loss: 0.6580 - accuracy: 0.7479 - val_loss: 0.6805 - val_accuracy: 0.7238 - lr: 1.0000e-04\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 5s 904ms/step - loss: 0.6425 - accuracy: 0.7534 - val_loss: 0.6601 - val_accuracy: 0.7143 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_1 = model_1.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm_1 = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy_1 = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1))\n",
        "precision_1 = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "recall_1 = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "f1_1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions_1, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy_1.round(4))\n",
        "print('Precision:',precision_1.round(4))\n",
        "print('Recall:',recall_1.round(4))\n",
        "print('F1:',f1_1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm_1.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8NwAhCEP5pRs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "926e4d10-9647-418f-e183-69e68313a735"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8\n",
            "Precision: 0.8325\n",
            "Recall: 0.8\n",
            "F1: 0.7946\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}