{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dirty_handmade_hiphop_classical.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for 2 genres classification - Country vs Blues\n",
        "\n",
        "We aim at training a Neural Network to distinguish between two genres: country and blues."
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1952a5fc-be57-4002-8aa6-0ca97884b627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a928e7-8e8c-4463-dd67-5df0aa80092b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "IoV9bIbPfg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "#genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "genres = {'hiphop': 0, 'classical': 1}\n",
        "outliers = {'blues': 0, 'disco': 1, 'country': 2, 'jazz': 3, 'metal': 4, 'pop': 5, 'reggae': 6, 'rock': 7}\n",
        "n_dirty_per_genre_per_type = 6\n",
        "\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "        \n",
        "    print(str(genre+' done'))\n",
        "\n",
        "for genre, genre_number in outliers.items():\n",
        "    count = 0\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        if count < 2*n_dirty_per_genre_per_type:\n",
        "          if count < n_dirty_per_genre_per_type:\n",
        "            dataset.append( (ps, 0) )\n",
        "          else:\n",
        "            dataset.append( (ps, 1) )\n",
        "        else:\n",
        "          break\n",
        "    print(str(genre+' done')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pu8r54LJMSj",
        "outputId": "4299dbcc-497d-4e62-ac02-74a2277eb959"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hiphop done\n",
            "classical done\n",
            "blues done\n",
            "disco done\n",
            "country done\n",
            "jazz done\n",
            "metal done\n",
            "pop done\n",
            "reggae done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "0sgOQfv-gZ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(2):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])\n",
        "\n",
        "for j in range(8):\n",
        "  for t in range(2):\n",
        "    for b in range(5):\n",
        "      training.append(dataset[200 + t*8*n_dirty_per_genre_per_type + j*n_dirty_per_genre_per_type + b])\n",
        "    validation.append(dataset[i*100 + t*8*n_dirty_per_genre_per_type + j*n_dirty_per_genre_per_type + 5])\n"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNsfoewZARn8",
        "outputId": "03d96724-a18c-4456-f802-0b941856513e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 2559)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, 2))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, 2))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, 2))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "O6AvTMw2hgxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_units = 2\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, n_units)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd68ac4-ee5d-4746-a826-394514a80890"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 128, 2559, 4)      104       \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 128, 2559, 8)      296       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 64, 1279, 8)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 64, 1279, 16)      1168      \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 64, 1279, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 32, 639, 16)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 32, 639, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 16, 319, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 16, 319, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 8, 159, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 8, 159, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 4, 79, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 4, 79, 286)        36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,216\n",
            "Trainable params: 195,216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 20,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e41a81f-986b-48b9-c405-274b4f1ef4a6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 5s 360ms/step - loss: 0.7561 - accuracy: 0.6636 - val_loss: 0.7739 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 4s 325ms/step - loss: 0.6469 - accuracy: 0.6455 - val_loss: 0.8297 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.5045 - accuracy: 0.7000 - val_loss: 0.6646 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 4s 354ms/step - loss: 0.4654 - accuracy: 0.6955 - val_loss: 0.5097 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.3866 - accuracy: 0.8273 - val_loss: 0.4887 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.3335 - accuracy: 0.9091 - val_loss: 0.2237 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.2278 - accuracy: 0.9409 - val_loss: 0.4843 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.2410 - accuracy: 0.9136 - val_loss: 0.3863 - val_accuracy: 0.8571 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 3s 322ms/step - loss: 0.2628 - accuracy: 0.9182 - val_loss: 0.1067 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.1769 - accuracy: 0.9591 - val_loss: 0.3066 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.2118 - accuracy: 0.9409 - val_loss: 0.1318 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 4s 353ms/step - loss: 0.1581 - accuracy: 0.9409 - val_loss: 0.0695 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.1914 - accuracy: 0.9318 - val_loss: 0.0731 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.1350 - accuracy: 0.9545 - val_loss: 0.1699 - val_accuracy: 0.9286 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.1309 - accuracy: 0.9409 - val_loss: 0.0671 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.1105 - accuracy: 0.9636 - val_loss: 0.1113 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0876 - accuracy: 0.9682 - val_loss: 0.1637 - val_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1750 - accuracy: 0.9591 - val_loss: 0.2156 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1545 - accuracy: 0.9636 - val_loss: 0.1281 - val_accuracy: 0.9643 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1188 - accuracy: 0.9545 - val_loss: 0.2274 - val_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1012 - accuracy: 0.9500 - val_loss: 0.0769 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0824 - accuracy: 0.9773 - val_loss: 0.1279 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0802 - accuracy: 0.9818 - val_loss: 0.0729 - val_accuracy: 0.9643 - lr: 5.0000e-04\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0706 - accuracy: 0.9727 - val_loss: 0.1193 - val_accuracy: 0.9286 - lr: 5.0000e-04\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0826 - accuracy: 0.9636 - val_loss: 0.1649 - val_accuracy: 0.9464 - lr: 5.0000e-04\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0517 - accuracy: 0.9773 - val_loss: 0.0750 - val_accuracy: 0.9643 - lr: 2.5000e-04\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 3s 322ms/step - loss: 0.0560 - accuracy: 0.9727 - val_loss: 0.1155 - val_accuracy: 0.9464 - lr: 2.5000e-04\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.0312 - accuracy: 0.9955 - val_loss: 0.0804 - val_accuracy: 0.9643 - lr: 2.5000e-04\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0239 - accuracy: 0.9955 - val_loss: 0.0624 - val_accuracy: 0.9643 - lr: 2.5000e-04\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 0.0195 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0418 - accuracy: 0.9909 - val_loss: 0.0836 - val_accuracy: 0.9643 - lr: 2.5000e-04\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0354 - accuracy: 0.9955 - val_loss: 0.0407 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 4s 322ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0668 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9821 - lr: 2.5000e-04\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9643 - lr: 2.5000e-04\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9643 - lr: 1.2500e-04\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0115 - accuracy: 0.9955 - val_loss: 0.0929 - val_accuracy: 0.9643 - lr: 1.2500e-04\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9643 - lr: 1.2500e-04\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.1093 - val_accuracy: 0.9643 - lr: 1.2500e-04\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 4s 322ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9821 - lr: 1.2500e-04\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9643 - lr: 1.0000e-04\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0090 - accuracy: 0.9955 - val_loss: 0.0492 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0329 - accuracy: 0.9909 - val_loss: 0.1391 - val_accuracy: 0.9643 - lr: 1.0000e-04\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9821 - lr: 1.0000e-04\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0146 - accuracy: 0.9909 - val_loss: 0.1078 - val_accuracy: 0.9643 - lr: 1.0000e-04\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0083 - accuracy: 0.9955 - val_loss: 0.1480 - val_accuracy: 0.9643 - lr: 1.0000e-04\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9643 - lr: 1.0000e-04\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9643 - lr: 1.0000e-04\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 3s 322ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9643 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "7e15dd48-2892-456f-8eb9-0031e60eb874"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "Precision: 0.9545\n",
            "Recall: 0.95\n",
            "F1: 0.9499\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/dirty_hiphopvclassical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "9c426269-0a32-4155-93bd-456b8cfbbeca"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/dirty_hiphopvclassical/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/hiphopvclassical/dirty_hiphopvclassical/assets\n"
          ]
        }
      ]
    }
  ]
}