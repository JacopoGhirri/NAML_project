{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dirty_handmade_reggae_jazz.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for 2 genres classification - Country vs Blues\n",
        "\n",
        "We aim at training a Neural Network to distinguish between two genres: country and blues."
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce4a2b5-6920-431e-d4f5-87df4284eb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe39631-265c-4f53-9aba-a7f428d5bf24"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "IoV9bIbPfg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "#genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "genres = {'reggae': 0, 'jazz': 1}\n",
        "outliers = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'metal': 6, 'pop': 7, 'rock': 9}\n",
        "n_dirty_per_genre_per_type = 6\n",
        "\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "        \n",
        "    print(str(genre+' done'))\n",
        "\n",
        "for genre, genre_number in outliers.items():\n",
        "    count = 0\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        if count < 2*n_dirty_per_genre_per_type:\n",
        "          if count < n_dirty_per_genre_per_type:\n",
        "            dataset.append( (ps, 0) )\n",
        "          else:\n",
        "            dataset.append( (ps, 1) )\n",
        "        else:\n",
        "          break\n",
        "    print(str(genre+' done')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pu8r54LJMSj",
        "outputId": "ef8429cd-31b2-4a33-895d-3ec171ec9716"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reggae done\n",
            "jazz done\n",
            "blues done\n",
            "classical done\n",
            "country done\n",
            "disco done\n",
            "hiphop done\n",
            "metal done\n",
            "pop done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "0sgOQfv-gZ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(2):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])\n",
        "\n",
        "for j in range(8):\n",
        "  for t in range(2):\n",
        "    for b in range(5):\n",
        "      training.append(dataset[200 + t*8*n_dirty_per_genre_per_type + j*n_dirty_per_genre_per_type + b])\n",
        "    validation.append(dataset[i*100 + t*8*n_dirty_per_genre_per_type + j*n_dirty_per_genre_per_type + 5])\n"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNsfoewZARn8",
        "outputId": "df39863b-3108-4141-c614-9391f555aa42"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 2559)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, 2))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, 2))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, 2))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "O6AvTMw2hgxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_units = 2\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, n_units)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4df6c2f-33e2-4e6e-8145-41c6432ca25e"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 128, 2559, 4)      104       \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 128, 2559, 8)      296       \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 64, 1279, 8)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 64, 1279, 16)      1168      \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 64, 1279, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 32, 639, 16)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 32, 639, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (None, 16, 319, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 16, 319, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 8, 159, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 8, 159, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 4, 79, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 4, 79, 286)        36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,216\n",
            "Trainable params: 195,216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 20,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f227df24-5103-48b3-89d1-30f5559680f8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 5s 360ms/step - loss: 0.6843 - accuracy: 0.6773 - val_loss: 0.7478 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 4s 332ms/step - loss: 0.6060 - accuracy: 0.6818 - val_loss: 0.8500 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.5602 - accuracy: 0.6864 - val_loss: 0.6649 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.4952 - accuracy: 0.6818 - val_loss: 0.6128 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.4884 - accuracy: 0.6818 - val_loss: 0.6070 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.4444 - accuracy: 0.6955 - val_loss: 0.6074 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4315 - accuracy: 0.7864 - val_loss: 0.7326 - val_accuracy: 0.4821 - lr: 0.0010\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 4s 355ms/step - loss: 0.4606 - accuracy: 0.7864 - val_loss: 0.5164 - val_accuracy: 0.8036 - lr: 0.0010\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4002 - accuracy: 0.8455 - val_loss: 0.5546 - val_accuracy: 0.6964 - lr: 0.0010\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.3849 - accuracy: 0.8455 - val_loss: 0.5376 - val_accuracy: 0.7143 - lr: 0.0010\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4142 - accuracy: 0.8682 - val_loss: 0.4759 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.4172 - accuracy: 0.8500 - val_loss: 0.4716 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 4s 325ms/step - loss: 0.3862 - accuracy: 0.8545 - val_loss: 0.4652 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.3552 - accuracy: 0.8727 - val_loss: 0.4256 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.3766 - accuracy: 0.8591 - val_loss: 0.3636 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.3859 - accuracy: 0.8636 - val_loss: 0.3206 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.3741 - accuracy: 0.8227 - val_loss: 0.6014 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.3376 - accuracy: 0.8727 - val_loss: 0.3609 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.2826 - accuracy: 0.8864 - val_loss: 0.2686 - val_accuracy: 0.9286 - lr: 0.0010\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.2513 - accuracy: 0.9136 - val_loss: 0.4834 - val_accuracy: 0.8214 - lr: 0.0010\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.3586 - accuracy: 0.8636 - val_loss: 0.4981 - val_accuracy: 0.7857 - lr: 0.0010\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.2879 - accuracy: 0.9000 - val_loss: 0.3855 - val_accuracy: 0.8571 - lr: 0.0010\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.2207 - accuracy: 0.9318 - val_loss: 0.3078 - val_accuracy: 0.8750 - lr: 0.0010\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1915 - accuracy: 0.9364 - val_loss: 0.2653 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.2161 - accuracy: 0.9182 - val_loss: 0.2687 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.1837 - accuracy: 0.9318 - val_loss: 0.3305 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.1748 - accuracy: 0.9318 - val_loss: 0.4062 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1362 - accuracy: 0.9773 - val_loss: 0.3074 - val_accuracy: 0.9107 - lr: 0.0010\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.1086 - accuracy: 0.9682 - val_loss: 0.5254 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0856 - accuracy: 0.9818 - val_loss: 0.4308 - val_accuracy: 0.9107 - lr: 5.0000e-04\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.1053 - accuracy: 0.9773 - val_loss: 0.4961 - val_accuracy: 0.9107 - lr: 5.0000e-04\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.1232 - accuracy: 0.9500 - val_loss: 1.0332 - val_accuracy: 0.6786 - lr: 5.0000e-04\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 3s 316ms/step - loss: 0.2320 - accuracy: 0.9091 - val_loss: 0.8073 - val_accuracy: 0.7321 - lr: 5.0000e-04\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.2459 - accuracy: 0.9273 - val_loss: 0.3254 - val_accuracy: 0.9107 - lr: 5.0000e-04\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.1128 - accuracy: 0.9682 - val_loss: 0.3371 - val_accuracy: 0.9107 - lr: 2.5000e-04\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0826 - accuracy: 0.9864 - val_loss: 0.3459 - val_accuracy: 0.9107 - lr: 2.5000e-04\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 3s 316ms/step - loss: 0.0752 - accuracy: 0.9818 - val_loss: 0.3357 - val_accuracy: 0.9107 - lr: 2.5000e-04\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0618 - accuracy: 0.9864 - val_loss: 0.3461 - val_accuracy: 0.9107 - lr: 2.5000e-04\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0789 - accuracy: 0.9818 - val_loss: 0.3785 - val_accuracy: 0.9107 - lr: 2.5000e-04\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0576 - accuracy: 0.9864 - val_loss: 0.4315 - val_accuracy: 0.9107 - lr: 1.2500e-04\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0628 - accuracy: 0.9864 - val_loss: 0.3857 - val_accuracy: 0.9286 - lr: 1.2500e-04\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.0504 - accuracy: 0.9864 - val_loss: 0.4230 - val_accuracy: 0.9107 - lr: 1.2500e-04\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0601 - accuracy: 0.9864 - val_loss: 0.4236 - val_accuracy: 0.9107 - lr: 1.2500e-04\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0465 - accuracy: 0.9909 - val_loss: 0.4431 - val_accuracy: 0.9107 - lr: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "bdf154d8-7d0f-4f66-b37c-41690c706211"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b0cb318c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8b0cb318c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "Precision: 0.9545\n",
            "Recall: 0.95\n",
            "F1: 0.9499\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/reggaevjazz/dirty_reggaevjazz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "9e5fdee5-2f6c-4e70-fa57-f4cf47e9ddda"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/reggaevjazz/dirty_reggaevjazz/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/reggaevjazz/dirty_reggaevjazz/assets\n"
          ]
        }
      ]
    }
  ]
}