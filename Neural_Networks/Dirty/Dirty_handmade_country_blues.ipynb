{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dirty_handmade_country_blues.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Black Box Approach for 2 genres classification - Country vs Blues\n",
        "\n",
        "We aim at training a Neural Network to distinguish between two genres: country and blues."
      ],
      "metadata": {
        "id": "gKB_Sss8Ql-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SwPJ54sBQlFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24afe139-2065-4b94-cff2-1a0b2326fd5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#importing google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the working directory\n",
        "%cd /gdrive/MyDrive/polimi/NAML/NAML_proj/"
      ],
      "metadata": {
        "id": "iYHj7NhnQs_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49970c4-544c-49e3-9f34-993197dcc251"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/polimi/NAML/NAML_proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "INc4ttEUQuxN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed of Mel-Spectrograms of each audio sample, labeled with respect to each genre"
      ],
      "metadata": {
        "id": "IoV9bIbPfg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "#genres = {'blues': 0, 'classical': 1, 'country': 2, 'disco': 3, 'hiphop': 4, 'jazz': 5, 'metal': 6, 'pop': 7, 'reggae': 8, 'rock': 9}\n",
        "genres = {'country': 0, 'blues': 1}\n",
        "outliers = {'classical': 0, 'disco': 1, 'hiphop': 2, 'jazz': 3, 'metal': 4, 'pop': 5, 'reggae': 6, 'rock': 7}\n",
        "n_dirty_per_genre_per_type = 6\n",
        "\n",
        "\n",
        "for genre, genre_number in genres.items():\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        dataset.append( (ps, genre_number) )\n",
        "        \n",
        "    print(str(genre+' done'))\n",
        "\n",
        "for genre, genre_number in outliers.items():\n",
        "    count = 0\n",
        "    for filename in os.listdir(f'dataset_old/genres/{genre}'):\n",
        "        songname = f'dataset_old/genres/{genre}/{filename}'\n",
        "        y, sr = librosa.load(songname, mono=True, duration=29.7)\n",
        "        ps = librosa.feature.melspectrogram(y=y, sr=sr, hop_length = 256, n_fft = 512)\n",
        "        ps = librosa.power_to_db(ps**2)\n",
        "        if count < 2*n_dirty_per_genre_per_type:\n",
        "          if count < n_dirty_per_genre_per_type:\n",
        "            dataset.append( (ps, 0) )\n",
        "          else:\n",
        "            dataset.append( (ps, 1) )\n",
        "        else:\n",
        "          break\n",
        "    print(str(genre+' done')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pu8r54LJMSj",
        "outputId": "9c0b2d2b-ea8b-430e-f2e4-1fb282d45367"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "country done\n",
            "blues done\n",
            "classical done\n",
            "disco done\n",
            "hiphop done\n",
            "jazz done\n",
            "metal done\n",
            "pop done\n",
            "reggae done\n",
            "rock done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We split the dataset according to the following composition:\n",
        "\n",
        "\n",
        "*   70% training set\n",
        "*   20% validation set\n",
        "*   10% test set\n",
        "\n",
        "Maintaining equal proportions amongst classes\n",
        "\n"
      ],
      "metadata": {
        "id": "0sgOQfv-gZ04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order = np.arange(start = 0, stop = 100, step = 1)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "training = []\n",
        "validation = []\n",
        "test = []\n",
        "\n",
        "for i in range(2):\n",
        "  shuffle = np.random.permutation(order)\n",
        "  for k in range(70):\n",
        "    training.append(dataset[i*100 + shuffle[k]])\n",
        "  for l in range(20):\n",
        "    validation.append(dataset[i*100 + shuffle[l+70]])\n",
        "  for m in range(10):\n",
        "    test.append(dataset[i*100 + shuffle[m+90]])\n",
        "\n",
        "for j in range(8):\n",
        "  for t in range(2):\n",
        "    for b in range(5):\n",
        "      training.append(dataset[200 + t*8*n_dirty_per_genre_per_type + j*n_dirty_per_genre_per_type + b])\n",
        "    validation.append(dataset[i*100 + t*8*n_dirty_per_genre_per_type + j*n_dirty_per_genre_per_type + 5])\n"
      ],
      "metadata": {
        "id": "OSUK8JPgRFVF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNsfoewZARn8",
        "outputId": "41da9a30-a6d7-4eb1-cd50-ccf6e3034697"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 2559)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = zip(*training)\n",
        "X_valid, Y_valid = zip(*validation)\n",
        "X_test, Y_test = zip(*test)\n",
        "\n",
        "X_train = np.array([x.reshape( (128, 2559, 1) ) for x in X_train])\n",
        "X_valid = np.array([x.reshape( (128, 2559, 1) ) for x in X_valid])\n",
        "X_test = np.array([x.reshape( (128, 2559, 1) ) for x in X_test])\n",
        "\n",
        "Y_train = np.array(tfk.utils.to_categorical(Y_train, 2))\n",
        "Y_valid = np.array(tfk.utils.to_categorical(Y_valid, 2))\n",
        "Y_test = np.array(tfk.utils.to_categorical(Y_test, 2))"
      ],
      "metadata": {
        "id": "WA29NV-URMuG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The proposed model is composed as a stack of convolutional layer, followed by a Global Average Pooling layer leading to a fully connected section.\n",
        "\n",
        "Optimization is performed as a Batch version of Adam optimizer algorithm"
      ],
      "metadata": {
        "id": "O6AvTMw2hgxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, n_units):\n",
        "# Build the neural network layer by layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "    conv1 = tfkl.Conv2D(\n",
        "        filters=4,\n",
        "        kernel_size=(5, 5),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(input_layer)\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=8,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv1)\n",
        "    pool1 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv1_2)\n",
        "\n",
        "    conv2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool1)\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv2)\n",
        "    pool2 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv2_2)\n",
        "\n",
        "    conv3 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool2)\n",
        "    pool3 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv3)\n",
        "\n",
        "    conv4 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool3)\n",
        "    conv4_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(conv4)\n",
        "    pool4 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv4_2)\n",
        "\n",
        "    conv5 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool4)\n",
        "    pool5 = tfkl.MaxPooling2D(\n",
        "        pool_size = (2, 2)\n",
        "    )(conv5)\n",
        "\n",
        "    conv6 = tfkl.Conv2D(\n",
        "        filters=286,\n",
        "        kernel_size=(1,1),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed)\n",
        "    )(pool5)\n",
        "    \n",
        "\n",
        "    global_average = tfkl.GlobalAveragePooling2D(name = 'GAP')(conv6)\n",
        "    global_average = tfkl.Dropout(0.3, seed=seed)(global_average)\n",
        "    \n",
        "    classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(global_average)\n",
        "    #flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
        "    #flattening_layer = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
        "    #classifier_layer = tfkl.Dense(units=64, name='Classifier', activation='relu')(flattening_layer)\n",
        "    \n",
        "    classifier_layer = tfkl.Dropout(0.3, seed=seed)(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dense(units=32, name='Classifier_2', activation='relu')(classifier_layer)\n",
        "    classifier_layer_2 = tfkl.Dropout(0.3, seed=seed)(classifier_layer_2)\n",
        "    output_layer = tfkl.Dense(units=n_units, activation='softmax', name='Output')(classifier_layer_2)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lR2QkBoSQ8lW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_units = 2\n",
        "input_shape = (128, 2559, 1)\n",
        "\n",
        "model = build_model(input_shape, n_units)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zIitkAlGQ-mM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83eab42a-93e8-4154-d0cf-61951503cb73"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 128, 2559, 1)]    0         \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 128, 2559, 4)      104       \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 128, 2559, 8)      296       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 64, 1279, 8)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 64, 1279, 16)      1168      \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 64, 1279, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 32, 639, 16)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 32, 639, 32)       4640      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 16, 319, 32)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 16, 319, 64)       18496     \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 16, 319, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 8, 159, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 8, 159, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 4, 79, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 4, 79, 286)        36894     \n",
            "                                                                 \n",
            " GAP (GlobalAveragePooling2D  (None, 286)              0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 286)               0         \n",
            "                                                                 \n",
            " Classifier (Dense)          (None, 64)                18368     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " Classifier_2 (Dense)        (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " Output (Dense)              (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,216\n",
            "Trainable params: 195,216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=20, restore_best_weights=True)\n",
        "adaptive_LR = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-4)\n",
        "\n",
        "standard_history = model.fit(\n",
        "    x = X_train,\n",
        "    y = Y_train,\n",
        "    epochs = 500,\n",
        "    batch_size = 20,\n",
        "    validation_data= (X_valid, Y_valid),\n",
        "    callbacks = [early_stopping, adaptive_LR]\n",
        "    )"
      ],
      "metadata": {
        "id": "yFUsDY6BRWi1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5634091b-4676-4b03-8c47-cb959a921884"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "11/11 [==============================] - 6s 437ms/step - loss: 0.6901 - accuracy: 0.6045 - val_loss: 0.7164 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.6106 - accuracy: 0.6909 - val_loss: 1.1054 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.6460 - accuracy: 0.6682 - val_loss: 0.7521 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.6049 - accuracy: 0.6955 - val_loss: 0.9723 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 4s 352ms/step - loss: 0.5923 - accuracy: 0.6818 - val_loss: 0.8846 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.5780 - accuracy: 0.6818 - val_loss: 0.7631 - val_accuracy: 0.3571 - lr: 0.0010\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.5647 - accuracy: 0.6773 - val_loss: 0.9235 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.5680 - accuracy: 0.6818 - val_loss: 0.7207 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.5636 - accuracy: 0.6864 - val_loss: 0.8719 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.5321 - accuracy: 0.6955 - val_loss: 0.7865 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.4957 - accuracy: 0.6818 - val_loss: 0.7110 - val_accuracy: 0.3571 - lr: 5.0000e-04\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.5007 - accuracy: 0.7091 - val_loss: 0.8125 - val_accuracy: 0.4464 - lr: 5.0000e-04\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.4733 - accuracy: 0.7045 - val_loss: 0.7693 - val_accuracy: 0.4464 - lr: 5.0000e-04\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4511 - accuracy: 0.7182 - val_loss: 0.8511 - val_accuracy: 0.6071 - lr: 5.0000e-04\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.4388 - accuracy: 0.7227 - val_loss: 0.8009 - val_accuracy: 0.6429 - lr: 5.0000e-04\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4283 - accuracy: 0.7455 - val_loss: 0.8406 - val_accuracy: 0.5179 - lr: 5.0000e-04\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4343 - accuracy: 0.7364 - val_loss: 0.7044 - val_accuracy: 0.6786 - lr: 2.5000e-04\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4173 - accuracy: 0.8227 - val_loss: 0.6939 - val_accuracy: 0.6607 - lr: 2.5000e-04\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.4449 - accuracy: 0.7636 - val_loss: 0.7006 - val_accuracy: 0.6250 - lr: 2.5000e-04\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4174 - accuracy: 0.7682 - val_loss: 0.6852 - val_accuracy: 0.6786 - lr: 2.5000e-04\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.4124 - accuracy: 0.7727 - val_loss: 0.6983 - val_accuracy: 0.6964 - lr: 2.5000e-04\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.4050 - accuracy: 0.7955 - val_loss: 0.6301 - val_accuracy: 0.7321 - lr: 2.5000e-04\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4129 - accuracy: 0.8091 - val_loss: 0.5993 - val_accuracy: 0.6250 - lr: 2.5000e-04\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.4011 - accuracy: 0.7909 - val_loss: 0.6764 - val_accuracy: 0.6964 - lr: 2.5000e-04\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.3647 - accuracy: 0.8182 - val_loss: 0.6025 - val_accuracy: 0.7857 - lr: 2.5000e-04\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.3740 - accuracy: 0.8364 - val_loss: 0.5583 - val_accuracy: 0.6786 - lr: 2.5000e-04\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.4407 - accuracy: 0.7636 - val_loss: 0.8153 - val_accuracy: 0.5179 - lr: 2.5000e-04\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.4400 - accuracy: 0.7636 - val_loss: 0.5473 - val_accuracy: 0.7143 - lr: 2.5000e-04\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.4018 - accuracy: 0.8318 - val_loss: 0.7015 - val_accuracy: 0.6964 - lr: 2.5000e-04\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.3837 - accuracy: 0.8182 - val_loss: 0.5636 - val_accuracy: 0.8036 - lr: 2.5000e-04\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.3436 - accuracy: 0.8500 - val_loss: 0.5291 - val_accuracy: 0.8214 - lr: 2.5000e-04\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.3323 - accuracy: 0.8545 - val_loss: 0.5208 - val_accuracy: 0.8036 - lr: 2.5000e-04\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.3264 - accuracy: 0.8636 - val_loss: 0.6195 - val_accuracy: 0.6964 - lr: 2.5000e-04\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.3317 - accuracy: 0.8364 - val_loss: 0.4358 - val_accuracy: 0.7679 - lr: 2.5000e-04\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.3236 - accuracy: 0.8727 - val_loss: 0.5224 - val_accuracy: 0.7143 - lr: 2.5000e-04\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.3344 - accuracy: 0.8136 - val_loss: 0.4916 - val_accuracy: 0.8036 - lr: 2.5000e-04\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.3304 - accuracy: 0.8455 - val_loss: 0.4234 - val_accuracy: 0.8393 - lr: 2.5000e-04\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.2841 - accuracy: 0.8818 - val_loss: 0.4008 - val_accuracy: 0.7500 - lr: 2.5000e-04\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.3284 - accuracy: 0.8409 - val_loss: 0.4623 - val_accuracy: 0.8036 - lr: 2.5000e-04\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.2937 - accuracy: 0.8909 - val_loss: 0.5217 - val_accuracy: 0.7143 - lr: 2.5000e-04\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.2737 - accuracy: 0.8773 - val_loss: 0.4969 - val_accuracy: 0.7500 - lr: 2.5000e-04\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.2634 - accuracy: 0.8727 - val_loss: 0.3605 - val_accuracy: 0.8393 - lr: 2.5000e-04\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.2623 - accuracy: 0.8636 - val_loss: 0.3577 - val_accuracy: 0.8571 - lr: 2.5000e-04\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.2340 - accuracy: 0.8955 - val_loss: 0.3461 - val_accuracy: 0.8214 - lr: 2.5000e-04\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.2234 - accuracy: 0.9091 - val_loss: 0.3082 - val_accuracy: 0.9107 - lr: 2.5000e-04\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.2093 - accuracy: 0.9182 - val_loss: 0.2795 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.2109 - accuracy: 0.9045 - val_loss: 0.3765 - val_accuracy: 0.8929 - lr: 2.5000e-04\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.2347 - accuracy: 0.9273 - val_loss: 0.3730 - val_accuracy: 0.8393 - lr: 2.5000e-04\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.2749 - accuracy: 0.8864 - val_loss: 0.3334 - val_accuracy: 0.8571 - lr: 2.5000e-04\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1787 - accuracy: 0.9409 - val_loss: 0.4382 - val_accuracy: 0.8214 - lr: 2.5000e-04\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 3s 322ms/step - loss: 0.1642 - accuracy: 0.9364 - val_loss: 0.2691 - val_accuracy: 0.8929 - lr: 2.5000e-04\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1999 - accuracy: 0.9227 - val_loss: 0.3014 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1596 - accuracy: 0.9545 - val_loss: 0.4712 - val_accuracy: 0.8929 - lr: 2.5000e-04\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.1670 - accuracy: 0.9318 - val_loss: 0.3126 - val_accuracy: 0.9107 - lr: 2.5000e-04\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.1558 - accuracy: 0.9409 - val_loss: 0.3533 - val_accuracy: 0.8571 - lr: 2.5000e-04\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.1106 - accuracy: 0.9455 - val_loss: 0.3099 - val_accuracy: 0.8750 - lr: 2.5000e-04\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.1173 - accuracy: 0.9682 - val_loss: 0.3288 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1211 - accuracy: 0.9682 - val_loss: 0.3560 - val_accuracy: 0.8393 - lr: 1.2500e-04\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.2055 - accuracy: 0.9318 - val_loss: 0.4840 - val_accuracy: 0.8036 - lr: 1.2500e-04\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 4s 351ms/step - loss: 0.1442 - accuracy: 0.9500 - val_loss: 0.3392 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.1054 - accuracy: 0.9591 - val_loss: 0.2966 - val_accuracy: 0.8750 - lr: 1.2500e-04\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.1080 - accuracy: 0.9545 - val_loss: 0.2829 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0906 - accuracy: 0.9773 - val_loss: 0.2910 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.1042 - accuracy: 0.9727 - val_loss: 0.3524 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.1125 - accuracy: 0.9682 - val_loss: 0.3786 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.1118 - accuracy: 0.9727 - val_loss: 0.2901 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0805 - accuracy: 0.9773 - val_loss: 0.3644 - val_accuracy: 0.8571 - lr: 1.0000e-04\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.1028 - accuracy: 0.9545 - val_loss: 0.3004 - val_accuracy: 0.8750 - lr: 1.0000e-04\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 4s 322ms/step - loss: 0.0834 - accuracy: 0.9636 - val_loss: 0.2733 - val_accuracy: 0.9286 - lr: 1.0000e-04\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.0720 - accuracy: 0.9864 - val_loss: 0.3200 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0691 - accuracy: 0.9773 - val_loss: 0.2937 - val_accuracy: 0.9286 - lr: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "\n",
        "# Compute the classification metrics\n",
        "accuracy = accuracy_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
        "precision = precision_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "recall = recall_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "f1 = f1_score(np.argmax(Y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T)#, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Xlmj6RaRRvk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "7fb46d6f-da8a-40a5-dd11-afd4aeb1f316"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.85\n",
            "Precision: 0.8535\n",
            "Recall: 0.85\n",
            "F1: 0.8496\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/gdrive/MyDrive/polimi/NAML/NAML_proj/models/countryvblues/dirty_countryvblues_1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO-HKBQc9I7r",
        "outputId": "0e0f9b98-a88c-45bf-e69e-9ff37f717ae5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/countryvblues/dirty_countryvblues_1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /gdrive/MyDrive/polimi/NAML/NAML_proj/models/countryvblues/dirty_countryvblues_1/assets\n"
          ]
        }
      ]
    }
  ]
}